[03/04 09:56:29] DATASET : 
[03/04 09:56:29]     batch_size : 16
[03/04 09:56:29]     num_workers : 8
[03/04 09:56:29]     test : 
[03/04 09:56:29]         file_path : /root/aistudio/data/new_label_cls14_train.json
[03/04 09:56:29]         format : BMNDataset
[03/04 09:56:29]         subset : validation
[03/04 09:56:29]         test_mode : True
[03/04 09:56:29]     test_batch_size : 1
[03/04 09:56:29]     train : 
[03/04 09:56:29]         file_path : /root/aistudio/data/new_label_cls14_train.json
[03/04 09:56:29]         format : BMNDataset
[03/04 09:56:29]         subset : train
[03/04 09:56:29]     valid : 
[03/04 09:56:29]         file_path : /root/aistudio/data/new_label_cls14_train.json
[03/04 09:56:29]         format : BMNDataset
[03/04 09:56:29]         subset : validation
[03/04 09:56:29] ------------------------------------------------------------
[03/04 09:56:29] INFERENCE : 
[03/04 09:56:29]     dscale : 100
[03/04 09:56:29]     feat_dim : 2048
[03/04 09:56:29]     name : BMN_Inference_helper
[03/04 09:56:29]     result_path : data/bmn/BMN_INFERENCE_results
[03/04 09:56:29]     tscale : 100
[03/04 09:56:29] ------------------------------------------------------------
[03/04 09:56:29] METRIC : 
[03/04 09:56:29]     dscale : 100
[03/04 09:56:29]     file_path : data/bmn_data/activitynet_1.3_annotations.json
[03/04 09:56:29]     ground_truth_filename : data/bmn_data/activity_net_1_3_new.json
[03/04 09:56:29]     name : BMNMetric
[03/04 09:56:29]     output_path : data/bmn/BMN_Test_output
[03/04 09:56:29]     result_path : data/bmn/BMN_Test_results
[03/04 09:56:29]     subset : validation
[03/04 09:56:29]     tscale : 100
[03/04 09:56:29] ------------------------------------------------------------
[03/04 09:56:29] MODEL : 
[03/04 09:56:29]     backbone : 
[03/04 09:56:29]         dscale : 100
[03/04 09:56:29]         feat_dim : 2048
[03/04 09:56:29]         name : BMN
[03/04 09:56:29]         num_sample : 32
[03/04 09:56:29]         num_sample_perbin : 3
[03/04 09:56:29]         prop_boundary_ratio : 0.5
[03/04 09:56:29]         tscale : 100
[03/04 09:56:29]     framework : BMNLocalizer
[03/04 09:56:29]     loss : 
[03/04 09:56:29]         dscale : 100
[03/04 09:56:29]         name : BMNLoss
[03/04 09:56:29]         tscale : 100
[03/04 09:56:29] ------------------------------------------------------------
[03/04 09:56:29] OPTIMIZER : 
[03/04 09:56:29]     learning_rate : 
[03/04 09:56:29]         gamma : 0.1
[03/04 09:56:29]         iter_step : False
[03/04 09:56:29]         learning_rate : 0.001
[03/04 09:56:29]         name : CustomStepDecay
[03/04 09:56:29]         step_size : 15
[03/04 09:56:29]     name : Adamax
[03/04 09:56:29]     weight_decay : 
[03/04 09:56:29]         name : L2
[03/04 09:56:29]         value : 0.0001
[03/04 09:56:29] ------------------------------------------------------------
[03/04 09:56:29] PIPELINE : 
[03/04 09:56:29]     test : 
[03/04 09:56:29]         load_feat : 
[03/04 09:56:29]             feat_path : /root/aistudio/data/Features_competition_train/npy
[03/04 09:56:29]             name : LoadFeat
[03/04 09:56:29]         transform : 
[03/04 09:56:29]             GetMatchMap : 
[03/04 09:56:29]                 tscale : 100
[03/04 09:56:29]             GetVideoLabel : 
[03/04 09:56:29]                 dscale : 100
[03/04 09:56:29]                 tscale : 100
[03/04 09:56:29]     train : 
[03/04 09:56:29]         load_feat : 
[03/04 09:56:29]             feat_path : /root/aistudio/data/Features_competition_train/npy
[03/04 09:56:29]             name : LoadFeat
[03/04 09:56:29]         transform : 
[03/04 09:56:29]             GetMatchMap : 
[03/04 09:56:29]                 tscale : 100
[03/04 09:56:29]             GetVideoLabel : 
[03/04 09:56:29]                 dscale : 100
[03/04 09:56:29]                 tscale : 100
[03/04 09:56:29]     valid : 
[03/04 09:56:29]         load_feat : 
[03/04 09:56:29]             feat_path : /root/aistudio/data/Features_competition_train/npy
[03/04 09:56:29]             name : LoadFeat
[03/04 09:56:29]         transform : 
[03/04 09:56:29]             GetMatchMap : 
[03/04 09:56:29]                 tscale : 100
[03/04 09:56:29]             GetVideoLabel : 
[03/04 09:56:29]                 dscale : 100
[03/04 09:56:29]                 tscale : 100
[03/04 09:56:29] ------------------------------------------------------------
[03/04 09:56:29] epochs : 30
[03/04 09:56:29] log_level : INFO
[03/04 09:56:29] log_path : log_BMN/log/
[03/04 09:56:29] model_name : BMN
[03/04 09:56:29] resume_from : 
[03/04 09:56:33] train subset video numbers: 12597
[03/04 09:56:35] epoch:[  1/30 ] train step:0    loss: 2.65151 lr: 0.001000 batch_cost: 2.16733 sec, reader_cost: 0.79209 sec, ips: 7.38236 instance/sec.
[03/04 09:56:39] epoch:[  1/30 ] train step:10   loss: 2.53120 lr: 0.001000 batch_cost: 0.35201 sec, reader_cost: 0.00249 sec, ips: 45.45347 instance/sec.
[03/04 09:56:42] epoch:[  1/30 ] train step:20   loss: 2.41014 lr: 0.001000 batch_cost: 0.35206 sec, reader_cost: 0.00225 sec, ips: 45.44719 instance/sec.
[03/04 09:56:46] epoch:[  1/30 ] train step:30   loss: 2.42725 lr: 0.001000 batch_cost: 0.35516 sec, reader_cost: 0.00057 sec, ips: 45.04997 instance/sec.
[03/04 09:56:50] epoch:[  1/30 ] train step:40   loss: 2.43351 lr: 0.001000 batch_cost: 0.36381 sec, reader_cost: 0.00290 sec, ips: 43.97844 instance/sec.
[03/04 09:56:53] epoch:[  1/30 ] train step:50   loss: 2.43494 lr: 0.001000 batch_cost: 0.35346 sec, reader_cost: 0.00025 sec, ips: 45.26712 instance/sec.
[03/04 09:56:57] epoch:[  1/30 ] train step:60   loss: 2.43284 lr: 0.001000 batch_cost: 0.35267 sec, reader_cost: 0.00238 sec, ips: 45.36804 instance/sec.
[03/04 09:57:00] epoch:[  1/30 ] train step:70   loss: 2.34698 lr: 0.001000 batch_cost: 0.34982 sec, reader_cost: 0.00223 sec, ips: 45.73835 instance/sec.
[03/04 09:57:04] epoch:[  1/30 ] train step:80   loss: 2.63890 lr: 0.001000 batch_cost: 0.36565 sec, reader_cost: 0.00085 sec, ips: 43.75778 instance/sec.
[03/04 09:57:07] epoch:[  1/30 ] train step:90   loss: 2.37687 lr: 0.001000 batch_cost: 0.35156 sec, reader_cost: 0.00233 sec, ips: 45.51151 instance/sec.
[03/04 09:57:11] epoch:[  1/30 ] train step:100  loss: 2.30692 lr: 0.001000 batch_cost: 0.35359 sec, reader_cost: 0.00220 sec, ips: 45.25033 instance/sec.
[03/04 09:57:14] epoch:[  1/30 ] train step:110  loss: 2.14123 lr: 0.001000 batch_cost: 0.35242 sec, reader_cost: 0.00232 sec, ips: 45.39978 instance/sec.
[03/04 09:57:18] epoch:[  1/30 ] train step:120  loss: 1.89636 lr: 0.001000 batch_cost: 0.35493 sec, reader_cost: 0.00252 sec, ips: 45.07968 instance/sec.
[03/04 09:57:21] epoch:[  1/30 ] train step:130  loss: 2.06320 lr: 0.001000 batch_cost: 0.35322 sec, reader_cost: 0.00233 sec, ips: 45.29706 instance/sec.
[03/04 09:57:25] epoch:[  1/30 ] train step:140  loss: 1.90642 lr: 0.001000 batch_cost: 0.35340 sec, reader_cost: 0.00016 sec, ips: 45.27469 instance/sec.
[03/04 09:57:28] epoch:[  1/30 ] train step:150  loss: 2.02551 lr: 0.001000 batch_cost: 0.35402 sec, reader_cost: 0.00224 sec, ips: 45.19548 instance/sec.
[03/04 09:57:32] epoch:[  1/30 ] train step:160  loss: 2.08195 lr: 0.001000 batch_cost: 0.35461 sec, reader_cost: 0.00271 sec, ips: 45.12012 instance/sec.
[03/04 09:57:35] epoch:[  1/30 ] train step:170  loss: 2.72931 lr: 0.001000 batch_cost: 0.35425 sec, reader_cost: 0.00227 sec, ips: 45.16555 instance/sec.
[03/04 09:57:39] epoch:[  1/30 ] train step:180  loss: 1.69499 lr: 0.001000 batch_cost: 0.35418 sec, reader_cost: 0.00218 sec, ips: 45.17439 instance/sec.
[03/04 09:57:42] epoch:[  1/30 ] train step:190  loss: 1.76491 lr: 0.001000 batch_cost: 0.35467 sec, reader_cost: 0.00257 sec, ips: 45.11272 instance/sec.
[03/04 09:57:46] epoch:[  1/30 ] train step:200  loss: 1.69003 lr: 0.001000 batch_cost: 0.35473 sec, reader_cost: 0.00272 sec, ips: 45.10410 instance/sec.
[03/04 09:57:49] epoch:[  1/30 ] train step:210  loss: 1.78598 lr: 0.001000 batch_cost: 0.35383 sec, reader_cost: 0.00217 sec, ips: 45.21996 instance/sec.
[03/04 09:57:53] epoch:[  1/30 ] train step:220  loss: 1.65167 lr: 0.001000 batch_cost: 0.35430 sec, reader_cost: 0.00220 sec, ips: 45.15959 instance/sec.
[03/04 09:57:57] epoch:[  1/30 ] train step:230  loss: 1.53508 lr: 0.001000 batch_cost: 0.35557 sec, reader_cost: 0.00214 sec, ips: 44.99792 instance/sec.
[03/04 09:58:00] epoch:[  1/30 ] train step:240  loss: 1.53061 lr: 0.001000 batch_cost: 0.35440 sec, reader_cost: 0.00270 sec, ips: 45.14652 instance/sec.
[03/04 09:58:04] epoch:[  1/30 ] train step:250  loss: 1.60177 lr: 0.001000 batch_cost: 0.35788 sec, reader_cost: 0.00231 sec, ips: 44.70771 instance/sec.
[03/04 09:58:07] epoch:[  1/30 ] train step:260  loss: 1.88400 lr: 0.001000 batch_cost: 0.35972 sec, reader_cost: 0.00228 sec, ips: 44.47963 instance/sec.
[03/04 09:58:11] epoch:[  1/30 ] train step:270  loss: 1.56798 lr: 0.001000 batch_cost: 0.35776 sec, reader_cost: 0.00216 sec, ips: 44.72234 instance/sec.
[03/04 09:58:14] epoch:[  1/30 ] train step:280  loss: 1.26235 lr: 0.001000 batch_cost: 0.35931 sec, reader_cost: 0.00272 sec, ips: 44.53016 instance/sec.
[03/04 09:58:18] epoch:[  1/30 ] train step:290  loss: 1.34899 lr: 0.001000 batch_cost: 0.35783 sec, reader_cost: 0.00218 sec, ips: 44.71417 instance/sec.
[03/04 09:58:22] epoch:[  1/30 ] train step:300  loss: 1.37616 lr: 0.001000 batch_cost: 0.35680 sec, reader_cost: 0.00233 sec, ips: 44.84280 instance/sec.
[03/04 09:58:25] epoch:[  1/30 ] train step:310  loss: 1.18930 lr: 0.001000 batch_cost: 0.35995 sec, reader_cost: 0.00227 sec, ips: 44.45035 instance/sec.
[03/04 09:58:29] epoch:[  1/30 ] train step:320  loss: 1.46091 lr: 0.001000 batch_cost: 0.35814 sec, reader_cost: 0.00268 sec, ips: 44.67533 instance/sec.
[03/04 09:58:32] epoch:[  1/30 ] train step:330  loss: 1.72574 lr: 0.001000 batch_cost: 0.35756 sec, reader_cost: 0.00234 sec, ips: 44.74715 instance/sec.
[03/04 09:58:36] epoch:[  1/30 ] train step:340  loss: 1.31058 lr: 0.001000 batch_cost: 0.35842 sec, reader_cost: 0.00227 sec, ips: 44.64047 instance/sec.
[03/04 09:58:39] epoch:[  1/30 ] train step:350  loss: 1.70996 lr: 0.001000 batch_cost: 0.35778 sec, reader_cost: 0.00227 sec, ips: 44.72001 instance/sec.
[03/04 09:58:43] epoch:[  1/30 ] train step:360  loss: 1.58696 lr: 0.001000 batch_cost: 0.35967 sec, reader_cost: 0.00259 sec, ips: 44.48556 instance/sec.
[03/04 09:58:47] epoch:[  1/30 ] train step:370  loss: 1.66094 lr: 0.001000 batch_cost: 0.35743 sec, reader_cost: 0.00223 sec, ips: 44.76413 instance/sec.
[03/04 09:58:50] epoch:[  1/30 ] train step:380  loss: 1.25180 lr: 0.001000 batch_cost: 0.35813 sec, reader_cost: 0.00221 sec, ips: 44.67607 instance/sec.
[03/04 09:58:54] epoch:[  1/30 ] train step:390  loss: 1.49914 lr: 0.001000 batch_cost: 0.35954 sec, reader_cost: 0.00259 sec, ips: 44.50169 instance/sec.
[03/04 09:58:57] epoch:[  1/30 ] train step:400  loss: 1.16550 lr: 0.001000 batch_cost: 0.35658 sec, reader_cost: 0.00256 sec, ips: 44.87125 instance/sec.
[03/04 09:59:01] epoch:[  1/30 ] train step:410  loss: 1.19400 lr: 0.001000 batch_cost: 0.35827 sec, reader_cost: 0.00223 sec, ips: 44.65865 instance/sec.
[03/04 09:59:05] epoch:[  1/30 ] train step:420  loss: 1.44319 lr: 0.001000 batch_cost: 0.35753 sec, reader_cost: 0.00215 sec, ips: 44.75183 instance/sec.
[03/04 09:59:08] epoch:[  1/30 ] train step:430  loss: 1.48665 lr: 0.001000 batch_cost: 0.35857 sec, reader_cost: 0.00226 sec, ips: 44.62118 instance/sec.
[03/04 09:59:12] epoch:[  1/30 ] train step:440  loss: 1.32694 lr: 0.001000 batch_cost: 0.36040 sec, reader_cost: 0.00269 sec, ips: 44.39512 instance/sec.
[03/04 09:59:15] epoch:[  1/30 ] train step:450  loss: 1.20772 lr: 0.001000 batch_cost: 0.35986 sec, reader_cost: 0.00219 sec, ips: 44.46195 instance/sec.
[03/04 09:59:19] epoch:[  1/30 ] train step:460  loss: 1.14983 lr: 0.001000 batch_cost: 0.35938 sec, reader_cost: 0.00229 sec, ips: 44.52130 instance/sec.
[03/04 09:59:22] epoch:[  1/30 ] train step:470  loss: 1.65950 lr: 0.001000 batch_cost: 0.35996 sec, reader_cost: 0.00262 sec, ips: 44.44887 instance/sec.
[03/04 09:59:26] epoch:[  1/30 ] train step:480  loss: 1.52156 lr: 0.001000 batch_cost: 0.35631 sec, reader_cost: 0.00230 sec, ips: 44.90530 instance/sec.
[03/04 09:59:30] epoch:[  1/30 ] train step:490  loss: 1.60732 lr: 0.001000 batch_cost: 0.35818 sec, reader_cost: 0.00221 sec, ips: 44.67075 instance/sec.
[03/04 09:59:33] epoch:[  1/30 ] train step:500  loss: 1.57799 lr: 0.001000 batch_cost: 0.36002 sec, reader_cost: 0.00221 sec, ips: 44.44251 instance/sec.
[03/04 09:59:37] epoch:[  1/30 ] train step:510  loss: 1.19742 lr: 0.001000 batch_cost: 0.35888 sec, reader_cost: 0.00231 sec, ips: 44.58323 instance/sec.
[03/04 09:59:40] epoch:[  1/30 ] train step:520  loss: 1.64062 lr: 0.001000 batch_cost: 0.35940 sec, reader_cost: 0.00265 sec, ips: 44.51902 instance/sec.
[03/04 09:59:44] epoch:[  1/30 ] train step:530  loss: 1.42352 lr: 0.001000 batch_cost: 0.35934 sec, reader_cost: 0.00221 sec, ips: 44.52620 instance/sec.
[03/04 09:59:48] epoch:[  1/30 ] train step:540  loss: 1.37965 lr: 0.001000 batch_cost: 0.35792 sec, reader_cost: 0.00039 sec, ips: 44.70309 instance/sec.
[03/04 09:59:51] epoch:[  1/30 ] train step:550  loss: 1.27610 lr: 0.001000 batch_cost: 0.36048 sec, reader_cost: 0.00217 sec, ips: 44.38578 instance/sec.
[03/04 09:59:55] epoch:[  1/30 ] train step:560  loss: 1.20028 lr: 0.001000 batch_cost: 0.35578 sec, reader_cost: 0.00271 sec, ips: 44.97172 instance/sec.
[03/04 09:59:58] epoch:[  1/30 ] train step:570  loss: 1.22854 lr: 0.001000 batch_cost: 0.35729 sec, reader_cost: 0.00220 sec, ips: 44.78104 instance/sec.
[03/04 10:00:02] epoch:[  1/30 ] train step:580  loss: 1.15399 lr: 0.001000 batch_cost: 0.35572 sec, reader_cost: 0.00020 sec, ips: 44.97877 instance/sec.
[03/04 10:00:05] epoch:[  1/30 ] train step:590  loss: 1.55439 lr: 0.001000 batch_cost: 0.35614 sec, reader_cost: 0.00221 sec, ips: 44.92568 instance/sec.
[03/04 10:00:09] epoch:[  1/30 ] train step:600  loss: 1.29140 lr: 0.001000 batch_cost: 0.35823 sec, reader_cost: 0.00268 sec, ips: 44.66459 instance/sec.
[03/04 10:00:13] epoch:[  1/30 ] train step:610  loss: 1.55429 lr: 0.001000 batch_cost: 0.35635 sec, reader_cost: 0.00261 sec, ips: 44.89950 instance/sec.
[03/04 10:00:16] epoch:[  1/30 ] train step:620  loss: 1.42028 lr: 0.001000 batch_cost: 0.35789 sec, reader_cost: 0.00244 sec, ips: 44.70690 instance/sec.
[03/04 10:00:20] epoch:[  1/30 ] train step:630  loss: 1.05099 lr: 0.001000 batch_cost: 0.35798 sec, reader_cost: 0.00233 sec, ips: 44.69514 instance/sec.
[03/04 10:00:23] epoch:[  1/30 ] train step:640  loss: 1.32231 lr: 0.001000 batch_cost: 0.35318 sec, reader_cost: 0.00012 sec, ips: 45.30272 instance/sec.
[03/04 10:00:27] epoch:[  1/30 ] train step:650  loss: 1.63237 lr: 0.001000 batch_cost: 0.35873 sec, reader_cost: 0.00224 sec, ips: 44.60119 instance/sec.
[03/04 10:00:30] epoch:[  1/30 ] train step:660  loss: 1.42098 lr: 0.001000 batch_cost: 0.35620 sec, reader_cost: 0.00021 sec, ips: 44.91814 instance/sec.
[03/04 10:00:34] epoch:[  1/30 ] train step:670  loss: 1.48192 lr: 0.001000 batch_cost: 0.35775 sec, reader_cost: 0.00235 sec, ips: 44.72439 instance/sec.
[03/04 10:00:38] epoch:[  1/30 ] train step:680  loss: 1.16456 lr: 0.001000 batch_cost: 0.35695 sec, reader_cost: 0.00265 sec, ips: 44.82450 instance/sec.
[03/04 10:00:41] epoch:[  1/30 ] train step:690  loss: 1.17316 lr: 0.001000 batch_cost: 0.35913 sec, reader_cost: 0.00234 sec, ips: 44.55171 instance/sec.
[03/04 10:00:45] epoch:[  1/30 ] train step:700  loss: 1.60820 lr: 0.001000 batch_cost: 0.35534 sec, reader_cost: 0.00227 sec, ips: 45.02703 instance/sec.
[03/04 10:00:48] epoch:[  1/30 ] train step:710  loss: 1.06955 lr: 0.001000 batch_cost: 0.35632 sec, reader_cost: 0.00220 sec, ips: 44.90308 instance/sec.
[03/04 10:00:52] epoch:[  1/30 ] train step:720  loss: 1.27032 lr: 0.001000 batch_cost: 0.35394 sec, reader_cost: 0.00017 sec, ips: 45.20564 instance/sec.
[03/04 10:00:55] epoch:[  1/30 ] train step:730  loss: 1.14711 lr: 0.001000 batch_cost: 0.35678 sec, reader_cost: 0.00219 sec, ips: 44.84613 instance/sec.
[03/04 10:00:59] epoch:[  1/30 ] train step:740  loss: 1.54369 lr: 0.001000 batch_cost: 0.35722 sec, reader_cost: 0.00015 sec, ips: 44.79081 instance/sec.
[03/04 10:01:02] epoch:[  1/30 ] train step:750  loss: 1.60642 lr: 0.001000 batch_cost: 0.35612 sec, reader_cost: 0.00220 sec, ips: 44.92929 instance/sec.
[03/04 10:01:06] epoch:[  1/30 ] train step:760  loss: 1.13615 lr: 0.001000 batch_cost: 0.35831 sec, reader_cost: 0.00273 sec, ips: 44.65363 instance/sec.
[03/04 10:01:10] epoch:[  1/30 ] train step:770  loss: 1.13721 lr: 0.001000 batch_cost: 0.35777 sec, reader_cost: 0.00220 sec, ips: 44.72138 instance/sec.
[03/04 10:01:13] epoch:[  1/30 ] train step:780  loss: 1.39644 lr: 0.001000 batch_cost: 0.35279 sec, reader_cost: 0.00006 sec, ips: 45.35284 instance/sec.
[03/04 10:01:15] END epoch:1   train loss_avg: 1.60828  avg_batch_cost: 0.35116 sec, avg_reader_cost: 0.00007 sec, batch_cost_sum: 281.95725 sec, avg_ips: 44.65925 instance/sec.
[03/04 10:01:17] epoch:[  2/30 ] train step:0    loss: 1.10712 lr: 0.001000 batch_cost: 1.14380 sec, reader_cost: 0.77527 sec, ips: 13.98843 instance/sec.
[03/04 10:01:20] epoch:[  2/30 ] train step:10   loss: 1.41211 lr: 0.001000 batch_cost: 0.35644 sec, reader_cost: 0.00239 sec, ips: 44.88878 instance/sec.
[03/04 10:01:24] epoch:[  2/30 ] train step:20   loss: 1.08334 lr: 0.001000 batch_cost: 0.35986 sec, reader_cost: 0.00215 sec, ips: 44.46207 instance/sec.
[03/04 10:01:28] epoch:[  2/30 ] train step:30   loss: 1.52442 lr: 0.001000 batch_cost: 0.35605 sec, reader_cost: 0.00224 sec, ips: 44.93739 instance/sec.
[03/04 10:01:31] epoch:[  2/30 ] train step:40   loss: 1.21596 lr: 0.001000 batch_cost: 0.35587 sec, reader_cost: 0.00233 sec, ips: 44.96087 instance/sec.
[03/04 10:01:35] epoch:[  2/30 ] train step:50   loss: 1.10253 lr: 0.001000 batch_cost: 0.35614 sec, reader_cost: 0.00236 sec, ips: 44.92668 instance/sec.
[03/04 10:01:38] epoch:[  2/30 ] train step:60   loss: 1.24417 lr: 0.001000 batch_cost: 0.35395 sec, reader_cost: 0.00012 sec, ips: 45.20424 instance/sec.
[03/04 10:01:42] epoch:[  2/30 ] train step:70   loss: 1.45659 lr: 0.001000 batch_cost: 0.35844 sec, reader_cost: 0.00231 sec, ips: 44.63839 instance/sec.
[03/04 10:01:45] epoch:[  2/30 ] train step:80   loss: 1.15432 lr: 0.001000 batch_cost: 0.35503 sec, reader_cost: 0.00238 sec, ips: 45.06603 instance/sec.
[03/04 10:01:49] epoch:[  2/30 ] train step:90   loss: 1.44559 lr: 0.001000 batch_cost: 0.35659 sec, reader_cost: 0.00043 sec, ips: 44.86930 instance/sec.
[03/04 10:01:52] epoch:[  2/30 ] train step:100  loss: 1.22012 lr: 0.001000 batch_cost: 0.35602 sec, reader_cost: 0.00231 sec, ips: 44.94079 instance/sec.
[03/04 10:01:56] epoch:[  2/30 ] train step:110  loss: 1.10097 lr: 0.001000 batch_cost: 0.35667 sec, reader_cost: 0.00241 sec, ips: 44.85980 instance/sec.
[03/04 10:02:00] epoch:[  2/30 ] train step:120  loss: 0.89260 lr: 0.001000 batch_cost: 0.35870 sec, reader_cost: 0.00158 sec, ips: 44.60584 instance/sec.
[03/04 10:02:03] epoch:[  2/30 ] train step:130  loss: 1.11683 lr: 0.001000 batch_cost: 0.35635 sec, reader_cost: 0.00235 sec, ips: 44.89977 instance/sec.
[03/04 10:02:07] epoch:[  2/30 ] train step:140  loss: 1.10567 lr: 0.001000 batch_cost: 0.35743 sec, reader_cost: 0.00015 sec, ips: 44.76431 instance/sec.
[03/04 10:02:10] epoch:[  2/30 ] train step:150  loss: 1.40144 lr: 0.001000 batch_cost: 0.35593 sec, reader_cost: 0.00223 sec, ips: 44.95253 instance/sec.
[03/04 10:02:14] epoch:[  2/30 ] train step:160  loss: 1.31101 lr: 0.001000 batch_cost: 0.35530 sec, reader_cost: 0.00235 sec, ips: 45.03177 instance/sec.
[03/04 10:02:17] epoch:[  2/30 ] train step:170  loss: 1.43336 lr: 0.001000 batch_cost: 0.35537 sec, reader_cost: 0.00212 sec, ips: 45.02385 instance/sec.
[03/04 10:02:21] epoch:[  2/30 ] train step:180  loss: 1.26816 lr: 0.001000 batch_cost: 0.35710 sec, reader_cost: 0.00223 sec, ips: 44.80511 instance/sec.
[03/04 10:02:25] epoch:[  2/30 ] train step:190  loss: 0.95793 lr: 0.001000 batch_cost: 0.36437 sec, reader_cost: 0.00249 sec, ips: 43.91157 instance/sec.
[03/04 10:02:28] epoch:[  2/30 ] train step:200  loss: 1.24088 lr: 0.001000 batch_cost: 0.35587 sec, reader_cost: 0.00222 sec, ips: 44.96048 instance/sec.
[03/04 10:02:32] epoch:[  2/30 ] train step:210  loss: 1.38786 lr: 0.001000 batch_cost: 0.35585 sec, reader_cost: 0.00233 sec, ips: 44.96325 instance/sec.
[03/04 10:02:35] epoch:[  2/30 ] train step:220  loss: 1.29226 lr: 0.001000 batch_cost: 0.35545 sec, reader_cost: 0.00217 sec, ips: 45.01353 instance/sec.
[03/04 10:02:39] epoch:[  2/30 ] train step:230  loss: 1.06403 lr: 0.001000 batch_cost: 0.35815 sec, reader_cost: 0.00226 sec, ips: 44.67417 instance/sec.
[03/04 10:02:42] epoch:[  2/30 ] train step:240  loss: 1.24327 lr: 0.001000 batch_cost: 0.35576 sec, reader_cost: 0.00232 sec, ips: 44.97401 instance/sec.
[03/04 10:02:46] epoch:[  2/30 ] train step:250  loss: 1.16854 lr: 0.001000 batch_cost: 0.35571 sec, reader_cost: 0.00230 sec, ips: 44.98076 instance/sec.
[03/04 10:02:50] epoch:[  2/30 ] train step:260  loss: 0.94583 lr: 0.001000 batch_cost: 0.35833 sec, reader_cost: 0.00248 sec, ips: 44.65211 instance/sec.
[03/04 10:02:53] epoch:[  2/30 ] train step:270  loss: 1.31320 lr: 0.001000 batch_cost: 0.35457 sec, reader_cost: 0.00251 sec, ips: 45.12497 instance/sec.
[03/04 10:02:57] epoch:[  2/30 ] train step:280  loss: 1.00884 lr: 0.001000 batch_cost: 0.35885 sec, reader_cost: 0.00229 sec, ips: 44.58741 instance/sec.
[03/04 10:03:00] epoch:[  2/30 ] train step:290  loss: 1.17818 lr: 0.001000 batch_cost: 0.35550 sec, reader_cost: 0.00222 sec, ips: 45.00682 instance/sec.
[03/04 10:03:04] epoch:[  2/30 ] train step:300  loss: 1.28099 lr: 0.001000 batch_cost: 0.35602 sec, reader_cost: 0.00229 sec, ips: 44.94067 instance/sec.
[03/04 10:03:07] epoch:[  2/30 ] train step:310  loss: 1.03665 lr: 0.001000 batch_cost: 0.35595 sec, reader_cost: 0.00225 sec, ips: 44.95057 instance/sec.
[03/04 10:03:11] epoch:[  2/30 ] train step:320  loss: 1.04873 lr: 0.001000 batch_cost: 0.35639 sec, reader_cost: 0.00244 sec, ips: 44.89419 instance/sec.
[03/04 10:03:15] epoch:[  2/30 ] train step:330  loss: 1.55396 lr: 0.001000 batch_cost: 0.36756 sec, reader_cost: 0.00120 sec, ips: 43.53077 instance/sec.
[03/04 10:03:18] epoch:[  2/30 ] train step:340  loss: 1.08327 lr: 0.001000 batch_cost: 0.35596 sec, reader_cost: 0.00014 sec, ips: 44.94922 instance/sec.
[03/04 10:03:22] epoch:[  2/30 ] train step:350  loss: 1.05589 lr: 0.001000 batch_cost: 0.35608 sec, reader_cost: 0.00019 sec, ips: 44.93381 instance/sec.
[03/04 10:03:25] epoch:[  2/30 ] train step:360  loss: 1.16186 lr: 0.001000 batch_cost: 0.35525 sec, reader_cost: 0.00218 sec, ips: 45.03839 instance/sec.
[03/04 10:03:29] epoch:[  2/30 ] train step:370  loss: 1.04568 lr: 0.001000 batch_cost: 0.35917 sec, reader_cost: 0.00241 sec, ips: 44.54677 instance/sec.
[03/04 10:03:32] epoch:[  2/30 ] train step:380  loss: 1.05846 lr: 0.001000 batch_cost: 0.35718 sec, reader_cost: 0.00229 sec, ips: 44.79497 instance/sec.
[03/04 10:03:36] epoch:[  2/30 ] train step:390  loss: 1.18180 lr: 0.001000 batch_cost: 0.35590 sec, reader_cost: 0.00219 sec, ips: 44.95641 instance/sec.
[03/04 10:03:39] epoch:[  2/30 ] train step:400  loss: 1.08744 lr: 0.001000 batch_cost: 0.35906 sec, reader_cost: 0.00231 sec, ips: 44.56109 instance/sec.
[03/04 10:03:43] epoch:[  2/30 ] train step:410  loss: 1.06166 lr: 0.001000 batch_cost: 0.35723 sec, reader_cost: 0.00230 sec, ips: 44.78914 instance/sec.
[03/04 10:03:47] epoch:[  2/30 ] train step:420  loss: 0.90180 lr: 0.001000 batch_cost: 0.35866 sec, reader_cost: 0.00259 sec, ips: 44.61109 instance/sec.
[03/04 10:03:50] epoch:[  2/30 ] train step:430  loss: 1.00317 lr: 0.001000 batch_cost: 0.35431 sec, reader_cost: 0.00014 sec, ips: 45.15807 instance/sec.
[03/04 10:03:54] epoch:[  2/30 ] train step:440  loss: 1.12968 lr: 0.001000 batch_cost: 0.35277 sec, reader_cost: 0.00011 sec, ips: 45.35477 instance/sec.
[03/04 10:03:57] epoch:[  2/30 ] train step:450  loss: 1.09571 lr: 0.001000 batch_cost: 0.35613 sec, reader_cost: 0.00229 sec, ips: 44.92719 instance/sec.
[03/04 10:04:01] epoch:[  2/30 ] train step:460  loss: 1.10816 lr: 0.001000 batch_cost: 0.35608 sec, reader_cost: 0.00211 sec, ips: 44.93366 instance/sec.
[03/04 10:04:04] epoch:[  2/30 ] train step:470  loss: 1.11642 lr: 0.001000 batch_cost: 0.35650 sec, reader_cost: 0.00229 sec, ips: 44.88026 instance/sec.
[03/04 10:04:08] epoch:[  2/30 ] train step:480  loss: 1.05610 lr: 0.001000 batch_cost: 0.35702 sec, reader_cost: 0.00268 sec, ips: 44.81483 instance/sec.
[03/04 10:04:12] epoch:[  2/30 ] train step:490  loss: 1.06394 lr: 0.001000 batch_cost: 0.35728 sec, reader_cost: 0.00041 sec, ips: 44.78334 instance/sec.
[03/04 10:04:15] epoch:[  2/30 ] train step:500  loss: 1.36596 lr: 0.001000 batch_cost: 0.35555 sec, reader_cost: 0.00248 sec, ips: 45.00091 instance/sec.
[03/04 10:04:19] epoch:[  2/30 ] train step:510  loss: 1.10769 lr: 0.001000 batch_cost: 0.35702 sec, reader_cost: 0.00235 sec, ips: 44.81561 instance/sec.
[03/04 10:04:22] epoch:[  2/30 ] train step:520  loss: 1.20464 lr: 0.001000 batch_cost: 0.35474 sec, reader_cost: 0.00234 sec, ips: 45.10407 instance/sec.
[03/04 10:04:26] epoch:[  2/30 ] train step:530  loss: 1.08381 lr: 0.001000 batch_cost: 0.35712 sec, reader_cost: 0.00229 sec, ips: 44.80319 instance/sec.
[03/04 10:04:29] epoch:[  2/30 ] train step:540  loss: 1.20687 lr: 0.001000 batch_cost: 0.35676 sec, reader_cost: 0.00228 sec, ips: 44.84849 instance/sec.
[03/04 10:04:33] epoch:[  2/30 ] train step:550  loss: 1.69426 lr: 0.001000 batch_cost: 0.35622 sec, reader_cost: 0.00238 sec, ips: 44.91669 instance/sec.
[03/04 10:04:36] epoch:[  2/30 ] train step:560  loss: 1.20992 lr: 0.001000 batch_cost: 0.35807 sec, reader_cost: 0.00218 sec, ips: 44.68372 instance/sec.
[03/04 10:04:40] epoch:[  2/30 ] train step:570  loss: 0.97170 lr: 0.001000 batch_cost: 0.35533 sec, reader_cost: 0.00222 sec, ips: 45.02860 instance/sec.
[03/04 10:04:44] epoch:[  2/30 ] train step:580  loss: 1.00921 lr: 0.001000 batch_cost: 0.35817 sec, reader_cost: 0.00247 sec, ips: 44.67179 instance/sec.
[03/04 10:04:47] epoch:[  2/30 ] train step:590  loss: 1.11967 lr: 0.001000 batch_cost: 0.35679 sec, reader_cost: 0.00234 sec, ips: 44.84493 instance/sec.
[03/04 10:04:51] epoch:[  2/30 ] train step:600  loss: 1.41342 lr: 0.001000 batch_cost: 0.35556 sec, reader_cost: 0.00255 sec, ips: 44.99889 instance/sec.
[03/04 10:04:54] epoch:[  2/30 ] train step:610  loss: 1.15603 lr: 0.001000 batch_cost: 0.35664 sec, reader_cost: 0.00242 sec, ips: 44.86312 instance/sec.
[03/04 10:04:58] epoch:[  2/30 ] train step:620  loss: 1.28208 lr: 0.001000 batch_cost: 0.35655 sec, reader_cost: 0.00233 sec, ips: 44.87428 instance/sec.
[03/04 10:05:01] epoch:[  2/30 ] train step:630  loss: 1.16782 lr: 0.001000 batch_cost: 0.35703 sec, reader_cost: 0.00015 sec, ips: 44.81414 instance/sec.
[03/04 10:05:05] epoch:[  2/30 ] train step:640  loss: 1.14495 lr: 0.001000 batch_cost: 0.35634 sec, reader_cost: 0.00231 sec, ips: 44.90089 instance/sec.
[03/04 10:05:09] epoch:[  2/30 ] train step:650  loss: 1.24159 lr: 0.001000 batch_cost: 0.35822 sec, reader_cost: 0.00245 sec, ips: 44.66474 instance/sec.
[03/04 10:05:12] epoch:[  2/30 ] train step:660  loss: 1.33119 lr: 0.001000 batch_cost: 0.35564 sec, reader_cost: 0.00246 sec, ips: 44.98929 instance/sec.
[03/04 10:05:16] epoch:[  2/30 ] train step:670  loss: 1.23387 lr: 0.001000 batch_cost: 0.35584 sec, reader_cost: 0.00252 sec, ips: 44.96412 instance/sec.
[03/04 10:05:19] epoch:[  2/30 ] train step:680  loss: 1.20040 lr: 0.001000 batch_cost: 0.35739 sec, reader_cost: 0.00015 sec, ips: 44.76888 instance/sec.
[03/04 10:05:23] epoch:[  2/30 ] train step:690  loss: 1.16559 lr: 0.001000 batch_cost: 0.35524 sec, reader_cost: 0.00270 sec, ips: 45.03975 instance/sec.
[03/04 10:05:26] epoch:[  2/30 ] train step:700  loss: 0.97356 lr: 0.001000 batch_cost: 0.35574 sec, reader_cost: 0.00025 sec, ips: 44.97693 instance/sec.
[03/04 10:05:30] epoch:[  2/30 ] train step:710  loss: 1.03425 lr: 0.001000 batch_cost: 0.35617 sec, reader_cost: 0.00224 sec, ips: 44.92247 instance/sec.
[03/04 10:05:34] epoch:[  2/30 ] train step:720  loss: 1.50756 lr: 0.001000 batch_cost: 0.35653 sec, reader_cost: 0.00225 sec, ips: 44.87759 instance/sec.
[03/04 10:05:37] epoch:[  2/30 ] train step:730  loss: 1.03851 lr: 0.001000 batch_cost: 0.35813 sec, reader_cost: 0.00232 sec, ips: 44.67696 instance/sec.
[03/04 10:05:41] epoch:[  2/30 ] train step:740  loss: 1.07000 lr: 0.001000 batch_cost: 0.35724 sec, reader_cost: 0.00233 sec, ips: 44.78743 instance/sec.
[03/04 10:05:44] epoch:[  2/30 ] train step:750  loss: 1.08344 lr: 0.001000 batch_cost: 0.35853 sec, reader_cost: 0.00242 sec, ips: 44.62702 instance/sec.
[03/04 10:05:48] epoch:[  2/30 ] train step:760  loss: 1.46105 lr: 0.001000 batch_cost: 0.35549 sec, reader_cost: 0.00229 sec, ips: 45.00830 instance/sec.
[03/04 10:05:51] epoch:[  2/30 ] train step:770  loss: 1.19200 lr: 0.001000 batch_cost: 0.35534 sec, reader_cost: 0.00016 sec, ips: 45.02790 instance/sec.
[03/04 10:05:55] epoch:[  2/30 ] train step:780  loss: 0.85838 lr: 0.001000 batch_cost: 0.35200 sec, reader_cost: 0.00006 sec, ips: 45.45513 instance/sec.
[03/04 10:05:57] END epoch:2   train loss_avg: 1.19596  avg_batch_cost: 0.35033 sec, avg_reader_cost: 0.00005 sec, batch_cost_sum: 281.35903 sec, avg_ips: 44.75421 instance/sec.
[03/04 10:05:59] epoch:[  3/30 ] train step:0    loss: 1.17779 lr: 0.001000 batch_cost: 1.15454 sec, reader_cost: 0.77900 sec, ips: 13.85830 instance/sec.
[03/04 10:06:02] epoch:[  3/30 ] train step:10   loss: 1.01764 lr: 0.001000 batch_cost: 0.36013 sec, reader_cost: 0.00241 sec, ips: 44.42804 instance/sec.
[03/04 10:06:06] epoch:[  3/30 ] train step:20   loss: 0.90438 lr: 0.001000 batch_cost: 0.35664 sec, reader_cost: 0.00228 sec, ips: 44.86324 instance/sec.
[03/04 10:06:09] epoch:[  3/30 ] train step:30   loss: 1.11059 lr: 0.001000 batch_cost: 0.35810 sec, reader_cost: 0.00230 sec, ips: 44.67982 instance/sec.
[03/04 10:06:13] epoch:[  3/30 ] train step:40   loss: 1.25766 lr: 0.001000 batch_cost: 0.35836 sec, reader_cost: 0.00231 sec, ips: 44.64807 instance/sec.
[03/04 10:06:17] epoch:[  3/30 ] train step:50   loss: 1.34332 lr: 0.001000 batch_cost: 0.35627 sec, reader_cost: 0.00017 sec, ips: 44.90981 instance/sec.
[03/04 10:06:20] epoch:[  3/30 ] train step:60   loss: 1.36721 lr: 0.001000 batch_cost: 0.35845 sec, reader_cost: 0.00230 sec, ips: 44.63610 instance/sec.
[03/04 10:06:24] epoch:[  3/30 ] train step:70   loss: 1.11227 lr: 0.001000 batch_cost: 0.35716 sec, reader_cost: 0.00222 sec, ips: 44.79805 instance/sec.
[03/04 10:06:27] epoch:[  3/30 ] train step:80   loss: 1.04907 lr: 0.001000 batch_cost: 0.36030 sec, reader_cost: 0.00219 sec, ips: 44.40690 instance/sec.
[03/04 10:06:31] epoch:[  3/30 ] train step:90   loss: 0.99705 lr: 0.001000 batch_cost: 0.35976 sec, reader_cost: 0.00232 sec, ips: 44.47450 instance/sec.
[03/04 10:06:34] epoch:[  3/30 ] train step:100  loss: 1.02203 lr: 0.001000 batch_cost: 0.35734 sec, reader_cost: 0.00226 sec, ips: 44.77506 instance/sec.
[03/04 10:06:38] epoch:[  3/30 ] train step:110  loss: 1.06909 lr: 0.001000 batch_cost: 0.35901 sec, reader_cost: 0.00219 sec, ips: 44.56665 instance/sec.
[03/04 10:06:42] epoch:[  3/30 ] train step:120  loss: 1.36984 lr: 0.001000 batch_cost: 0.36086 sec, reader_cost: 0.00251 sec, ips: 44.33834 instance/sec.
[03/04 10:06:45] epoch:[  3/30 ] train step:130  loss: 1.58384 lr: 0.001000 batch_cost: 0.35813 sec, reader_cost: 0.00227 sec, ips: 44.67699 instance/sec.
[03/04 10:06:49] epoch:[  3/30 ] train step:140  loss: 0.93987 lr: 0.001000 batch_cost: 0.36373 sec, reader_cost: 0.00246 sec, ips: 43.98902 instance/sec.
[03/04 10:06:52] epoch:[  3/30 ] train step:150  loss: 0.92575 lr: 0.001000 batch_cost: 0.36002 sec, reader_cost: 0.00224 sec, ips: 44.44151 instance/sec.
[03/04 10:06:56] epoch:[  3/30 ] train step:160  loss: 1.02185 lr: 0.001000 batch_cost: 0.35755 sec, reader_cost: 0.00014 sec, ips: 44.74900 instance/sec.
[03/04 10:07:00] epoch:[  3/30 ] train step:170  loss: 0.96769 lr: 0.001000 batch_cost: 0.35858 sec, reader_cost: 0.00225 sec, ips: 44.62061 instance/sec.
[03/04 10:07:03] epoch:[  3/30 ] train step:180  loss: 1.16620 lr: 0.001000 batch_cost: 0.36024 sec, reader_cost: 0.00240 sec, ips: 44.41510 instance/sec.
[03/04 10:07:07] epoch:[  3/30 ] train step:190  loss: 1.20703 lr: 0.001000 batch_cost: 0.35877 sec, reader_cost: 0.00034 sec, ips: 44.59668 instance/sec.
[03/04 10:07:10] epoch:[  3/30 ] train step:200  loss: 1.11441 lr: 0.001000 batch_cost: 0.35929 sec, reader_cost: 0.00230 sec, ips: 44.53288 instance/sec.
[03/04 10:07:14] epoch:[  3/30 ] train step:210  loss: 1.15633 lr: 0.001000 batch_cost: 0.35875 sec, reader_cost: 0.00216 sec, ips: 44.59959 instance/sec.
[03/04 10:07:18] epoch:[  3/30 ] train step:220  loss: 1.04294 lr: 0.001000 batch_cost: 0.35779 sec, reader_cost: 0.00226 sec, ips: 44.71900 instance/sec.
[03/04 10:07:21] epoch:[  3/30 ] train step:230  loss: 1.09733 lr: 0.001000 batch_cost: 0.35803 sec, reader_cost: 0.00016 sec, ips: 44.68866 instance/sec.
[03/04 10:07:25] epoch:[  3/30 ] train step:240  loss: 1.19760 lr: 0.001000 batch_cost: 0.35564 sec, reader_cost: 0.00031 sec, ips: 44.98899 instance/sec.
[03/04 10:07:28] epoch:[  3/30 ] train step:250  loss: 1.02041 lr: 0.001000 batch_cost: 0.35817 sec, reader_cost: 0.00222 sec, ips: 44.67134 instance/sec.
[03/04 10:07:32] epoch:[  3/30 ] train step:260  loss: 1.20250 lr: 0.001000 batch_cost: 0.36026 sec, reader_cost: 0.00220 sec, ips: 44.41240 instance/sec.
[03/04 10:07:36] epoch:[  3/30 ] train step:270  loss: 0.87857 lr: 0.001000 batch_cost: 0.35955 sec, reader_cost: 0.00230 sec, ips: 44.49951 instance/sec.
[03/04 10:07:39] epoch:[  3/30 ] train step:280  loss: 1.45325 lr: 0.001000 batch_cost: 0.35722 sec, reader_cost: 0.00014 sec, ips: 44.79006 instance/sec.
[03/04 10:07:43] epoch:[  3/30 ] train step:290  loss: 1.18667 lr: 0.001000 batch_cost: 0.36065 sec, reader_cost: 0.00222 sec, ips: 44.36466 instance/sec.
[03/04 10:07:46] epoch:[  3/30 ] train step:300  loss: 1.24619 lr: 0.001000 batch_cost: 0.35818 sec, reader_cost: 0.00214 sec, ips: 44.67033 instance/sec.
[03/04 10:07:50] epoch:[  3/30 ] train step:310  loss: 1.07608 lr: 0.001000 batch_cost: 0.35824 sec, reader_cost: 0.00223 sec, ips: 44.66236 instance/sec.
[03/04 10:07:53] epoch:[  3/30 ] train step:320  loss: 0.95047 lr: 0.001000 batch_cost: 0.35896 sec, reader_cost: 0.00014 sec, ips: 44.57370 instance/sec.
[03/04 10:07:57] epoch:[  3/30 ] train step:330  loss: 0.99086 lr: 0.001000 batch_cost: 0.35542 sec, reader_cost: 0.00223 sec, ips: 45.01691 instance/sec.
[03/04 10:08:01] epoch:[  3/30 ] train step:340  loss: 1.00544 lr: 0.001000 batch_cost: 0.35982 sec, reader_cost: 0.00230 sec, ips: 44.46660 instance/sec.
[03/04 10:08:04] epoch:[  3/30 ] train step:350  loss: 1.31535 lr: 0.001000 batch_cost: 0.35702 sec, reader_cost: 0.00219 sec, ips: 44.81594 instance/sec.
[03/04 10:08:08] epoch:[  3/30 ] train step:360  loss: 0.94493 lr: 0.001000 batch_cost: 0.35393 sec, reader_cost: 0.00058 sec, ips: 45.20692 instance/sec.
[03/04 10:08:11] epoch:[  3/30 ] train step:370  loss: 1.11533 lr: 0.001000 batch_cost: 0.36181 sec, reader_cost: 0.00234 sec, ips: 44.22260 instance/sec.
[03/04 10:08:15] epoch:[  3/30 ] train step:380  loss: 1.04266 lr: 0.001000 batch_cost: 0.35793 sec, reader_cost: 0.00233 sec, ips: 44.70095 instance/sec.
[03/04 10:08:19] epoch:[  3/30 ] train step:390  loss: 0.99814 lr: 0.001000 batch_cost: 0.35809 sec, reader_cost: 0.00223 sec, ips: 44.68131 instance/sec.
[03/04 10:08:22] epoch:[  3/30 ] train step:400  loss: 1.01312 lr: 0.001000 batch_cost: 0.36033 sec, reader_cost: 0.00239 sec, ips: 44.40340 instance/sec.
[03/04 10:08:26] epoch:[  3/30 ] train step:410  loss: 1.00803 lr: 0.001000 batch_cost: 0.35872 sec, reader_cost: 0.00237 sec, ips: 44.60317 instance/sec.
[03/04 10:08:29] epoch:[  3/30 ] train step:420  loss: 1.09144 lr: 0.001000 batch_cost: 0.35780 sec, reader_cost: 0.00210 sec, ips: 44.71745 instance/sec.
[03/04 10:08:33] epoch:[  3/30 ] train step:430  loss: 1.22009 lr: 0.001000 batch_cost: 0.35941 sec, reader_cost: 0.00228 sec, ips: 44.51793 instance/sec.
[03/04 10:08:36] epoch:[  3/30 ] train step:440  loss: 1.06922 lr: 0.001000 batch_cost: 0.35521 sec, reader_cost: 0.00014 sec, ips: 45.04401 instance/sec.
[03/04 10:08:40] epoch:[  3/30 ] train step:450  loss: 0.93902 lr: 0.001000 batch_cost: 0.36147 sec, reader_cost: 0.00243 sec, ips: 44.26382 instance/sec.
[03/04 10:08:44] epoch:[  3/30 ] train step:460  loss: 1.18643 lr: 0.001000 batch_cost: 0.36030 sec, reader_cost: 0.00228 sec, ips: 44.40746 instance/sec.
[03/04 10:08:47] epoch:[  3/30 ] train step:470  loss: 1.08976 lr: 0.001000 batch_cost: 0.35912 sec, reader_cost: 0.00235 sec, ips: 44.55363 instance/sec.
[03/04 10:08:51] epoch:[  3/30 ] train step:480  loss: 0.97836 lr: 0.001000 batch_cost: 0.35939 sec, reader_cost: 0.00013 sec, ips: 44.52023 instance/sec.
[03/04 10:08:54] epoch:[  3/30 ] train step:490  loss: 0.88516 lr: 0.001000 batch_cost: 0.35867 sec, reader_cost: 0.00238 sec, ips: 44.60872 instance/sec.
[03/04 10:08:58] epoch:[  3/30 ] train step:500  loss: 0.94721 lr: 0.001000 batch_cost: 0.35728 sec, reader_cost: 0.00223 sec, ips: 44.78313 instance/sec.
[03/04 10:09:02] epoch:[  3/30 ] train step:510  loss: 0.99288 lr: 0.001000 batch_cost: 0.35758 sec, reader_cost: 0.00016 sec, ips: 44.74512 instance/sec.
[03/04 10:09:05] epoch:[  3/30 ] train step:520  loss: 1.49394 lr: 0.001000 batch_cost: 0.35886 sec, reader_cost: 0.00244 sec, ips: 44.58593 instance/sec.
[03/04 10:09:09] epoch:[  3/30 ] train step:530  loss: 1.20623 lr: 0.001000 batch_cost: 0.35812 sec, reader_cost: 0.00236 sec, ips: 44.67780 instance/sec.
[03/04 10:09:12] epoch:[  3/30 ] train step:540  loss: 1.02532 lr: 0.001000 batch_cost: 0.35744 sec, reader_cost: 0.00231 sec, ips: 44.76225 instance/sec.
[03/04 10:09:16] epoch:[  3/30 ] train step:550  loss: 1.05944 lr: 0.001000 batch_cost: 0.35993 sec, reader_cost: 0.00214 sec, ips: 44.45267 instance/sec.
[03/04 10:09:20] epoch:[  3/30 ] train step:560  loss: 0.99268 lr: 0.001000 batch_cost: 0.35866 sec, reader_cost: 0.00014 sec, ips: 44.61094 instance/sec.
[03/04 10:09:23] epoch:[  3/30 ] train step:570  loss: 1.15454 lr: 0.001000 batch_cost: 0.35648 sec, reader_cost: 0.00226 sec, ips: 44.88374 instance/sec.
[03/04 10:09:27] epoch:[  3/30 ] train step:580  loss: 1.03630 lr: 0.001000 batch_cost: 0.35933 sec, reader_cost: 0.00232 sec, ips: 44.52777 instance/sec.
[03/04 10:09:30] epoch:[  3/30 ] train step:590  loss: 1.04182 lr: 0.001000 batch_cost: 0.36046 sec, reader_cost: 0.00232 sec, ips: 44.38713 instance/sec.
[03/04 10:09:34] epoch:[  3/30 ] train step:600  loss: 0.97420 lr: 0.001000 batch_cost: 0.35993 sec, reader_cost: 0.00013 sec, ips: 44.45323 instance/sec.
[03/04 10:09:37] epoch:[  3/30 ] train step:610  loss: 1.01754 lr: 0.001000 batch_cost: 0.35917 sec, reader_cost: 0.00253 sec, ips: 44.54662 instance/sec.
[03/04 10:09:41] epoch:[  3/30 ] train step:620  loss: 1.24615 lr: 0.001000 batch_cost: 0.35975 sec, reader_cost: 0.00231 sec, ips: 44.47574 instance/sec.
[03/04 10:09:45] epoch:[  3/30 ] train step:630  loss: 1.18360 lr: 0.001000 batch_cost: 0.35948 sec, reader_cost: 0.00235 sec, ips: 44.50934 instance/sec.
[03/04 10:09:48] epoch:[  3/30 ] train step:640  loss: 1.38649 lr: 0.001000 batch_cost: 0.35650 sec, reader_cost: 0.00223 sec, ips: 44.88035 instance/sec.
[03/04 10:09:52] epoch:[  3/30 ] train step:650  loss: 1.12213 lr: 0.001000 batch_cost: 0.35874 sec, reader_cost: 0.00234 sec, ips: 44.60110 instance/sec.
[03/04 10:09:55] epoch:[  3/30 ] train step:660  loss: 1.09449 lr: 0.001000 batch_cost: 0.35885 sec, reader_cost: 0.00251 sec, ips: 44.58631 instance/sec.
[03/04 10:09:59] epoch:[  3/30 ] train step:670  loss: 1.01107 lr: 0.001000 batch_cost: 0.35976 sec, reader_cost: 0.00232 sec, ips: 44.47421 instance/sec.
[03/04 10:10:03] epoch:[  3/30 ] train step:680  loss: 1.15672 lr: 0.001000 batch_cost: 0.35571 sec, reader_cost: 0.00246 sec, ips: 44.98064 instance/sec.
[03/04 10:10:06] epoch:[  3/30 ] train step:690  loss: 1.07073 lr: 0.001000 batch_cost: 0.35793 sec, reader_cost: 0.00217 sec, ips: 44.70146 instance/sec.
[03/04 10:10:10] epoch:[  3/30 ] train step:700  loss: 1.37494 lr: 0.001000 batch_cost: 0.35894 sec, reader_cost: 0.00225 sec, ips: 44.57598 instance/sec.
[03/04 10:10:13] epoch:[  3/30 ] train step:710  loss: 1.24758 lr: 0.001000 batch_cost: 0.35857 sec, reader_cost: 0.00246 sec, ips: 44.62168 instance/sec.
[03/04 10:10:17] epoch:[  3/30 ] train step:720  loss: 0.99248 lr: 0.001000 batch_cost: 0.35686 sec, reader_cost: 0.00013 sec, ips: 44.83609 instance/sec.
[03/04 10:10:20] epoch:[  3/30 ] train step:730  loss: 1.36249 lr: 0.001000 batch_cost: 0.35923 sec, reader_cost: 0.00232 sec, ips: 44.53956 instance/sec.
[03/04 10:10:24] epoch:[  3/30 ] train step:740  loss: 0.84402 lr: 0.001000 batch_cost: 0.35921 sec, reader_cost: 0.00222 sec, ips: 44.54172 instance/sec.
[03/04 10:10:28] epoch:[  3/30 ] train step:750  loss: 1.20610 lr: 0.001000 batch_cost: 0.35966 sec, reader_cost: 0.00235 sec, ips: 44.48591 instance/sec.
[03/04 10:10:31] epoch:[  3/30 ] train step:760  loss: 1.09487 lr: 0.001000 batch_cost: 0.35624 sec, reader_cost: 0.00240 sec, ips: 44.91345 instance/sec.
[03/04 10:10:35] epoch:[  3/30 ] train step:770  loss: 1.14410 lr: 0.001000 batch_cost: 0.36029 sec, reader_cost: 0.00223 sec, ips: 44.40928 instance/sec.
[03/04 10:10:38] epoch:[  3/30 ] train step:780  loss: 0.94448 lr: 0.001000 batch_cost: 0.35394 sec, reader_cost: 0.00008 sec, ips: 45.20497 instance/sec.
[03/04 10:10:41] END epoch:3   train loss_avg: 1.10535  avg_batch_cost: 0.35581 sec, avg_reader_cost: 0.00007 sec, batch_cost_sum: 283.00167 sec, avg_ips: 44.49444 instance/sec.
[03/04 10:10:42] epoch:[  4/30 ] train step:0    loss: 1.12634 lr: 0.001000 batch_cost: 1.06707 sec, reader_cost: 0.70539 sec, ips: 14.99431 instance/sec.
[03/04 10:10:46] epoch:[  4/30 ] train step:10   loss: 0.99882 lr: 0.001000 batch_cost: 0.35541 sec, reader_cost: 0.00269 sec, ips: 45.01790 instance/sec.
[03/04 10:10:49] epoch:[  4/30 ] train step:20   loss: 0.84499 lr: 0.001000 batch_cost: 0.35775 sec, reader_cost: 0.00224 sec, ips: 44.72389 instance/sec.
[03/04 10:10:53] epoch:[  4/30 ] train step:30   loss: 1.18805 lr: 0.001000 batch_cost: 0.35548 sec, reader_cost: 0.00015 sec, ips: 45.01002 instance/sec.
[03/04 10:10:56] epoch:[  4/30 ] train step:40   loss: 1.18590 lr: 0.001000 batch_cost: 0.35838 sec, reader_cost: 0.00232 sec, ips: 44.64584 instance/sec.
[03/04 10:11:00] epoch:[  4/30 ] train step:50   loss: 1.10742 lr: 0.001000 batch_cost: 0.36272 sec, reader_cost: 0.00221 sec, ips: 44.11090 instance/sec.
[03/04 10:11:03] epoch:[  4/30 ] train step:60   loss: 0.97570 lr: 0.001000 batch_cost: 0.35754 sec, reader_cost: 0.00018 sec, ips: 44.75013 instance/sec.
[03/04 10:11:07] epoch:[  4/30 ] train step:70   loss: 1.07752 lr: 0.001000 batch_cost: 0.35506 sec, reader_cost: 0.00241 sec, ips: 45.06237 instance/sec.
[03/04 10:11:11] epoch:[  4/30 ] train step:80   loss: 0.87768 lr: 0.001000 batch_cost: 0.35513 sec, reader_cost: 0.00231 sec, ips: 45.05357 instance/sec.
[03/04 10:11:14] epoch:[  4/30 ] train step:90   loss: 0.87318 lr: 0.001000 batch_cost: 0.35538 sec, reader_cost: 0.00234 sec, ips: 45.02189 instance/sec.
[03/04 10:11:18] epoch:[  4/30 ] train step:100  loss: 1.06229 lr: 0.001000 batch_cost: 0.35433 sec, reader_cost: 0.00236 sec, ips: 45.15521 instance/sec.
[03/04 10:11:21] epoch:[  4/30 ] train step:110  loss: 1.53308 lr: 0.001000 batch_cost: 0.35748 sec, reader_cost: 0.00264 sec, ips: 44.75792 instance/sec.
[03/04 10:11:25] epoch:[  4/30 ] train step:120  loss: 0.90629 lr: 0.001000 batch_cost: 0.35544 sec, reader_cost: 0.00221 sec, ips: 45.01416 instance/sec.
[03/04 10:11:28] epoch:[  4/30 ] train step:130  loss: 1.34738 lr: 0.001000 batch_cost: 0.35659 sec, reader_cost: 0.00228 sec, ips: 44.86918 instance/sec.
[03/04 10:11:32] epoch:[  4/30 ] train step:140  loss: 1.44151 lr: 0.001000 batch_cost: 0.35500 sec, reader_cost: 0.00224 sec, ips: 45.07057 instance/sec.
[03/04 10:11:35] epoch:[  4/30 ] train step:150  loss: 0.93334 lr: 0.001000 batch_cost: 0.35964 sec, reader_cost: 0.00252 sec, ips: 44.48839 instance/sec.
[03/04 10:11:39] epoch:[  4/30 ] train step:160  loss: 0.86479 lr: 0.001000 batch_cost: 0.35426 sec, reader_cost: 0.00226 sec, ips: 45.16439 instance/sec.
[03/04 10:11:43] epoch:[  4/30 ] train step:170  loss: 1.19450 lr: 0.001000 batch_cost: 0.35772 sec, reader_cost: 0.00229 sec, ips: 44.72740 instance/sec.
[03/04 10:11:46] epoch:[  4/30 ] train step:180  loss: 1.00384 lr: 0.001000 batch_cost: 0.35334 sec, reader_cost: 0.00222 sec, ips: 45.28190 instance/sec.
[03/04 10:11:50] epoch:[  4/30 ] train step:190  loss: 1.13304 lr: 0.001000 batch_cost: 0.35175 sec, reader_cost: 0.00013 sec, ips: 45.48696 instance/sec.
[03/04 10:11:53] epoch:[  4/30 ] train step:200  loss: 1.04572 lr: 0.001000 batch_cost: 0.35583 sec, reader_cost: 0.00217 sec, ips: 44.96497 instance/sec.
[03/04 10:11:57] epoch:[  4/30 ] train step:210  loss: 1.06696 lr: 0.001000 batch_cost: 0.35453 sec, reader_cost: 0.00230 sec, ips: 45.13022 instance/sec.
[03/04 10:12:00] epoch:[  4/30 ] train step:220  loss: 0.86557 lr: 0.001000 batch_cost: 0.35761 sec, reader_cost: 0.00227 sec, ips: 44.74151 instance/sec.
[03/04 10:12:04] epoch:[  4/30 ] train step:230  loss: 1.50632 lr: 0.001000 batch_cost: 0.35563 sec, reader_cost: 0.00262 sec, ips: 44.99017 instance/sec.
[03/04 10:12:07] epoch:[  4/30 ] train step:240  loss: 1.15617 lr: 0.001000 batch_cost: 0.35752 sec, reader_cost: 0.00239 sec, ips: 44.75216 instance/sec.
[03/04 10:12:11] epoch:[  4/30 ] train step:250  loss: 0.90575 lr: 0.001000 batch_cost: 0.35481 sec, reader_cost: 0.00020 sec, ips: 45.09459 instance/sec.
[03/04 10:12:15] epoch:[  4/30 ] train step:260  loss: 1.20417 lr: 0.001000 batch_cost: 0.35720 sec, reader_cost: 0.00238 sec, ips: 44.79261 instance/sec.
[03/04 10:12:18] epoch:[  4/30 ] train step:270  loss: 0.98595 lr: 0.001000 batch_cost: 0.35492 sec, reader_cost: 0.00267 sec, ips: 45.08035 instance/sec.
[03/04 10:12:22] epoch:[  4/30 ] train step:280  loss: 0.88571 lr: 0.001000 batch_cost: 0.35877 sec, reader_cost: 0.00230 sec, ips: 44.59695 instance/sec.
[03/04 10:12:25] epoch:[  4/30 ] train step:290  loss: 0.96164 lr: 0.001000 batch_cost: 0.35553 sec, reader_cost: 0.00218 sec, ips: 45.00384 instance/sec.
[03/04 10:12:29] epoch:[  4/30 ] train step:300  loss: 1.02552 lr: 0.001000 batch_cost: 0.35558 sec, reader_cost: 0.00237 sec, ips: 44.99723 instance/sec.
[03/04 10:12:32] epoch:[  4/30 ] train step:310  loss: 0.99640 lr: 0.001000 batch_cost: 0.35517 sec, reader_cost: 0.00259 sec, ips: 45.04930 instance/sec.
[03/04 10:12:36] epoch:[  4/30 ] train step:320  loss: 0.89792 lr: 0.001000 batch_cost: 0.35585 sec, reader_cost: 0.00226 sec, ips: 44.96334 instance/sec.
[03/04 10:12:39] epoch:[  4/30 ] train step:330  loss: 0.95000 lr: 0.001000 batch_cost: 0.35891 sec, reader_cost: 0.00227 sec, ips: 44.57965 instance/sec.
[03/04 10:12:43] epoch:[  4/30 ] train step:340  loss: 1.04454 lr: 0.001000 batch_cost: 0.35406 sec, reader_cost: 0.00236 sec, ips: 45.18982 instance/sec.
[03/04 10:12:47] epoch:[  4/30 ] train step:350  loss: 0.83297 lr: 0.001000 batch_cost: 0.35806 sec, reader_cost: 0.00268 sec, ips: 44.68565 instance/sec.
[03/04 10:12:50] epoch:[  4/30 ] train step:360  loss: 0.93819 lr: 0.001000 batch_cost: 0.35516 sec, reader_cost: 0.00229 sec, ips: 45.04991 instance/sec.
[03/04 10:12:54] epoch:[  4/30 ] train step:370  loss: 1.18899 lr: 0.001000 batch_cost: 0.35705 sec, reader_cost: 0.00230 sec, ips: 44.81166 instance/sec.
[03/04 10:12:57] epoch:[  4/30 ] train step:380  loss: 1.04784 lr: 0.001000 batch_cost: 0.35571 sec, reader_cost: 0.00244 sec, ips: 44.98058 instance/sec.
[03/04 10:13:01] epoch:[  4/30 ] train step:390  loss: 0.92847 lr: 0.001000 batch_cost: 0.35234 sec, reader_cost: 0.00012 sec, ips: 45.41099 instance/sec.
[03/04 10:13:04] epoch:[  4/30 ] train step:400  loss: 1.19695 lr: 0.001000 batch_cost: 0.35444 sec, reader_cost: 0.00015 sec, ips: 45.14218 instance/sec.
[03/04 10:13:08] epoch:[  4/30 ] train step:410  loss: 1.12173 lr: 0.001000 batch_cost: 0.35717 sec, reader_cost: 0.00236 sec, ips: 44.79700 instance/sec.
[03/04 10:13:12] epoch:[  4/30 ] train step:420  loss: 1.75238 lr: 0.001000 batch_cost: 0.35584 sec, reader_cost: 0.00218 sec, ips: 44.96451 instance/sec.
[03/04 10:13:15] epoch:[  4/30 ] train step:430  loss: 0.87465 lr: 0.001000 batch_cost: 0.35756 sec, reader_cost: 0.00030 sec, ips: 44.74748 instance/sec.
[03/04 10:13:19] epoch:[  4/30 ] train step:440  loss: 1.01336 lr: 0.001000 batch_cost: 0.35915 sec, reader_cost: 0.00226 sec, ips: 44.54911 instance/sec.
[03/04 10:13:22] epoch:[  4/30 ] train step:450  loss: 0.90490 lr: 0.001000 batch_cost: 0.35516 sec, reader_cost: 0.00016 sec, ips: 45.05018 instance/sec.
[03/04 10:13:26] epoch:[  4/30 ] train step:460  loss: 0.79157 lr: 0.001000 batch_cost: 0.35830 sec, reader_cost: 0.00232 sec, ips: 44.65490 instance/sec.
[03/04 10:13:29] epoch:[  4/30 ] train step:470  loss: 1.07755 lr: 0.001000 batch_cost: 0.35463 sec, reader_cost: 0.00265 sec, ips: 45.11799 instance/sec.
[03/04 10:13:33] epoch:[  4/30 ] train step:480  loss: 0.98417 lr: 0.001000 batch_cost: 0.35686 sec, reader_cost: 0.00230 sec, ips: 44.83510 instance/sec.
[03/04 10:13:36] epoch:[  4/30 ] train step:490  loss: 0.80029 lr: 0.001000 batch_cost: 0.35733 sec, reader_cost: 0.00235 sec, ips: 44.77593 instance/sec.
[03/04 10:13:40] epoch:[  4/30 ] train step:500  loss: 0.90124 lr: 0.001000 batch_cost: 0.35445 sec, reader_cost: 0.00228 sec, ips: 45.14060 instance/sec.
[03/04 10:13:44] epoch:[  4/30 ] train step:510  loss: 1.17868 lr: 0.001000 batch_cost: 0.35654 sec, reader_cost: 0.00260 sec, ips: 44.87608 instance/sec.
[03/04 10:13:47] epoch:[  4/30 ] train step:520  loss: 1.29374 lr: 0.001000 batch_cost: 0.35535 sec, reader_cost: 0.00014 sec, ips: 45.02609 instance/sec.
[03/04 10:13:51] epoch:[  4/30 ] train step:530  loss: 1.02497 lr: 0.001000 batch_cost: 0.35569 sec, reader_cost: 0.00014 sec, ips: 44.98341 instance/sec.
[03/04 10:13:54] epoch:[  4/30 ] train step:540  loss: 1.41453 lr: 0.001000 batch_cost: 0.35490 sec, reader_cost: 0.00239 sec, ips: 45.08335 instance/sec.
[03/04 10:13:58] epoch:[  4/30 ] train step:550  loss: 0.96509 lr: 0.001000 batch_cost: 0.35797 sec, reader_cost: 0.00271 sec, ips: 44.69708 instance/sec.
[03/04 10:14:01] epoch:[  4/30 ] train step:560  loss: 1.14930 lr: 0.001000 batch_cost: 0.35488 sec, reader_cost: 0.00241 sec, ips: 45.08508 instance/sec.
[03/04 10:14:05] epoch:[  4/30 ] train step:570  loss: 0.86923 lr: 0.001000 batch_cost: 0.35506 sec, reader_cost: 0.00234 sec, ips: 45.06273 instance/sec.
[03/04 10:14:08] epoch:[  4/30 ] train step:580  loss: 1.24766 lr: 0.001000 batch_cost: 0.35490 sec, reader_cost: 0.00233 sec, ips: 45.08250 instance/sec.
[03/04 10:14:12] epoch:[  4/30 ] train step:590  loss: 0.75549 lr: 0.001000 batch_cost: 0.35741 sec, reader_cost: 0.00267 sec, ips: 44.76661 instance/sec.
[03/04 10:14:16] epoch:[  4/30 ] train step:600  loss: 1.04409 lr: 0.001000 batch_cost: 0.35741 sec, reader_cost: 0.00239 sec, ips: 44.76688 instance/sec.
[03/04 10:14:19] epoch:[  4/30 ] train step:610  loss: 0.93078 lr: 0.001000 batch_cost: 0.35671 sec, reader_cost: 0.00228 sec, ips: 44.85374 instance/sec.
[03/04 10:14:23] epoch:[  4/30 ] train step:620  loss: 1.01185 lr: 0.001000 batch_cost: 0.35730 sec, reader_cost: 0.00247 sec, ips: 44.77981 instance/sec.
[03/04 10:14:26] epoch:[  4/30 ] train step:630  loss: 1.39956 lr: 0.001000 batch_cost: 0.35440 sec, reader_cost: 0.00254 sec, ips: 45.14725 instance/sec.
[03/04 10:14:30] epoch:[  4/30 ] train step:640  loss: 1.03577 lr: 0.001000 batch_cost: 0.35939 sec, reader_cost: 0.00220 sec, ips: 44.51961 instance/sec.
[03/04 10:14:33] epoch:[  4/30 ] train step:650  loss: 1.71071 lr: 0.001000 batch_cost: 0.35490 sec, reader_cost: 0.00015 sec, ips: 45.08268 instance/sec.
[03/04 10:14:37] epoch:[  4/30 ] train step:660  loss: 1.35772 lr: 0.001000 batch_cost: 0.35584 sec, reader_cost: 0.00235 sec, ips: 44.96364 instance/sec.
[03/04 10:14:40] epoch:[  4/30 ] train step:670  loss: 0.92565 lr: 0.001000 batch_cost: 0.35612 sec, reader_cost: 0.00259 sec, ips: 44.92815 instance/sec.
[03/04 10:14:44] epoch:[  4/30 ] train step:680  loss: 1.14824 lr: 0.001000 batch_cost: 0.35598 sec, reader_cost: 0.00226 sec, ips: 44.94596 instance/sec.
[03/04 10:14:48] epoch:[  4/30 ] train step:690  loss: 0.86791 lr: 0.001000 batch_cost: 0.35432 sec, reader_cost: 0.00230 sec, ips: 45.15664 instance/sec.
[03/04 10:14:51] epoch:[  4/30 ] train step:700  loss: 0.98444 lr: 0.001000 batch_cost: 0.35359 sec, reader_cost: 0.00244 sec, ips: 45.25039 instance/sec.
[03/04 10:14:55] epoch:[  4/30 ] train step:710  loss: 0.81247 lr: 0.001000 batch_cost: 0.35516 sec, reader_cost: 0.00254 sec, ips: 45.05012 instance/sec.
[03/04 10:14:58] epoch:[  4/30 ] train step:720  loss: 1.01996 lr: 0.001000 batch_cost: 0.35548 sec, reader_cost: 0.00220 sec, ips: 45.00972 instance/sec.
[03/04 10:15:02] epoch:[  4/30 ] train step:730  loss: 1.40872 lr: 0.001000 batch_cost: 0.35741 sec, reader_cost: 0.00248 sec, ips: 44.76595 instance/sec.
[03/04 10:15:05] epoch:[  4/30 ] train step:740  loss: 0.96142 lr: 0.001000 batch_cost: 0.35435 sec, reader_cost: 0.00248 sec, ips: 45.15357 instance/sec.
[03/04 10:15:09] epoch:[  4/30 ] train step:750  loss: 0.95356 lr: 0.001000 batch_cost: 0.35766 sec, reader_cost: 0.00261 sec, ips: 44.73486 instance/sec.
[03/04 10:15:13] epoch:[  4/30 ] train step:760  loss: 0.83513 lr: 0.001000 batch_cost: 0.35466 sec, reader_cost: 0.00240 sec, ips: 45.11396 instance/sec.
[03/04 10:15:16] epoch:[  4/30 ] train step:770  loss: 0.79666 lr: 0.001000 batch_cost: 0.35585 sec, reader_cost: 0.00273 sec, ips: 44.96289 instance/sec.
[03/04 10:15:20] epoch:[  4/30 ] train step:780  loss: 1.37948 lr: 0.001000 batch_cost: 0.35151 sec, reader_cost: 0.00005 sec, ips: 45.51766 instance/sec.
[03/04 10:15:22] END epoch:4   train loss_avg: 1.05718  avg_batch_cost: 0.35312 sec, avg_reader_cost: 0.00005 sec, batch_cost_sum: 280.75481 sec, avg_ips: 44.85052 instance/sec.
[03/04 10:15:23] epoch:[  5/30 ] train step:0    loss: 0.85391 lr: 0.001000 batch_cost: 1.05075 sec, reader_cost: 0.68338 sec, ips: 15.22717 instance/sec.
[03/04 10:15:27] epoch:[  5/30 ] train step:10   loss: 1.00726 lr: 0.001000 batch_cost: 0.35706 sec, reader_cost: 0.00218 sec, ips: 44.81049 instance/sec.
[03/04 10:15:30] epoch:[  5/30 ] train step:20   loss: 1.14107 lr: 0.001000 batch_cost: 0.35685 sec, reader_cost: 0.00210 sec, ips: 44.83696 instance/sec.
[03/04 10:15:34] epoch:[  5/30 ] train step:30   loss: 1.08769 lr: 0.001000 batch_cost: 0.35910 sec, reader_cost: 0.00226 sec, ips: 44.55579 instance/sec.
[03/04 10:15:37] epoch:[  5/30 ] train step:40   loss: 0.89004 lr: 0.001000 batch_cost: 0.35461 sec, reader_cost: 0.00249 sec, ips: 45.11984 instance/sec.
[03/04 10:15:41] epoch:[  5/30 ] train step:50   loss: 0.95923 lr: 0.001000 batch_cost: 0.35473 sec, reader_cost: 0.00229 sec, ips: 45.10410 instance/sec.
[03/04 10:15:45] epoch:[  5/30 ] train step:60   loss: 1.11551 lr: 0.001000 batch_cost: 0.35599 sec, reader_cost: 0.00218 sec, ips: 44.94473 instance/sec.
[03/04 10:15:48] epoch:[  5/30 ] train step:70   loss: 0.97988 lr: 0.001000 batch_cost: 0.35360 sec, reader_cost: 0.00017 sec, ips: 45.24829 instance/sec.
[03/04 10:15:52] epoch:[  5/30 ] train step:80   loss: 0.91615 lr: 0.001000 batch_cost: 0.35371 sec, reader_cost: 0.00011 sec, ips: 45.23502 instance/sec.
[03/04 10:15:55] epoch:[  5/30 ] train step:90   loss: 0.75380 lr: 0.001000 batch_cost: 0.35580 sec, reader_cost: 0.00211 sec, ips: 44.96876 instance/sec.
[03/04 10:15:59] epoch:[  5/30 ] train step:100  loss: 1.04495 lr: 0.001000 batch_cost: 0.35807 sec, reader_cost: 0.00229 sec, ips: 44.68401 instance/sec.
[03/04 10:16:02] epoch:[  5/30 ] train step:110  loss: 1.30216 lr: 0.001000 batch_cost: 0.35618 sec, reader_cost: 0.00016 sec, ips: 44.92156 instance/sec.
[03/04 10:16:06] epoch:[  5/30 ] train step:120  loss: 0.89921 lr: 0.001000 batch_cost: 0.35852 sec, reader_cost: 0.00015 sec, ips: 44.62797 instance/sec.
[03/04 10:16:09] epoch:[  5/30 ] train step:130  loss: 1.38090 lr: 0.001000 batch_cost: 0.35520 sec, reader_cost: 0.00219 sec, ips: 45.04462 instance/sec.
[03/04 10:16:13] epoch:[  5/30 ] train step:140  loss: 1.29003 lr: 0.001000 batch_cost: 0.35820 sec, reader_cost: 0.00226 sec, ips: 44.66822 instance/sec.
[03/04 10:16:17] epoch:[  5/30 ] train step:150  loss: 0.96668 lr: 0.001000 batch_cost: 0.35597 sec, reader_cost: 0.00235 sec, ips: 44.94711 instance/sec.
[03/04 10:16:20] epoch:[  5/30 ] train step:160  loss: 0.88952 lr: 0.001000 batch_cost: 0.35404 sec, reader_cost: 0.00012 sec, ips: 45.19310 instance/sec.
[03/04 10:16:24] epoch:[  5/30 ] train step:170  loss: 1.05370 lr: 0.001000 batch_cost: 0.35672 sec, reader_cost: 0.00231 sec, ips: 44.85254 instance/sec.
[03/04 10:16:27] epoch:[  5/30 ] train step:180  loss: 1.01472 lr: 0.001000 batch_cost: 0.35536 sec, reader_cost: 0.00232 sec, ips: 45.02455 instance/sec.
[03/04 10:16:31] epoch:[  5/30 ] train step:190  loss: 1.17200 lr: 0.001000 batch_cost: 0.35652 sec, reader_cost: 0.00248 sec, ips: 44.87846 instance/sec.
[03/04 10:16:34] epoch:[  5/30 ] train step:200  loss: 1.10309 lr: 0.001000 batch_cost: 0.35379 sec, reader_cost: 0.00251 sec, ips: 45.22438 instance/sec.
[03/04 10:16:38] epoch:[  5/30 ] train step:210  loss: 0.94758 lr: 0.001000 batch_cost: 0.35775 sec, reader_cost: 0.00224 sec, ips: 44.72341 instance/sec.
[03/04 10:16:42] epoch:[  5/30 ] train step:220  loss: 0.93629 lr: 0.001000 batch_cost: 0.35780 sec, reader_cost: 0.00234 sec, ips: 44.71715 instance/sec.
[03/04 10:16:45] epoch:[  5/30 ] train step:230  loss: 1.15937 lr: 0.001000 batch_cost: 0.35778 sec, reader_cost: 0.00215 sec, ips: 44.72079 instance/sec.
[03/04 10:16:49] epoch:[  5/30 ] train step:240  loss: 1.14679 lr: 0.001000 batch_cost: 0.35191 sec, reader_cost: 0.00012 sec, ips: 45.46560 instance/sec.
[03/04 10:16:52] epoch:[  5/30 ] train step:250  loss: 0.91579 lr: 0.001000 batch_cost: 0.35888 sec, reader_cost: 0.00242 sec, ips: 44.58270 instance/sec.
[03/04 10:16:56] epoch:[  5/30 ] train step:260  loss: 0.83935 lr: 0.001000 batch_cost: 0.35518 sec, reader_cost: 0.00216 sec, ips: 45.04764 instance/sec.
[03/04 10:16:59] epoch:[  5/30 ] train step:270  loss: 0.93374 lr: 0.001000 batch_cost: 0.35565 sec, reader_cost: 0.00227 sec, ips: 44.98779 instance/sec.
[03/04 10:17:03] epoch:[  5/30 ] train step:280  loss: 0.85999 lr: 0.001000 batch_cost: 0.35268 sec, reader_cost: 0.00013 sec, ips: 45.36715 instance/sec.
[03/04 10:17:06] epoch:[  5/30 ] train step:290  loss: 0.94126 lr: 0.001000 batch_cost: 0.35596 sec, reader_cost: 0.00227 sec, ips: 44.94843 instance/sec.
[03/04 10:17:10] epoch:[  5/30 ] train step:300  loss: 1.07924 lr: 0.001000 batch_cost: 0.35575 sec, reader_cost: 0.00224 sec, ips: 44.97485 instance/sec.
[03/04 10:17:14] epoch:[  5/30 ] train step:310  loss: 0.99380 lr: 0.001000 batch_cost: 0.36069 sec, reader_cost: 0.00243 sec, ips: 44.35909 instance/sec.
[03/04 10:17:17] epoch:[  5/30 ] train step:320  loss: 0.95623 lr: 0.001000 batch_cost: 0.35744 sec, reader_cost: 0.00270 sec, ips: 44.76315 instance/sec.
[03/04 10:17:21] epoch:[  5/30 ] train step:330  loss: 1.53026 lr: 0.001000 batch_cost: 0.35453 sec, reader_cost: 0.00245 sec, ips: 45.13046 instance/sec.
[03/04 10:17:24] epoch:[  5/30 ] train step:340  loss: 1.01518 lr: 0.001000 batch_cost: 0.35674 sec, reader_cost: 0.00237 sec, ips: 44.85032 instance/sec.
[03/04 10:17:28] epoch:[  5/30 ] train step:350  loss: 1.35233 lr: 0.001000 batch_cost: 0.35528 sec, reader_cost: 0.00017 sec, ips: 45.03503 instance/sec.
[03/04 10:17:31] epoch:[  5/30 ] train step:360  loss: 0.95770 lr: 0.001000 batch_cost: 0.35379 sec, reader_cost: 0.00255 sec, ips: 45.22502 instance/sec.
[03/04 10:17:35] epoch:[  5/30 ] train step:370  loss: 0.80981 lr: 0.001000 batch_cost: 0.35510 sec, reader_cost: 0.00019 sec, ips: 45.05744 instance/sec.
[03/04 10:17:38] epoch:[  5/30 ] train step:380  loss: 0.96797 lr: 0.001000 batch_cost: 0.35490 sec, reader_cost: 0.00224 sec, ips: 45.08271 instance/sec.
[03/04 10:17:42] epoch:[  5/30 ] train step:390  loss: 0.90367 lr: 0.001000 batch_cost: 0.35524 sec, reader_cost: 0.00015 sec, ips: 45.04023 instance/sec.
[03/04 10:17:46] epoch:[  5/30 ] train step:400  loss: 1.22691 lr: 0.001000 batch_cost: 0.35418 sec, reader_cost: 0.00263 sec, ips: 45.17518 instance/sec.
[03/04 10:17:49] epoch:[  5/30 ] train step:410  loss: 1.10163 lr: 0.001000 batch_cost: 0.35657 sec, reader_cost: 0.00227 sec, ips: 44.87230 instance/sec.
[03/04 10:17:53] epoch:[  5/30 ] train step:420  loss: 0.99840 lr: 0.001000 batch_cost: 0.35469 sec, reader_cost: 0.00018 sec, ips: 45.11035 instance/sec.
[03/04 10:17:56] epoch:[  5/30 ] train step:430  loss: 1.09622 lr: 0.001000 batch_cost: 0.35783 sec, reader_cost: 0.00015 sec, ips: 44.71414 instance/sec.
[03/04 10:18:00] epoch:[  5/30 ] train step:440  loss: 0.90886 lr: 0.001000 batch_cost: 0.35563 sec, reader_cost: 0.00269 sec, ips: 44.99080 instance/sec.
[03/04 10:18:03] epoch:[  5/30 ] train step:450  loss: 1.01959 lr: 0.001000 batch_cost: 0.35613 sec, reader_cost: 0.00228 sec, ips: 44.92737 instance/sec.
[03/04 10:18:07] epoch:[  5/30 ] train step:460  loss: 1.11273 lr: 0.001000 batch_cost: 0.35569 sec, reader_cost: 0.00016 sec, ips: 44.98344 instance/sec.
[03/04 10:18:10] epoch:[  5/30 ] train step:470  loss: 0.92732 lr: 0.001000 batch_cost: 0.35637 sec, reader_cost: 0.00239 sec, ips: 44.89704 instance/sec.
[03/04 10:18:14] epoch:[  5/30 ] train step:480  loss: 1.03439 lr: 0.001000 batch_cost: 0.35448 sec, reader_cost: 0.00272 sec, ips: 45.13644 instance/sec.
[03/04 10:18:18] epoch:[  5/30 ] train step:490  loss: 0.80289 lr: 0.001000 batch_cost: 0.35407 sec, reader_cost: 0.00016 sec, ips: 45.18826 instance/sec.
[03/04 10:18:21] epoch:[  5/30 ] train step:500  loss: 0.70738 lr: 0.001000 batch_cost: 0.35660 sec, reader_cost: 0.00015 sec, ips: 44.86855 instance/sec.
[03/04 10:18:25] epoch:[  5/30 ] train step:510  loss: 1.04458 lr: 0.001000 batch_cost: 0.35493 sec, reader_cost: 0.00027 sec, ips: 45.07987 instance/sec.
[03/04 10:18:28] epoch:[  5/30 ] train step:520  loss: 0.99414 lr: 0.001000 batch_cost: 0.35589 sec, reader_cost: 0.00011 sec, ips: 44.95792 instance/sec.
[03/04 10:18:32] epoch:[  5/30 ] train step:530  loss: 0.91708 lr: 0.001000 batch_cost: 0.35526 sec, reader_cost: 0.00225 sec, ips: 45.03766 instance/sec.
[03/04 10:18:35] epoch:[  5/30 ] train step:540  loss: 0.79855 lr: 0.001000 batch_cost: 0.35694 sec, reader_cost: 0.00012 sec, ips: 44.82582 instance/sec.
[03/04 10:18:39] epoch:[  5/30 ] train step:550  loss: 1.29895 lr: 0.001000 batch_cost: 0.35654 sec, reader_cost: 0.00221 sec, ips: 44.87611 instance/sec.
[03/04 10:18:42] epoch:[  5/30 ] train step:560  loss: 1.15710 lr: 0.001000 batch_cost: 0.35504 sec, reader_cost: 0.00273 sec, ips: 45.06591 instance/sec.
[03/04 10:18:46] epoch:[  5/30 ] train step:570  loss: 1.03588 lr: 0.001000 batch_cost: 0.35487 sec, reader_cost: 0.00016 sec, ips: 45.08723 instance/sec.
[03/04 10:18:50] epoch:[  5/30 ] train step:580  loss: 0.99840 lr: 0.001000 batch_cost: 0.35540 sec, reader_cost: 0.00015 sec, ips: 45.01935 instance/sec.
[03/04 10:18:53] epoch:[  5/30 ] train step:590  loss: 0.91233 lr: 0.001000 batch_cost: 0.35378 sec, reader_cost: 0.00016 sec, ips: 45.22554 instance/sec.
[03/04 10:18:57] epoch:[  5/30 ] train step:600  loss: 1.23311 lr: 0.001000 batch_cost: 0.35406 sec, reader_cost: 0.00256 sec, ips: 45.19021 instance/sec.
[03/04 10:19:00] epoch:[  5/30 ] train step:610  loss: 0.90047 lr: 0.001000 batch_cost: 0.35786 sec, reader_cost: 0.00230 sec, ips: 44.71000 instance/sec.
[03/04 10:19:04] epoch:[  5/30 ] train step:620  loss: 0.90943 lr: 0.001000 batch_cost: 0.35609 sec, reader_cost: 0.00233 sec, ips: 44.93206 instance/sec.
[03/04 10:19:07] epoch:[  5/30 ] train step:630  loss: 1.01923 lr: 0.001000 batch_cost: 0.35513 sec, reader_cost: 0.00012 sec, ips: 45.05384 instance/sec.
[03/04 10:19:11] epoch:[  5/30 ] train step:640  loss: 1.03499 lr: 0.001000 batch_cost: 0.35490 sec, reader_cost: 0.00269 sec, ips: 45.08317 instance/sec.
[03/04 10:19:15] epoch:[  5/30 ] train step:650  loss: 0.90835 lr: 0.001000 batch_cost: 0.35802 sec, reader_cost: 0.00223 sec, ips: 44.69059 instance/sec.
[03/04 10:19:18] epoch:[  5/30 ] train step:660  loss: 0.88047 lr: 0.001000 batch_cost: 0.35585 sec, reader_cost: 0.00231 sec, ips: 44.96253 instance/sec.
[03/04 10:19:22] epoch:[  5/30 ] train step:670  loss: 1.12477 lr: 0.001000 batch_cost: 0.35478 sec, reader_cost: 0.00016 sec, ips: 45.09865 instance/sec.
[03/04 10:19:25] epoch:[  5/30 ] train step:680  loss: 0.97051 lr: 0.001000 batch_cost: 0.35430 sec, reader_cost: 0.00269 sec, ips: 45.15938 instance/sec.
[03/04 10:19:29] epoch:[  5/30 ] train step:690  loss: 0.94959 lr: 0.001000 batch_cost: 0.35494 sec, reader_cost: 0.00016 sec, ips: 45.07844 instance/sec.
[03/04 10:19:32] epoch:[  5/30 ] train step:700  loss: 0.87067 lr: 0.001000 batch_cost: 0.35513 sec, reader_cost: 0.00018 sec, ips: 45.05417 instance/sec.
[03/04 10:19:36] epoch:[  5/30 ] train step:710  loss: 0.83115 lr: 0.001000 batch_cost: 0.35740 sec, reader_cost: 0.00277 sec, ips: 44.76807 instance/sec.
[03/04 10:19:39] epoch:[  5/30 ] train step:720  loss: 1.11011 lr: 0.001000 batch_cost: 0.35618 sec, reader_cost: 0.00272 sec, ips: 44.92048 instance/sec.
[03/04 10:19:43] epoch:[  5/30 ] train step:730  loss: 0.89325 lr: 0.001000 batch_cost: 0.35356 sec, reader_cost: 0.00041 sec, ips: 45.25344 instance/sec.
[03/04 10:19:47] epoch:[  5/30 ] train step:740  loss: 1.25758 lr: 0.001000 batch_cost: 0.35609 sec, reader_cost: 0.00016 sec, ips: 44.93284 instance/sec.
[03/04 10:19:50] epoch:[  5/30 ] train step:750  loss: 1.28485 lr: 0.001000 batch_cost: 0.35566 sec, reader_cost: 0.00015 sec, ips: 44.98649 instance/sec.
[03/04 10:19:54] epoch:[  5/30 ] train step:760  loss: 1.03252 lr: 0.001000 batch_cost: 0.35792 sec, reader_cost: 0.00269 sec, ips: 44.70321 instance/sec.
[03/04 10:19:57] epoch:[  5/30 ] train step:770  loss: 0.94714 lr: 0.001000 batch_cost: 0.35630 sec, reader_cost: 0.00224 sec, ips: 44.90551 instance/sec.
[03/04 10:20:01] epoch:[  5/30 ] train step:780  loss: 0.87030 lr: 0.001000 batch_cost: 0.35334 sec, reader_cost: 0.00007 sec, ips: 45.28211 instance/sec.
[03/04 10:20:03] END epoch:5   train loss_avg: 1.02941  avg_batch_cost: 0.35049 sec, avg_reader_cost: 0.00005 sec, batch_cost_sum: 280.65978 sec, avg_ips: 44.86571 instance/sec.
[03/04 10:20:05] epoch:[  6/30 ] train step:0    loss: 0.90692 lr: 0.001000 batch_cost: 1.16163 sec, reader_cost: 0.79304 sec, ips: 13.77379 instance/sec.
[03/04 10:20:08] epoch:[  6/30 ] train step:10   loss: 0.77170 lr: 0.001000 batch_cost: 0.35476 sec, reader_cost: 0.00018 sec, ips: 45.10062 instance/sec.
[03/04 10:20:12] epoch:[  6/30 ] train step:20   loss: 0.87640 lr: 0.001000 batch_cost: 0.35575 sec, reader_cost: 0.00017 sec, ips: 44.97566 instance/sec.
[03/04 10:20:15] epoch:[  6/30 ] train step:30   loss: 1.00907 lr: 0.001000 batch_cost: 0.35571 sec, reader_cost: 0.00013 sec, ips: 44.98040 instance/sec.
[03/04 10:20:19] epoch:[  6/30 ] train step:40   loss: 1.00509 lr: 0.001000 batch_cost: 0.35430 sec, reader_cost: 0.00224 sec, ips: 45.16007 instance/sec.
[03/04 10:20:22] epoch:[  6/30 ] train step:50   loss: 1.04760 lr: 0.001000 batch_cost: 0.35592 sec, reader_cost: 0.00213 sec, ips: 44.95352 instance/sec.
[03/04 10:20:26] epoch:[  6/30 ] train step:60   loss: 0.98054 lr: 0.001000 batch_cost: 0.35564 sec, reader_cost: 0.00224 sec, ips: 44.98887 instance/sec.
[03/04 10:20:29] epoch:[  6/30 ] train step:70   loss: 1.14472 lr: 0.001000 batch_cost: 0.35287 sec, reader_cost: 0.00011 sec, ips: 45.34260 instance/sec.
[03/04 10:20:33] epoch:[  6/30 ] train step:80   loss: 1.03614 lr: 0.001000 batch_cost: 0.35702 sec, reader_cost: 0.00227 sec, ips: 44.81597 instance/sec.
[03/04 10:20:37] epoch:[  6/30 ] train step:90   loss: 0.83397 lr: 0.001000 batch_cost: 0.35300 sec, reader_cost: 0.00011 sec, ips: 45.32573 instance/sec.
[03/04 10:20:40] epoch:[  6/30 ] train step:100  loss: 0.92787 lr: 0.001000 batch_cost: 0.36865 sec, reader_cost: 0.00250 sec, ips: 43.40107 instance/sec.
[03/04 10:20:44] epoch:[  6/30 ] train step:110  loss: 0.95338 lr: 0.001000 batch_cost: 0.35268 sec, reader_cost: 0.00014 sec, ips: 45.36651 instance/sec.
[03/04 10:20:47] epoch:[  6/30 ] train step:120  loss: 0.95482 lr: 0.001000 batch_cost: 0.35809 sec, reader_cost: 0.00018 sec, ips: 44.68119 instance/sec.
[03/04 10:20:51] epoch:[  6/30 ] train step:130  loss: 0.78520 lr: 0.001000 batch_cost: 0.35777 sec, reader_cost: 0.00212 sec, ips: 44.72195 instance/sec.
[03/04 10:20:54] epoch:[  6/30 ] train step:140  loss: 0.98589 lr: 0.001000 batch_cost: 0.35607 sec, reader_cost: 0.00224 sec, ips: 44.93474 instance/sec.
[03/04 10:20:58] epoch:[  6/30 ] train step:150  loss: 1.14367 lr: 0.001000 batch_cost: 0.35441 sec, reader_cost: 0.00014 sec, ips: 45.14482 instance/sec.
[03/04 10:21:01] epoch:[  6/30 ] train step:160  loss: 1.70551 lr: 0.001000 batch_cost: 0.35502 sec, reader_cost: 0.00232 sec, ips: 45.06770 instance/sec.
[03/04 10:21:05] epoch:[  6/30 ] train step:170  loss: 0.90131 lr: 0.001000 batch_cost: 0.35766 sec, reader_cost: 0.00226 sec, ips: 44.73569 instance/sec.
[03/04 10:21:09] epoch:[  6/30 ] train step:180  loss: 1.07554 lr: 0.001000 batch_cost: 0.35554 sec, reader_cost: 0.00242 sec, ips: 45.00148 instance/sec.
[03/04 10:21:12] epoch:[  6/30 ] train step:190  loss: 0.93085 lr: 0.001000 batch_cost: 0.35747 sec, reader_cost: 0.00225 sec, ips: 44.75909 instance/sec.
[03/04 10:21:16] epoch:[  6/30 ] train step:200  loss: 0.81061 lr: 0.001000 batch_cost: 0.35559 sec, reader_cost: 0.00015 sec, ips: 44.99515 instance/sec.
[03/04 10:21:19] epoch:[  6/30 ] train step:210  loss: 1.06856 lr: 0.001000 batch_cost: 0.35680 sec, reader_cost: 0.00225 sec, ips: 44.84340 instance/sec.
[03/04 10:21:23] epoch:[  6/30 ] train step:220  loss: 1.30817 lr: 0.001000 batch_cost: 0.35681 sec, reader_cost: 0.00226 sec, ips: 44.84208 instance/sec.
[03/04 10:21:26] epoch:[  6/30 ] train step:230  loss: 0.81747 lr: 0.001000 batch_cost: 0.35460 sec, reader_cost: 0.00241 sec, ips: 45.12081 instance/sec.
[03/04 10:21:30] epoch:[  6/30 ] train step:240  loss: 0.82793 lr: 0.001000 batch_cost: 0.35556 sec, reader_cost: 0.00233 sec, ips: 44.99982 instance/sec.
[03/04 10:21:34] epoch:[  6/30 ] train step:250  loss: 0.94953 lr: 0.001000 batch_cost: 0.35555 sec, reader_cost: 0.00231 sec, ips: 45.00112 instance/sec.
[03/04 10:21:37] epoch:[  6/30 ] train step:260  loss: 0.86019 lr: 0.001000 batch_cost: 0.35734 sec, reader_cost: 0.00245 sec, ips: 44.77527 instance/sec.
[03/04 10:21:41] epoch:[  6/30 ] train step:270  loss: 1.23458 lr: 0.001000 batch_cost: 0.35523 sec, reader_cost: 0.00011 sec, ips: 45.04062 instance/sec.
[03/04 10:21:44] epoch:[  6/30 ] train step:280  loss: 0.79552 lr: 0.001000 batch_cost: 0.35927 sec, reader_cost: 0.00232 sec, ips: 44.53495 instance/sec.
[03/04 10:21:48] epoch:[  6/30 ] train step:290  loss: 0.98296 lr: 0.001000 batch_cost: 0.35467 sec, reader_cost: 0.00227 sec, ips: 45.11256 instance/sec.
[03/04 10:21:51] epoch:[  6/30 ] train step:300  loss: 1.01403 lr: 0.001000 batch_cost: 0.35527 sec, reader_cost: 0.00248 sec, ips: 45.03606 instance/sec.
[03/04 10:21:55] epoch:[  6/30 ] train step:310  loss: 1.01880 lr: 0.001000 batch_cost: 0.35524 sec, reader_cost: 0.00239 sec, ips: 45.04011 instance/sec.
[03/04 10:21:58] epoch:[  6/30 ] train step:320  loss: 0.86037 lr: 0.001000 batch_cost: 0.35749 sec, reader_cost: 0.00232 sec, ips: 44.75601 instance/sec.
[03/04 10:22:02] epoch:[  6/30 ] train step:330  loss: 1.01616 lr: 0.001000 batch_cost: 0.35741 sec, reader_cost: 0.00218 sec, ips: 44.76655 instance/sec.
[03/04 10:22:06] epoch:[  6/30 ] train step:340  loss: 1.09791 lr: 0.001000 batch_cost: 0.35753 sec, reader_cost: 0.00253 sec, ips: 44.75112 instance/sec.
[03/04 10:22:09] epoch:[  6/30 ] train step:350  loss: 0.86671 lr: 0.001000 batch_cost: 0.35867 sec, reader_cost: 0.00222 sec, ips: 44.60928 instance/sec.
[03/04 10:22:13] epoch:[  6/30 ] train step:360  loss: 0.94239 lr: 0.001000 batch_cost: 0.35577 sec, reader_cost: 0.00228 sec, ips: 44.97229 instance/sec.
[03/04 10:22:16] epoch:[  6/30 ] train step:370  loss: 1.04107 lr: 0.001000 batch_cost: 0.35868 sec, reader_cost: 0.00218 sec, ips: 44.60833 instance/sec.
[03/04 10:22:20] epoch:[  6/30 ] train step:380  loss: 1.15533 lr: 0.001000 batch_cost: 0.35540 sec, reader_cost: 0.00017 sec, ips: 45.02029 instance/sec.
[03/04 10:22:23] epoch:[  6/30 ] train step:390  loss: 1.18592 lr: 0.001000 batch_cost: 0.35494 sec, reader_cost: 0.00241 sec, ips: 45.07772 instance/sec.
[03/04 10:22:27] epoch:[  6/30 ] train step:400  loss: 1.18479 lr: 0.001000 batch_cost: 0.35699 sec, reader_cost: 0.00015 sec, ips: 44.81890 instance/sec.
[03/04 10:22:31] epoch:[  6/30 ] train step:410  loss: 1.56466 lr: 0.001000 batch_cost: 0.35576 sec, reader_cost: 0.00234 sec, ips: 44.97458 instance/sec.
[03/04 10:22:34] epoch:[  6/30 ] train step:420  loss: 0.85481 lr: 0.001000 batch_cost: 0.35598 sec, reader_cost: 0.00017 sec, ips: 44.94605 instance/sec.
[03/04 10:22:38] epoch:[  6/30 ] train step:430  loss: 0.92378 lr: 0.001000 batch_cost: 0.35563 sec, reader_cost: 0.00235 sec, ips: 44.99074 instance/sec.
[03/04 10:22:41] epoch:[  6/30 ] train step:440  loss: 0.90939 lr: 0.001000 batch_cost: 0.35633 sec, reader_cost: 0.00236 sec, ips: 44.90281 instance/sec.
[03/04 10:22:45] epoch:[  6/30 ] train step:450  loss: 1.03531 lr: 0.001000 batch_cost: 0.35651 sec, reader_cost: 0.00251 sec, ips: 44.87954 instance/sec.
[03/04 10:22:48] epoch:[  6/30 ] train step:460  loss: 1.30611 lr: 0.001000 batch_cost: 0.35941 sec, reader_cost: 0.00225 sec, ips: 44.51781 instance/sec.
[03/04 10:22:52] epoch:[  6/30 ] train step:470  loss: 0.88114 lr: 0.001000 batch_cost: 0.35527 sec, reader_cost: 0.00249 sec, ips: 45.03585 instance/sec.
[03/04 10:22:55] epoch:[  6/30 ] train step:480  loss: 0.84979 lr: 0.001000 batch_cost: 0.35475 sec, reader_cost: 0.00223 sec, ips: 45.10277 instance/sec.
[03/04 10:22:59] epoch:[  6/30 ] train step:490  loss: 0.94035 lr: 0.001000 batch_cost: 0.35728 sec, reader_cost: 0.00229 sec, ips: 44.78256 instance/sec.
[03/04 10:23:03] epoch:[  6/30 ] train step:500  loss: 0.98975 lr: 0.001000 batch_cost: 0.35611 sec, reader_cost: 0.00018 sec, ips: 44.92956 instance/sec.
[03/04 10:23:06] epoch:[  6/30 ] train step:510  loss: 0.87612 lr: 0.001000 batch_cost: 0.35744 sec, reader_cost: 0.00244 sec, ips: 44.76330 instance/sec.
[03/04 10:23:10] epoch:[  6/30 ] train step:520  loss: 0.69334 lr: 0.001000 batch_cost: 0.35836 sec, reader_cost: 0.00236 sec, ips: 44.64816 instance/sec.
[03/04 10:23:13] epoch:[  6/30 ] train step:530  loss: 0.89979 lr: 0.001000 batch_cost: 0.35960 sec, reader_cost: 0.00236 sec, ips: 44.49364 instance/sec.
[03/04 10:23:17] epoch:[  6/30 ] train step:540  loss: 2.12967 lr: 0.001000 batch_cost: 0.35955 sec, reader_cost: 0.00239 sec, ips: 44.50016 instance/sec.
[03/04 10:23:21] epoch:[  6/30 ] train step:550  loss: 1.06315 lr: 0.001000 batch_cost: 0.35605 sec, reader_cost: 0.00024 sec, ips: 44.93715 instance/sec.
[03/04 10:23:24] epoch:[  6/30 ] train step:560  loss: 1.02854 lr: 0.001000 batch_cost: 0.35826 sec, reader_cost: 0.00232 sec, ips: 44.66037 instance/sec.
[03/04 10:23:28] epoch:[  6/30 ] train step:570  loss: 1.28795 lr: 0.001000 batch_cost: 0.35783 sec, reader_cost: 0.00229 sec, ips: 44.71337 instance/sec.
[03/04 10:23:31] epoch:[  6/30 ] train step:580  loss: 1.24429 lr: 0.001000 batch_cost: 0.36178 sec, reader_cost: 0.00182 sec, ips: 44.22584 instance/sec.
[03/04 10:23:35] epoch:[  6/30 ] train step:590  loss: 0.85551 lr: 0.001000 batch_cost: 0.36060 sec, reader_cost: 0.00240 sec, ips: 44.36994 instance/sec.
[03/04 10:23:38] epoch:[  6/30 ] train step:600  loss: 0.83728 lr: 0.001000 batch_cost: 0.36544 sec, reader_cost: 0.00252 sec, ips: 43.78236 instance/sec.
[03/04 10:23:42] epoch:[  6/30 ] train step:610  loss: 0.83783 lr: 0.001000 batch_cost: 0.35911 sec, reader_cost: 0.00219 sec, ips: 44.55470 instance/sec.
[03/04 10:23:46] epoch:[  6/30 ] train step:620  loss: 0.86011 lr: 0.001000 batch_cost: 0.36099 sec, reader_cost: 0.00245 sec, ips: 44.32317 instance/sec.
[03/04 10:23:49] epoch:[  6/30 ] train step:630  loss: 0.98469 lr: 0.001000 batch_cost: 0.35498 sec, reader_cost: 0.00024 sec, ips: 45.07321 instance/sec.
[03/04 10:23:53] epoch:[  6/30 ] train step:640  loss: 0.90991 lr: 0.001000 batch_cost: 0.35786 sec, reader_cost: 0.00227 sec, ips: 44.71048 instance/sec.
[03/04 10:23:56] epoch:[  6/30 ] train step:650  loss: 0.97704 lr: 0.001000 batch_cost: 0.35834 sec, reader_cost: 0.00238 sec, ips: 44.65095 instance/sec.
[03/04 10:24:00] epoch:[  6/30 ] train step:660  loss: 0.95487 lr: 0.001000 batch_cost: 0.35748 sec, reader_cost: 0.00234 sec, ips: 44.75780 instance/sec.
[03/04 10:24:04] epoch:[  6/30 ] train step:670  loss: 0.89613 lr: 0.001000 batch_cost: 0.35851 sec, reader_cost: 0.00249 sec, ips: 44.62889 instance/sec.
[03/04 10:24:07] epoch:[  6/30 ] train step:680  loss: 0.80973 lr: 0.001000 batch_cost: 0.35867 sec, reader_cost: 0.00219 sec, ips: 44.60904 instance/sec.
[03/04 10:24:11] epoch:[  6/30 ] train step:690  loss: 0.98244 lr: 0.001000 batch_cost: 0.35679 sec, reader_cost: 0.00012 sec, ips: 44.84481 instance/sec.
[03/04 10:24:14] epoch:[  6/30 ] train step:700  loss: 0.84248 lr: 0.001000 batch_cost: 0.36043 sec, reader_cost: 0.00254 sec, ips: 44.39163 instance/sec.
[03/04 10:24:18] epoch:[  6/30 ] train step:710  loss: 0.90019 lr: 0.001000 batch_cost: 0.35625 sec, reader_cost: 0.00235 sec, ips: 44.91242 instance/sec.
[03/04 10:24:22] epoch:[  6/30 ] train step:720  loss: 0.93778 lr: 0.001000 batch_cost: 0.35808 sec, reader_cost: 0.00016 sec, ips: 44.68247 instance/sec.
[03/04 10:24:25] epoch:[  6/30 ] train step:730  loss: 0.96716 lr: 0.001000 batch_cost: 0.35895 sec, reader_cost: 0.00219 sec, ips: 44.57500 instance/sec.
[03/04 10:24:29] epoch:[  6/30 ] train step:740  loss: 1.01068 lr: 0.001000 batch_cost: 0.35769 sec, reader_cost: 0.00250 sec, ips: 44.73173 instance/sec.
[03/04 10:24:32] epoch:[  6/30 ] train step:750  loss: 0.95067 lr: 0.001000 batch_cost: 0.35794 sec, reader_cost: 0.00252 sec, ips: 44.70014 instance/sec.
[03/04 10:24:36] epoch:[  6/30 ] train step:760  loss: 0.99719 lr: 0.001000 batch_cost: 0.35927 sec, reader_cost: 0.00226 sec, ips: 44.53474 instance/sec.
[03/04 10:24:39] epoch:[  6/30 ] train step:770  loss: 0.93773 lr: 0.001000 batch_cost: 0.35981 sec, reader_cost: 0.00225 sec, ips: 44.46802 instance/sec.
[03/04 10:24:43] epoch:[  6/30 ] train step:780  loss: 0.87942 lr: 0.001000 batch_cost: 0.35583 sec, reader_cost: 0.00007 sec, ips: 44.96476 instance/sec.
[03/04 10:24:45] END epoch:6   train loss_avg: 0.99616  avg_batch_cost: 0.35384 sec, avg_reader_cost: 0.00006 sec, batch_cost_sum: 281.74926 sec, avg_ips: 44.69222 instance/sec.
[03/04 10:24:47] epoch:[  7/30 ] train step:0    loss: 0.72658 lr: 0.001000 batch_cost: 1.15061 sec, reader_cost: 0.78347 sec, ips: 13.90568 instance/sec.
[03/04 10:24:50] epoch:[  7/30 ] train step:10   loss: 0.76400 lr: 0.001000 batch_cost: 0.35390 sec, reader_cost: 0.00023 sec, ips: 45.21033 instance/sec.
[03/04 10:24:54] epoch:[  7/30 ] train step:20   loss: 0.79404 lr: 0.001000 batch_cost: 0.35653 sec, reader_cost: 0.00226 sec, ips: 44.87644 instance/sec.
[03/04 10:24:57] epoch:[  7/30 ] train step:30   loss: 0.91394 lr: 0.001000 batch_cost: 0.35822 sec, reader_cost: 0.00283 sec, ips: 44.66489 instance/sec.
[03/04 10:25:01] epoch:[  7/30 ] train step:40   loss: 0.75201 lr: 0.001000 batch_cost: 0.35635 sec, reader_cost: 0.00024 sec, ips: 44.90010 instance/sec.
[03/04 10:25:05] epoch:[  7/30 ] train step:50   loss: 0.93691 lr: 0.001000 batch_cost: 0.35551 sec, reader_cost: 0.00017 sec, ips: 45.00595 instance/sec.
[03/04 10:25:08] epoch:[  7/30 ] train step:60   loss: 0.99230 lr: 0.001000 batch_cost: 0.35389 sec, reader_cost: 0.00030 sec, ips: 45.21125 instance/sec.
[03/04 10:25:12] epoch:[  7/30 ] train step:70   loss: 0.89152 lr: 0.001000 batch_cost: 0.35795 sec, reader_cost: 0.00223 sec, ips: 44.69869 instance/sec.
[03/04 10:25:15] epoch:[  7/30 ] train step:80   loss: 0.86303 lr: 0.001000 batch_cost: 0.35472 sec, reader_cost: 0.00014 sec, ips: 45.10641 instance/sec.
[03/04 10:25:19] epoch:[  7/30 ] train step:90   loss: 1.10398 lr: 0.001000 batch_cost: 0.35593 sec, reader_cost: 0.00013 sec, ips: 44.95235 instance/sec.
[03/04 10:25:22] epoch:[  7/30 ] train step:100  loss: 1.06814 lr: 0.001000 batch_cost: 0.35735 sec, reader_cost: 0.00249 sec, ips: 44.77357 instance/sec.
[03/04 10:25:26] epoch:[  7/30 ] train step:110  loss: 0.91547 lr: 0.001000 batch_cost: 0.35547 sec, reader_cost: 0.00232 sec, ips: 45.01036 instance/sec.
[03/04 10:25:29] epoch:[  7/30 ] train step:120  loss: 1.15293 lr: 0.001000 batch_cost: 0.35546 sec, reader_cost: 0.00225 sec, ips: 45.01186 instance/sec.
[03/04 10:25:33] epoch:[  7/30 ] train step:130  loss: 0.79114 lr: 0.001000 batch_cost: 0.35408 sec, reader_cost: 0.00013 sec, ips: 45.18705 instance/sec.
[03/04 10:25:37] epoch:[  7/30 ] train step:140  loss: 0.88151 lr: 0.001000 batch_cost: 0.35676 sec, reader_cost: 0.00215 sec, ips: 44.84861 instance/sec.
[03/04 10:25:40] epoch:[  7/30 ] train step:150  loss: 0.83393 lr: 0.001000 batch_cost: 0.35438 sec, reader_cost: 0.00249 sec, ips: 45.14902 instance/sec.
[03/04 10:25:44] epoch:[  7/30 ] train step:160  loss: 0.89051 lr: 0.001000 batch_cost: 0.35965 sec, reader_cost: 0.00244 sec, ips: 44.48709 instance/sec.
[03/04 10:25:47] epoch:[  7/30 ] train step:170  loss: 1.00837 lr: 0.001000 batch_cost: 0.35176 sec, reader_cost: 0.00013 sec, ips: 45.48511 instance/sec.
[03/04 10:25:51] epoch:[  7/30 ] train step:180  loss: 0.73237 lr: 0.001000 batch_cost: 0.35521 sec, reader_cost: 0.00219 sec, ips: 45.04325 instance/sec.
[03/04 10:25:54] epoch:[  7/30 ] train step:190  loss: 1.20700 lr: 0.001000 batch_cost: 0.35593 sec, reader_cost: 0.00014 sec, ips: 44.95232 instance/sec.
[03/04 10:25:58] epoch:[  7/30 ] train step:200  loss: 1.35059 lr: 0.001000 batch_cost: 0.35509 sec, reader_cost: 0.00238 sec, ips: 45.05841 instance/sec.
[03/04 10:26:02] epoch:[  7/30 ] train step:210  loss: 0.95806 lr: 0.001000 batch_cost: 0.35420 sec, reader_cost: 0.00013 sec, ips: 45.17266 instance/sec.
[03/04 10:26:05] epoch:[  7/30 ] train step:220  loss: 1.13239 lr: 0.001000 batch_cost: 0.35697 sec, reader_cost: 0.00215 sec, ips: 44.82198 instance/sec.
[03/04 10:26:09] epoch:[  7/30 ] train step:230  loss: 1.10944 lr: 0.001000 batch_cost: 0.35873 sec, reader_cost: 0.00229 sec, ips: 44.60184 instance/sec.
[03/04 10:26:12] epoch:[  7/30 ] train step:240  loss: 0.96427 lr: 0.001000 batch_cost: 0.35955 sec, reader_cost: 0.00058 sec, ips: 44.50001 instance/sec.
[03/04 10:26:16] epoch:[  7/30 ] train step:250  loss: 1.16303 lr: 0.001000 batch_cost: 0.35516 sec, reader_cost: 0.00012 sec, ips: 45.04976 instance/sec.
[03/04 10:26:19] epoch:[  7/30 ] train step:260  loss: 0.95914 lr: 0.001000 batch_cost: 0.35484 sec, reader_cost: 0.00216 sec, ips: 45.09077 instance/sec.
[03/04 10:26:23] epoch:[  7/30 ] train step:270  loss: 0.89761 lr: 0.001000 batch_cost: 0.35626 sec, reader_cost: 0.00230 sec, ips: 44.91122 instance/sec.
[03/04 10:26:26] epoch:[  7/30 ] train step:280  loss: 0.80427 lr: 0.001000 batch_cost: 0.35638 sec, reader_cost: 0.00229 sec, ips: 44.89584 instance/sec.
[03/04 10:26:30] epoch:[  7/30 ] train step:290  loss: 0.91351 lr: 0.001000 batch_cost: 0.35596 sec, reader_cost: 0.00240 sec, ips: 44.94867 instance/sec.
[03/04 10:26:34] epoch:[  7/30 ] train step:300  loss: 1.15147 lr: 0.001000 batch_cost: 0.35759 sec, reader_cost: 0.00236 sec, ips: 44.74348 instance/sec.
[03/04 10:26:37] epoch:[  7/30 ] train step:310  loss: 0.85545 lr: 0.001000 batch_cost: 0.35527 sec, reader_cost: 0.00017 sec, ips: 45.03564 instance/sec.
[03/04 10:26:41] epoch:[  7/30 ] train step:320  loss: 1.09229 lr: 0.001000 batch_cost: 0.35704 sec, reader_cost: 0.00215 sec, ips: 44.81238 instance/sec.
[03/04 10:26:44] epoch:[  7/30 ] train step:330  loss: 1.13231 lr: 0.001000 batch_cost: 0.35310 sec, reader_cost: 0.00014 sec, ips: 45.31333 instance/sec.
[03/04 10:26:48] epoch:[  7/30 ] train step:340  loss: 0.89596 lr: 0.001000 batch_cost: 0.35660 sec, reader_cost: 0.00223 sec, ips: 44.86846 instance/sec.
[03/04 10:26:51] epoch:[  7/30 ] train step:350  loss: 0.92084 lr: 0.001000 batch_cost: 0.35610 sec, reader_cost: 0.00235 sec, ips: 44.93059 instance/sec.
[03/04 10:26:55] epoch:[  7/30 ] train step:360  loss: 0.91290 lr: 0.001000 batch_cost: 0.35579 sec, reader_cost: 0.00235 sec, ips: 44.97015 instance/sec.
[03/04 10:26:58] epoch:[  7/30 ] train step:370  loss: 0.98768 lr: 0.001000 batch_cost: 0.35374 sec, reader_cost: 0.00012 sec, ips: 45.23057 instance/sec.
[03/04 10:27:02] epoch:[  7/30 ] train step:380  loss: 0.79564 lr: 0.001000 batch_cost: 0.35199 sec, reader_cost: 0.00011 sec, ips: 45.45590 instance/sec.
[03/04 10:27:06] epoch:[  7/30 ] train step:390  loss: 1.25119 lr: 0.001000 batch_cost: 0.35606 sec, reader_cost: 0.00014 sec, ips: 44.93567 instance/sec.
[03/04 10:27:09] epoch:[  7/30 ] train step:400  loss: 0.79054 lr: 0.001000 batch_cost: 0.35472 sec, reader_cost: 0.00013 sec, ips: 45.10592 instance/sec.
[03/04 10:27:13] epoch:[  7/30 ] train step:410  loss: 1.10054 lr: 0.001000 batch_cost: 0.35616 sec, reader_cost: 0.00024 sec, ips: 44.92394 instance/sec.
[03/04 10:27:16] epoch:[  7/30 ] train step:420  loss: 0.87737 lr: 0.001000 batch_cost: 0.35572 sec, reader_cost: 0.00219 sec, ips: 44.97862 instance/sec.
[03/04 10:27:20] epoch:[  7/30 ] train step:430  loss: 0.88193 lr: 0.001000 batch_cost: 0.35616 sec, reader_cost: 0.00239 sec, ips: 44.92358 instance/sec.
[03/04 10:27:23] epoch:[  7/30 ] train step:440  loss: 1.28273 lr: 0.001000 batch_cost: 0.35605 sec, reader_cost: 0.00021 sec, ips: 44.93787 instance/sec.
[03/04 10:27:27] epoch:[  7/30 ] train step:450  loss: 0.80828 lr: 0.001000 batch_cost: 0.35241 sec, reader_cost: 0.00009 sec, ips: 45.40135 instance/sec.
[03/04 10:27:31] epoch:[  7/30 ] train step:460  loss: 0.78691 lr: 0.001000 batch_cost: 0.35805 sec, reader_cost: 0.00217 sec, ips: 44.68607 instance/sec.
[03/04 10:27:34] epoch:[  7/30 ] train step:470  loss: 0.88236 lr: 0.001000 batch_cost: 0.35476 sec, reader_cost: 0.00238 sec, ips: 45.10126 instance/sec.
[03/04 10:27:38] epoch:[  7/30 ] train step:480  loss: 1.23145 lr: 0.001000 batch_cost: 0.35676 sec, reader_cost: 0.00015 sec, ips: 44.84774 instance/sec.
[03/04 10:27:41] epoch:[  7/30 ] train step:490  loss: 0.95689 lr: 0.001000 batch_cost: 0.35309 sec, reader_cost: 0.00012 sec, ips: 45.31416 instance/sec.
[03/04 10:27:45] epoch:[  7/30 ] train step:500  loss: 1.00845 lr: 0.001000 batch_cost: 0.35999 sec, reader_cost: 0.00218 sec, ips: 44.44602 instance/sec.
[03/04 10:27:48] epoch:[  7/30 ] train step:510  loss: 1.14614 lr: 0.001000 batch_cost: 0.35812 sec, reader_cost: 0.00232 sec, ips: 44.67791 instance/sec.
[03/04 10:27:52] epoch:[  7/30 ] train step:520  loss: 0.84075 lr: 0.001000 batch_cost: 0.35649 sec, reader_cost: 0.00263 sec, ips: 44.88176 instance/sec.
[03/04 10:27:55] epoch:[  7/30 ] train step:530  loss: 1.05029 lr: 0.001000 batch_cost: 0.35371 sec, reader_cost: 0.00014 sec, ips: 45.23511 instance/sec.
[03/04 10:27:59] epoch:[  7/30 ] train step:540  loss: 1.35929 lr: 0.001000 batch_cost: 0.35422 sec, reader_cost: 0.00223 sec, ips: 45.16983 instance/sec.
[03/04 10:28:03] epoch:[  7/30 ] train step:550  loss: 1.13207 lr: 0.001000 batch_cost: 0.35652 sec, reader_cost: 0.00240 sec, ips: 44.87858 instance/sec.
[03/04 10:28:06] epoch:[  7/30 ] train step:560  loss: 0.96481 lr: 0.001000 batch_cost: 0.35564 sec, reader_cost: 0.00231 sec, ips: 44.98881 instance/sec.
[03/04 10:28:10] epoch:[  7/30 ] train step:570  loss: 0.96363 lr: 0.001000 batch_cost: 0.35606 sec, reader_cost: 0.00013 sec, ips: 44.93591 instance/sec.
[03/04 10:28:13] epoch:[  7/30 ] train step:580  loss: 0.85174 lr: 0.001000 batch_cost: 0.35312 sec, reader_cost: 0.00019 sec, ips: 45.30978 instance/sec.
[03/04 10:28:17] epoch:[  7/30 ] train step:590  loss: 0.94427 lr: 0.001000 batch_cost: 0.35644 sec, reader_cost: 0.00233 sec, ips: 44.88791 instance/sec.
[03/04 10:28:20] epoch:[  7/30 ] train step:600  loss: 1.01681 lr: 0.001000 batch_cost: 0.35423 sec, reader_cost: 0.00053 sec, ips: 45.16831 instance/sec.
[03/04 10:28:24] epoch:[  7/30 ] train step:610  loss: 0.84327 lr: 0.001000 batch_cost: 0.35270 sec, reader_cost: 0.00013 sec, ips: 45.36415 instance/sec.
[03/04 10:28:28] epoch:[  7/30 ] train step:620  loss: 1.11966 lr: 0.001000 batch_cost: 0.35541 sec, reader_cost: 0.00016 sec, ips: 45.01866 instance/sec.
[03/04 10:28:31] epoch:[  7/30 ] train step:630  loss: 0.94867 lr: 0.001000 batch_cost: 0.35595 sec, reader_cost: 0.00042 sec, ips: 44.94991 instance/sec.
[03/04 10:28:35] epoch:[  7/30 ] train step:640  loss: 0.76163 lr: 0.001000 batch_cost: 0.35921 sec, reader_cost: 0.00233 sec, ips: 44.54272 instance/sec.
[03/04 10:28:38] epoch:[  7/30 ] train step:650  loss: 1.03142 lr: 0.001000 batch_cost: 0.35606 sec, reader_cost: 0.00231 sec, ips: 44.93651 instance/sec.
[03/04 10:28:42] epoch:[  7/30 ] train step:660  loss: 0.91322 lr: 0.001000 batch_cost: 0.35601 sec, reader_cost: 0.00219 sec, ips: 44.94259 instance/sec.
[03/04 10:28:45] epoch:[  7/30 ] train step:670  loss: 0.97270 lr: 0.001000 batch_cost: 0.35611 sec, reader_cost: 0.00220 sec, ips: 44.92974 instance/sec.
[03/04 10:28:49] epoch:[  7/30 ] train step:680  loss: 0.97803 lr: 0.001000 batch_cost: 0.35532 sec, reader_cost: 0.00016 sec, ips: 45.03038 instance/sec.
[03/04 10:28:52] epoch:[  7/30 ] train step:690  loss: 1.06489 lr: 0.001000 batch_cost: 0.35540 sec, reader_cost: 0.00225 sec, ips: 45.01908 instance/sec.
[03/04 10:28:56] epoch:[  7/30 ] train step:700  loss: 0.91553 lr: 0.001000 batch_cost: 0.35626 sec, reader_cost: 0.00234 sec, ips: 44.91137 instance/sec.
[03/04 10:29:00] epoch:[  7/30 ] train step:710  loss: 1.11963 lr: 0.001000 batch_cost: 0.35851 sec, reader_cost: 0.00228 sec, ips: 44.62856 instance/sec.
[03/04 10:29:03] epoch:[  7/30 ] train step:720  loss: 0.78618 lr: 0.001000 batch_cost: 0.35725 sec, reader_cost: 0.00227 sec, ips: 44.78630 instance/sec.
[03/04 10:29:07] epoch:[  7/30 ] train step:730  loss: 0.87589 lr: 0.001000 batch_cost: 0.35896 sec, reader_cost: 0.00246 sec, ips: 44.57290 instance/sec.
[03/04 10:29:10] epoch:[  7/30 ] train step:740  loss: 0.81558 lr: 0.001000 batch_cost: 0.35521 sec, reader_cost: 0.00234 sec, ips: 45.04392 instance/sec.
[03/04 10:29:14] epoch:[  7/30 ] train step:750  loss: 0.91258 lr: 0.001000 batch_cost: 0.35676 sec, reader_cost: 0.00231 sec, ips: 44.84834 instance/sec.
[03/04 10:29:17] epoch:[  7/30 ] train step:760  loss: 0.95425 lr: 0.001000 batch_cost: 0.35650 sec, reader_cost: 0.00233 sec, ips: 44.88017 instance/sec.
[03/04 10:29:21] epoch:[  7/30 ] train step:770  loss: 0.89090 lr: 0.001000 batch_cost: 0.35330 sec, reader_cost: 0.00011 sec, ips: 45.28780 instance/sec.
[03/04 10:29:25] epoch:[  7/30 ] train step:780  loss: 1.17286 lr: 0.001000 batch_cost: 0.35153 sec, reader_cost: 0.00006 sec, ips: 45.51571 instance/sec.
[03/04 10:29:27] END epoch:7   train loss_avg: 0.98251  avg_batch_cost: 0.35369 sec, avg_reader_cost: 0.00005 sec, batch_cost_sum: 281.02927 sec, avg_ips: 44.80672 instance/sec.
[03/04 10:29:28] epoch:[  8/30 ] train step:0    loss: 1.00059 lr: 0.001000 batch_cost: 1.15330 sec, reader_cost: 0.78310 sec, ips: 13.87319 instance/sec.
[03/04 10:29:32] epoch:[  8/30 ] train step:10   loss: 0.84870 lr: 0.001000 batch_cost: 0.35779 sec, reader_cost: 0.00233 sec, ips: 44.71948 instance/sec.
[03/04 10:29:35] epoch:[  8/30 ] train step:20   loss: 1.05924 lr: 0.001000 batch_cost: 0.35898 sec, reader_cost: 0.00208 sec, ips: 44.57077 instance/sec.
[03/04 10:29:39] epoch:[  8/30 ] train step:30   loss: 0.89162 lr: 0.001000 batch_cost: 0.35587 sec, reader_cost: 0.00227 sec, ips: 44.96024 instance/sec.
[03/04 10:29:43] epoch:[  8/30 ] train step:40   loss: 0.76822 lr: 0.001000 batch_cost: 0.35791 sec, reader_cost: 0.00221 sec, ips: 44.70422 instance/sec.
[03/04 10:29:46] epoch:[  8/30 ] train step:50   loss: 0.93623 lr: 0.001000 batch_cost: 0.35620 sec, reader_cost: 0.00266 sec, ips: 44.91808 instance/sec.
[03/04 10:29:50] epoch:[  8/30 ] train step:60   loss: 0.85483 lr: 0.001000 batch_cost: 0.35538 sec, reader_cost: 0.00215 sec, ips: 45.02240 instance/sec.
[03/04 10:29:53] epoch:[  8/30 ] train step:70   loss: 0.98193 lr: 0.001000 batch_cost: 0.35437 sec, reader_cost: 0.00017 sec, ips: 45.15114 instance/sec.
[03/04 10:29:57] epoch:[  8/30 ] train step:80   loss: 1.11929 lr: 0.001000 batch_cost: 0.35544 sec, reader_cost: 0.00211 sec, ips: 45.01461 instance/sec.
[03/04 10:30:00] epoch:[  8/30 ] train step:90   loss: 1.01920 lr: 0.001000 batch_cost: 0.35609 sec, reader_cost: 0.00259 sec, ips: 44.93284 instance/sec.
[03/04 10:30:04] epoch:[  8/30 ] train step:100  loss: 0.89894 lr: 0.001000 batch_cost: 0.35613 sec, reader_cost: 0.00232 sec, ips: 44.92716 instance/sec.
[03/04 10:30:07] epoch:[  8/30 ] train step:110  loss: 0.88851 lr: 0.001000 batch_cost: 0.35690 sec, reader_cost: 0.00040 sec, ips: 44.83103 instance/sec.
[03/04 10:30:11] epoch:[  8/30 ] train step:120  loss: 0.82158 lr: 0.001000 batch_cost: 0.35490 sec, reader_cost: 0.00217 sec, ips: 45.08317 instance/sec.
[03/04 10:30:15] epoch:[  8/30 ] train step:130  loss: 1.02081 lr: 0.001000 batch_cost: 0.35838 sec, reader_cost: 0.00259 sec, ips: 44.64480 instance/sec.
[03/04 10:30:18] epoch:[  8/30 ] train step:140  loss: 0.85137 lr: 0.001000 batch_cost: 0.35420 sec, reader_cost: 0.00014 sec, ips: 45.17205 instance/sec.
[03/04 10:30:22] epoch:[  8/30 ] train step:150  loss: 0.77599 lr: 0.001000 batch_cost: 0.35944 sec, reader_cost: 0.00227 sec, ips: 44.51394 instance/sec.
[03/04 10:30:25] epoch:[  8/30 ] train step:160  loss: 0.89364 lr: 0.001000 batch_cost: 0.36073 sec, reader_cost: 0.00221 sec, ips: 44.35410 instance/sec.
[03/04 10:30:29] epoch:[  8/30 ] train step:170  loss: 0.89308 lr: 0.001000 batch_cost: 0.35727 sec, reader_cost: 0.00273 sec, ips: 44.78459 instance/sec.
[03/04 10:30:32] epoch:[  8/30 ] train step:180  loss: 0.88067 lr: 0.001000 batch_cost: 0.35704 sec, reader_cost: 0.00232 sec, ips: 44.81280 instance/sec.
[03/04 10:30:36] epoch:[  8/30 ] train step:190  loss: 0.92571 lr: 0.001000 batch_cost: 0.35755 sec, reader_cost: 0.00232 sec, ips: 44.74864 instance/sec.
[03/04 10:30:40] epoch:[  8/30 ] train step:200  loss: 0.94772 lr: 0.001000 batch_cost: 0.35933 sec, reader_cost: 0.00221 sec, ips: 44.52747 instance/sec.
[03/04 10:30:43] epoch:[  8/30 ] train step:210  loss: 0.85665 lr: 0.001000 batch_cost: 0.36114 sec, reader_cost: 0.00259 sec, ips: 44.30476 instance/sec.
[03/04 10:30:47] epoch:[  8/30 ] train step:220  loss: 0.83356 lr: 0.001000 batch_cost: 0.35807 sec, reader_cost: 0.00222 sec, ips: 44.68410 instance/sec.
[03/04 10:30:50] epoch:[  8/30 ] train step:230  loss: 1.06927 lr: 0.001000 batch_cost: 0.35699 sec, reader_cost: 0.00012 sec, ips: 44.81974 instance/sec.
[03/04 10:30:54] epoch:[  8/30 ] train step:240  loss: 1.08696 lr: 0.001000 batch_cost: 0.36290 sec, reader_cost: 0.00227 sec, ips: 44.08896 instance/sec.
[03/04 10:30:58] epoch:[  8/30 ] train step:250  loss: 1.07747 lr: 0.001000 batch_cost: 0.35736 sec, reader_cost: 0.00272 sec, ips: 44.77315 instance/sec.
[03/04 10:31:01] epoch:[  8/30 ] train step:260  loss: 0.96329 lr: 0.001000 batch_cost: 0.35827 sec, reader_cost: 0.00226 sec, ips: 44.65844 instance/sec.
[03/04 10:31:05] epoch:[  8/30 ] train step:270  loss: 1.27164 lr: 0.001000 batch_cost: 0.35899 sec, reader_cost: 0.00239 sec, ips: 44.57005 instance/sec.
[03/04 10:31:08] epoch:[  8/30 ] train step:280  loss: 0.99002 lr: 0.001000 batch_cost: 0.35897 sec, reader_cost: 0.00229 sec, ips: 44.57180 instance/sec.
[03/04 10:31:12] epoch:[  8/30 ] train step:290  loss: 1.19842 lr: 0.001000 batch_cost: 0.36098 sec, reader_cost: 0.00272 sec, ips: 44.32328 instance/sec.
[03/04 10:31:16] epoch:[  8/30 ] train step:300  loss: 0.81196 lr: 0.001000 batch_cost: 0.35726 sec, reader_cost: 0.00238 sec, ips: 44.78537 instance/sec.
[03/04 10:31:19] epoch:[  8/30 ] train step:310  loss: 0.79596 lr: 0.001000 batch_cost: 0.35878 sec, reader_cost: 0.00221 sec, ips: 44.59559 instance/sec.
[03/04 10:31:23] epoch:[  8/30 ] train step:320  loss: 0.96673 lr: 0.001000 batch_cost: 0.35890 sec, reader_cost: 0.00013 sec, ips: 44.58110 instance/sec.
[03/04 10:31:26] epoch:[  8/30 ] train step:330  loss: 0.85018 lr: 0.001000 batch_cost: 0.35812 sec, reader_cost: 0.00272 sec, ips: 44.67735 instance/sec.
[03/04 10:31:30] epoch:[  8/30 ] train step:340  loss: 0.82824 lr: 0.001000 batch_cost: 0.35729 sec, reader_cost: 0.00225 sec, ips: 44.78149 instance/sec.
[03/04 10:31:33] epoch:[  8/30 ] train step:350  loss: 0.84230 lr: 0.001000 batch_cost: 0.35954 sec, reader_cost: 0.00226 sec, ips: 44.50128 instance/sec.
[03/04 10:31:37] epoch:[  8/30 ] train step:360  loss: 1.06433 lr: 0.001000 batch_cost: 0.35848 sec, reader_cost: 0.00224 sec, ips: 44.63337 instance/sec.
[03/04 10:31:41] epoch:[  8/30 ] train step:370  loss: 0.88968 lr: 0.001000 batch_cost: 0.35698 sec, reader_cost: 0.00263 sec, ips: 44.81992 instance/sec.
[03/04 10:31:44] epoch:[  8/30 ] train step:380  loss: 0.83609 lr: 0.001000 batch_cost: 0.35778 sec, reader_cost: 0.00225 sec, ips: 44.72052 instance/sec.
[03/04 10:31:48] epoch:[  8/30 ] train step:390  loss: 0.93866 lr: 0.001000 batch_cost: 0.35846 sec, reader_cost: 0.00219 sec, ips: 44.63495 instance/sec.
[03/04 10:31:51] epoch:[  8/30 ] train step:400  loss: 0.92955 lr: 0.001000 batch_cost: 0.36021 sec, reader_cost: 0.00232 sec, ips: 44.41819 instance/sec.
[03/04 10:31:55] epoch:[  8/30 ] train step:410  loss: 0.68364 lr: 0.001000 batch_cost: 0.35869 sec, reader_cost: 0.00218 sec, ips: 44.60685 instance/sec.
[03/04 10:31:59] epoch:[  8/30 ] train step:420  loss: 1.01217 lr: 0.001000 batch_cost: 0.35884 sec, reader_cost: 0.00223 sec, ips: 44.58833 instance/sec.
[03/04 10:32:02] epoch:[  8/30 ] train step:430  loss: 1.42171 lr: 0.001000 batch_cost: 0.36072 sec, reader_cost: 0.00224 sec, ips: 44.35601 instance/sec.
[03/04 10:32:06] epoch:[  8/30 ] train step:440  loss: 1.09431 lr: 0.001000 batch_cost: 0.35389 sec, reader_cost: 0.00220 sec, ips: 45.21119 instance/sec.
[03/04 10:32:09] epoch:[  8/30 ] train step:450  loss: 1.10060 lr: 0.001000 batch_cost: 0.35770 sec, reader_cost: 0.00016 sec, ips: 44.72964 instance/sec.
[03/04 10:32:13] epoch:[  8/30 ] train step:460  loss: 0.90719 lr: 0.001000 batch_cost: 0.35312 sec, reader_cost: 0.00015 sec, ips: 45.31000 instance/sec.
[03/04 10:32:16] epoch:[  8/30 ] train step:470  loss: 0.95173 lr: 0.001000 batch_cost: 0.35717 sec, reader_cost: 0.00219 sec, ips: 44.79709 instance/sec.
[03/04 10:32:20] epoch:[  8/30 ] train step:480  loss: 0.93963 lr: 0.001000 batch_cost: 0.35757 sec, reader_cost: 0.00231 sec, ips: 44.74697 instance/sec.
[03/04 10:32:24] epoch:[  8/30 ] train step:490  loss: 1.22107 lr: 0.001000 batch_cost: 0.35556 sec, reader_cost: 0.00254 sec, ips: 44.99985 instance/sec.
[03/04 10:32:27] epoch:[  8/30 ] train step:500  loss: 0.94449 lr: 0.001000 batch_cost: 0.35751 sec, reader_cost: 0.00232 sec, ips: 44.75410 instance/sec.
[03/04 10:32:31] epoch:[  8/30 ] train step:510  loss: 0.98708 lr: 0.001000 batch_cost: 0.35531 sec, reader_cost: 0.00227 sec, ips: 45.03113 instance/sec.
[03/04 10:32:34] epoch:[  8/30 ] train step:520  loss: 1.18130 lr: 0.001000 batch_cost: 0.35864 sec, reader_cost: 0.00221 sec, ips: 44.61248 instance/sec.
[03/04 10:32:38] epoch:[  8/30 ] train step:530  loss: 1.03562 lr: 0.001000 batch_cost: 0.35667 sec, reader_cost: 0.00263 sec, ips: 44.85998 instance/sec.
[03/04 10:32:41] epoch:[  8/30 ] train step:540  loss: 0.88896 lr: 0.001000 batch_cost: 0.35493 sec, reader_cost: 0.00230 sec, ips: 45.07872 instance/sec.
[03/04 10:32:45] epoch:[  8/30 ] train step:550  loss: 1.48234 lr: 0.001000 batch_cost: 0.35805 sec, reader_cost: 0.00224 sec, ips: 44.68607 instance/sec.
[03/04 10:32:48] epoch:[  8/30 ] train step:560  loss: 1.05150 lr: 0.001000 batch_cost: 0.35651 sec, reader_cost: 0.00235 sec, ips: 44.87990 instance/sec.
[03/04 10:32:52] epoch:[  8/30 ] train step:570  loss: 1.11520 lr: 0.001000 batch_cost: 0.35530 sec, reader_cost: 0.00267 sec, ips: 45.03252 instance/sec.
[03/04 10:32:56] epoch:[  8/30 ] train step:580  loss: 0.96348 lr: 0.001000 batch_cost: 0.35489 sec, reader_cost: 0.00257 sec, ips: 45.08389 instance/sec.
[03/04 10:32:59] epoch:[  8/30 ] train step:590  loss: 0.92643 lr: 0.001000 batch_cost: 0.35736 sec, reader_cost: 0.00247 sec, ips: 44.77217 instance/sec.
[03/04 10:33:03] epoch:[  8/30 ] train step:600  loss: 0.80824 lr: 0.001000 batch_cost: 0.35412 sec, reader_cost: 0.00016 sec, ips: 45.18209 instance/sec.
[03/04 10:33:06] epoch:[  8/30 ] train step:610  loss: 1.02453 lr: 0.001000 batch_cost: 0.35715 sec, reader_cost: 0.00265 sec, ips: 44.79853 instance/sec.
[03/04 10:33:10] epoch:[  8/30 ] train step:620  loss: 0.99727 lr: 0.001000 batch_cost: 0.35619 sec, reader_cost: 0.00233 sec, ips: 44.91946 instance/sec.
[03/04 10:33:13] epoch:[  8/30 ] train step:630  loss: 0.87132 lr: 0.001000 batch_cost: 0.35486 sec, reader_cost: 0.00213 sec, ips: 45.08768 instance/sec.
[03/04 10:33:17] epoch:[  8/30 ] train step:640  loss: 0.82416 lr: 0.001000 batch_cost: 0.35840 sec, reader_cost: 0.00234 sec, ips: 44.64335 instance/sec.
[03/04 10:33:21] epoch:[  8/30 ] train step:650  loss: 1.21087 lr: 0.001000 batch_cost: 0.35352 sec, reader_cost: 0.00013 sec, ips: 45.25854 instance/sec.
[03/04 10:33:24] epoch:[  8/30 ] train step:660  loss: 0.96166 lr: 0.001000 batch_cost: 0.35493 sec, reader_cost: 0.00016 sec, ips: 45.07926 instance/sec.
[03/04 10:33:28] epoch:[  8/30 ] train step:670  loss: 1.02700 lr: 0.001000 batch_cost: 0.35567 sec, reader_cost: 0.00232 sec, ips: 44.98522 instance/sec.
[03/04 10:33:31] epoch:[  8/30 ] train step:680  loss: 0.90761 lr: 0.001000 batch_cost: 0.35638 sec, reader_cost: 0.00011 sec, ips: 44.89632 instance/sec.
[03/04 10:33:35] epoch:[  8/30 ] train step:690  loss: 0.85497 lr: 0.001000 batch_cost: 0.35888 sec, reader_cost: 0.00282 sec, ips: 44.58264 instance/sec.
[03/04 10:33:38] epoch:[  8/30 ] train step:700  loss: 0.91329 lr: 0.001000 batch_cost: 0.35407 sec, reader_cost: 0.00043 sec, ips: 45.18893 instance/sec.
[03/04 10:33:42] epoch:[  8/30 ] train step:710  loss: 0.89490 lr: 0.001000 batch_cost: 0.35679 sec, reader_cost: 0.00217 sec, ips: 44.84379 instance/sec.
[03/04 10:33:45] epoch:[  8/30 ] train step:720  loss: 0.91059 lr: 0.001000 batch_cost: 0.35529 sec, reader_cost: 0.00218 sec, ips: 45.03364 instance/sec.
[03/04 10:33:49] epoch:[  8/30 ] train step:730  loss: 0.76256 lr: 0.001000 batch_cost: 0.35733 sec, reader_cost: 0.00273 sec, ips: 44.77691 instance/sec.
[03/04 10:33:53] epoch:[  8/30 ] train step:740  loss: 0.83945 lr: 0.001000 batch_cost: 0.35519 sec, reader_cost: 0.00027 sec, ips: 45.04661 instance/sec.
[03/04 10:33:56] epoch:[  8/30 ] train step:750  loss: 1.16445 lr: 0.001000 batch_cost: 0.35718 sec, reader_cost: 0.00225 sec, ips: 44.79577 instance/sec.
[03/04 10:34:00] epoch:[  8/30 ] train step:760  loss: 0.98262 lr: 0.001000 batch_cost: 0.35619 sec, reader_cost: 0.00241 sec, ips: 44.91997 instance/sec.
[03/04 10:34:03] epoch:[  8/30 ] train step:770  loss: 1.15043 lr: 0.001000 batch_cost: 0.35530 sec, reader_cost: 0.00038 sec, ips: 45.03246 instance/sec.
[03/04 10:34:07] epoch:[  8/30 ] train step:780  loss: 0.94333 lr: 0.001000 batch_cost: 0.35062 sec, reader_cost: 0.00008 sec, ips: 45.63326 instance/sec.
[03/04 10:34:09] END epoch:8   train loss_avg: 0.96614  avg_batch_cost: 0.35206 sec, avg_reader_cost: 0.00006 sec, batch_cost_sum: 281.73147 sec, avg_ips: 44.69504 instance/sec.
[03/04 10:34:11] epoch:[  9/30 ] train step:0    loss: 0.71796 lr: 0.001000 batch_cost: 1.17530 sec, reader_cost: 0.79842 sec, ips: 13.61352 instance/sec.
[03/04 10:34:14] epoch:[  9/30 ] train step:10   loss: 0.92005 lr: 0.001000 batch_cost: 0.35546 sec, reader_cost: 0.00216 sec, ips: 45.01271 instance/sec.
[03/04 10:34:18] epoch:[  9/30 ] train step:20   loss: 0.81714 lr: 0.001000 batch_cost: 0.36107 sec, reader_cost: 0.00238 sec, ips: 44.31266 instance/sec.
[03/04 10:34:21] epoch:[  9/30 ] train step:30   loss: 0.95864 lr: 0.001000 batch_cost: 0.36124 sec, reader_cost: 0.00032 sec, ips: 44.29137 instance/sec.
[03/04 10:34:25] epoch:[  9/30 ] train step:40   loss: 0.87596 lr: 0.001000 batch_cost: 0.36241 sec, reader_cost: 0.00016 sec, ips: 44.14868 instance/sec.
[03/04 10:34:28] epoch:[  9/30 ] train step:50   loss: 1.22800 lr: 0.001000 batch_cost: 0.35576 sec, reader_cost: 0.00237 sec, ips: 44.97377 instance/sec.
[03/04 10:34:32] epoch:[  9/30 ] train step:60   loss: 0.84947 lr: 0.001000 batch_cost: 0.35529 sec, reader_cost: 0.00234 sec, ips: 45.03358 instance/sec.
[03/04 10:34:36] epoch:[  9/30 ] train step:70   loss: 0.83370 lr: 0.001000 batch_cost: 0.35277 sec, reader_cost: 0.00024 sec, ips: 45.35477 instance/sec.
[03/04 10:34:39] epoch:[  9/30 ] train step:80   loss: 0.87329 lr: 0.001000 batch_cost: 0.35500 sec, reader_cost: 0.00221 sec, ips: 45.07090 instance/sec.
[03/04 10:34:43] epoch:[  9/30 ] train step:90   loss: 1.30941 lr: 0.001000 batch_cost: 0.35813 sec, reader_cost: 0.00235 sec, ips: 44.67607 instance/sec.
[03/04 10:34:46] epoch:[  9/30 ] train step:100  loss: 0.86951 lr: 0.001000 batch_cost: 0.35171 sec, reader_cost: 0.00012 sec, ips: 45.49235 instance/sec.
[03/04 10:34:50] epoch:[  9/30 ] train step:110  loss: 1.08115 lr: 0.001000 batch_cost: 0.35507 sec, reader_cost: 0.00215 sec, ips: 45.06104 instance/sec.
[03/04 10:34:53] epoch:[  9/30 ] train step:120  loss: 0.82150 lr: 0.001000 batch_cost: 0.35433 sec, reader_cost: 0.00216 sec, ips: 45.15509 instance/sec.
[03/04 10:34:57] epoch:[  9/30 ] train step:130  loss: 0.95536 lr: 0.001000 batch_cost: 0.35775 sec, reader_cost: 0.00236 sec, ips: 44.72344 instance/sec.
[03/04 10:35:00] epoch:[  9/30 ] train step:140  loss: 0.80235 lr: 0.001000 batch_cost: 0.35671 sec, reader_cost: 0.00235 sec, ips: 44.85425 instance/sec.
[03/04 10:35:04] epoch:[  9/30 ] train step:150  loss: 0.80798 lr: 0.001000 batch_cost: 0.35845 sec, reader_cost: 0.00228 sec, ips: 44.63682 instance/sec.
[03/04 10:35:07] epoch:[  9/30 ] train step:160  loss: 0.81820 lr: 0.001000 batch_cost: 0.35481 sec, reader_cost: 0.00224 sec, ips: 45.09480 instance/sec.
[03/04 10:35:11] epoch:[  9/30 ] train step:170  loss: 1.05585 lr: 0.001000 batch_cost: 0.35363 sec, reader_cost: 0.00226 sec, ips: 45.24459 instance/sec.
[03/04 10:35:15] epoch:[  9/30 ] train step:180  loss: 0.91655 lr: 0.001000 batch_cost: 0.35406 sec, reader_cost: 0.00012 sec, ips: 45.18982 instance/sec.
[03/04 10:35:18] epoch:[  9/30 ] train step:190  loss: 0.95037 lr: 0.001000 batch_cost: 0.35459 sec, reader_cost: 0.00234 sec, ips: 45.12227 instance/sec.
[03/04 10:35:22] epoch:[  9/30 ] train step:200  loss: 0.77454 lr: 0.001000 batch_cost: 0.35377 sec, reader_cost: 0.00226 sec, ips: 45.22734 instance/sec.
[03/04 10:35:25] epoch:[  9/30 ] train step:210  loss: 0.86907 lr: 0.001000 batch_cost: 0.35487 sec, reader_cost: 0.00035 sec, ips: 45.08692 instance/sec.
[03/04 10:35:29] epoch:[  9/30 ] train step:220  loss: 0.86779 lr: 0.001000 batch_cost: 0.35810 sec, reader_cost: 0.00239 sec, ips: 44.68018 instance/sec.
[03/04 10:35:32] epoch:[  9/30 ] train step:230  loss: 0.83391 lr: 0.001000 batch_cost: 0.35672 sec, reader_cost: 0.00240 sec, ips: 44.85284 instance/sec.
[03/04 10:35:36] epoch:[  9/30 ] train step:240  loss: 1.63225 lr: 0.001000 batch_cost: 0.35351 sec, reader_cost: 0.00013 sec, ips: 45.26061 instance/sec.
[03/04 10:35:39] epoch:[  9/30 ] train step:250  loss: 0.91404 lr: 0.001000 batch_cost: 0.35424 sec, reader_cost: 0.00245 sec, ips: 45.16761 instance/sec.
[03/04 10:35:43] epoch:[  9/30 ] train step:260  loss: 0.97837 lr: 0.001000 batch_cost: 0.35761 sec, reader_cost: 0.00245 sec, ips: 44.74139 instance/sec.
[03/04 10:35:47] epoch:[  9/30 ] train step:270  loss: 0.90127 lr: 0.001000 batch_cost: 0.35366 sec, reader_cost: 0.00015 sec, ips: 45.24100 instance/sec.
[03/04 10:35:50] epoch:[  9/30 ] train step:280  loss: 1.13251 lr: 0.001000 batch_cost: 0.35727 sec, reader_cost: 0.00227 sec, ips: 44.78459 instance/sec.
[03/04 10:35:54] epoch:[  9/30 ] train step:290  loss: 0.92755 lr: 0.001000 batch_cost: 0.35419 sec, reader_cost: 0.00015 sec, ips: 45.17336 instance/sec.
[03/04 10:35:57] epoch:[  9/30 ] train step:300  loss: 0.91063 lr: 0.001000 batch_cost: 0.35659 sec, reader_cost: 0.00219 sec, ips: 44.86894 instance/sec.
[03/04 10:36:01] epoch:[  9/30 ] train step:310  loss: 1.06026 lr: 0.001000 batch_cost: 0.35445 sec, reader_cost: 0.00240 sec, ips: 45.14051 instance/sec.
[03/04 10:36:04] epoch:[  9/30 ] train step:320  loss: 0.81446 lr: 0.001000 batch_cost: 0.35830 sec, reader_cost: 0.00219 sec, ips: 44.65482 instance/sec.
[03/04 10:36:08] epoch:[  9/30 ] train step:330  loss: 0.78856 lr: 0.001000 batch_cost: 0.35520 sec, reader_cost: 0.00232 sec, ips: 45.04471 instance/sec.
[03/04 10:36:11] epoch:[  9/30 ] train step:340  loss: 1.12822 lr: 0.001000 batch_cost: 0.35508 sec, reader_cost: 0.00231 sec, ips: 45.05974 instance/sec.
[03/04 10:36:15] epoch:[  9/30 ] train step:350  loss: 0.90328 lr: 0.001000 batch_cost: 0.35541 sec, reader_cost: 0.00017 sec, ips: 45.01802 instance/sec.
[03/04 10:36:19] epoch:[  9/30 ] train step:360  loss: 0.86758 lr: 0.001000 batch_cost: 0.35556 sec, reader_cost: 0.00016 sec, ips: 44.99910 instance/sec.
[03/04 10:36:22] epoch:[  9/30 ] train step:370  loss: 0.98444 lr: 0.001000 batch_cost: 0.35497 sec, reader_cost: 0.00233 sec, ips: 45.07372 instance/sec.
[03/04 10:36:26] epoch:[  9/30 ] train step:380  loss: 0.91556 lr: 0.001000 batch_cost: 0.35467 sec, reader_cost: 0.00012 sec, ips: 45.11199 instance/sec.
[03/04 10:36:29] epoch:[  9/30 ] train step:390  loss: 0.85248 lr: 0.001000 batch_cost: 0.35466 sec, reader_cost: 0.00023 sec, ips: 45.11308 instance/sec.
[03/04 10:36:33] epoch:[  9/30 ] train step:400  loss: 1.57916 lr: 0.001000 batch_cost: 0.35526 sec, reader_cost: 0.00227 sec, ips: 45.03787 instance/sec.
[03/04 10:36:36] epoch:[  9/30 ] train step:410  loss: 0.75853 lr: 0.001000 batch_cost: 0.35837 sec, reader_cost: 0.00021 sec, ips: 44.64670 instance/sec.
[03/04 10:36:40] epoch:[  9/30 ] train step:420  loss: 0.75282 lr: 0.001000 batch_cost: 0.35588 sec, reader_cost: 0.00250 sec, ips: 44.95930 instance/sec.
[03/04 10:36:43] epoch:[  9/30 ] train step:430  loss: 0.66085 lr: 0.001000 batch_cost: 0.35611 sec, reader_cost: 0.00244 sec, ips: 44.93041 instance/sec.
[03/04 10:36:47] epoch:[  9/30 ] train step:440  loss: 0.90737 lr: 0.001000 batch_cost: 0.35339 sec, reader_cost: 0.00013 sec, ips: 45.27524 instance/sec.
[03/04 10:36:51] epoch:[  9/30 ] train step:450  loss: 1.37304 lr: 0.001000 batch_cost: 0.35522 sec, reader_cost: 0.00022 sec, ips: 45.04189 instance/sec.
[03/04 10:36:54] epoch:[  9/30 ] train step:460  loss: 0.75244 lr: 0.001000 batch_cost: 0.35304 sec, reader_cost: 0.00014 sec, ips: 45.32107 instance/sec.
[03/04 10:36:58] epoch:[  9/30 ] train step:470  loss: 0.87937 lr: 0.001000 batch_cost: 0.35257 sec, reader_cost: 0.00131 sec, ips: 45.38133 instance/sec.
[03/04 10:37:01] epoch:[  9/30 ] train step:480  loss: 0.85453 lr: 0.001000 batch_cost: 0.35629 sec, reader_cost: 0.00249 sec, ips: 44.90756 instance/sec.
[03/04 10:37:05] epoch:[  9/30 ] train step:490  loss: 0.91326 lr: 0.001000 batch_cost: 0.35614 sec, reader_cost: 0.00252 sec, ips: 44.92653 instance/sec.
[03/04 10:37:08] epoch:[  9/30 ] train step:500  loss: 0.93129 lr: 0.001000 batch_cost: 0.35445 sec, reader_cost: 0.00241 sec, ips: 45.14048 instance/sec.
[03/04 10:37:12] epoch:[  9/30 ] train step:510  loss: 1.08917 lr: 0.001000 batch_cost: 0.35592 sec, reader_cost: 0.00249 sec, ips: 44.95409 instance/sec.
[03/04 10:37:15] epoch:[  9/30 ] train step:520  loss: 0.93803 lr: 0.001000 batch_cost: 0.35621 sec, reader_cost: 0.00226 sec, ips: 44.91696 instance/sec.
[03/04 10:37:19] epoch:[  9/30 ] train step:530  loss: 1.19059 lr: 0.001000 batch_cost: 0.35511 sec, reader_cost: 0.00222 sec, ips: 45.05668 instance/sec.
[03/04 10:37:23] epoch:[  9/30 ] train step:540  loss: 1.06825 lr: 0.001000 batch_cost: 0.35676 sec, reader_cost: 0.00240 sec, ips: 44.84765 instance/sec.
[03/04 10:37:26] epoch:[  9/30 ] train step:550  loss: 0.78299 lr: 0.001000 batch_cost: 0.35558 sec, reader_cost: 0.00246 sec, ips: 44.99720 instance/sec.
[03/04 10:37:30] epoch:[  9/30 ] train step:560  loss: 0.96582 lr: 0.001000 batch_cost: 0.35538 sec, reader_cost: 0.00228 sec, ips: 45.02237 instance/sec.
[03/04 10:37:33] epoch:[  9/30 ] train step:570  loss: 0.71075 lr: 0.001000 batch_cost: 0.35427 sec, reader_cost: 0.00232 sec, ips: 45.16296 instance/sec.
[03/04 10:37:37] epoch:[  9/30 ] train step:580  loss: 1.01088 lr: 0.001000 batch_cost: 0.35614 sec, reader_cost: 0.00014 sec, ips: 44.92586 instance/sec.
[03/04 10:37:40] epoch:[  9/30 ] train step:590  loss: 1.11051 lr: 0.001000 batch_cost: 0.35182 sec, reader_cost: 0.00023 sec, ips: 45.47715 instance/sec.
[03/04 10:37:44] epoch:[  9/30 ] train step:600  loss: 0.94100 lr: 0.001000 batch_cost: 0.35559 sec, reader_cost: 0.00238 sec, ips: 44.99505 instance/sec.
[03/04 10:37:47] epoch:[  9/30 ] train step:610  loss: 0.94339 lr: 0.001000 batch_cost: 0.35531 sec, reader_cost: 0.00264 sec, ips: 45.03116 instance/sec.
[03/04 10:37:51] epoch:[  9/30 ] train step:620  loss: 0.95322 lr: 0.001000 batch_cost: 0.35424 sec, reader_cost: 0.00024 sec, ips: 45.16694 instance/sec.
[03/04 10:37:54] epoch:[  9/30 ] train step:630  loss: 0.82398 lr: 0.001000 batch_cost: 0.35351 sec, reader_cost: 0.00245 sec, ips: 45.26013 instance/sec.
[03/04 10:37:58] epoch:[  9/30 ] train step:640  loss: 0.98183 lr: 0.001000 batch_cost: 0.35809 sec, reader_cost: 0.00026 sec, ips: 44.68089 instance/sec.
[03/04 10:38:02] epoch:[  9/30 ] train step:650  loss: 1.02263 lr: 0.001000 batch_cost: 0.35506 sec, reader_cost: 0.00251 sec, ips: 45.06319 instance/sec.
[03/04 10:38:05] epoch:[  9/30 ] train step:660  loss: 1.08570 lr: 0.001000 batch_cost: 0.35300 sec, reader_cost: 0.00023 sec, ips: 45.32622 instance/sec.
[03/04 10:38:09] epoch:[  9/30 ] train step:670  loss: 0.71373 lr: 0.001000 batch_cost: 0.35201 sec, reader_cost: 0.00022 sec, ips: 45.45285 instance/sec.
[03/04 10:38:12] epoch:[  9/30 ] train step:680  loss: 0.81913 lr: 0.001000 batch_cost: 0.35067 sec, reader_cost: 0.00014 sec, ips: 45.62687 instance/sec.
[03/04 10:38:16] epoch:[  9/30 ] train step:690  loss: 1.06395 lr: 0.001000 batch_cost: 0.35411 sec, reader_cost: 0.00231 sec, ips: 45.18373 instance/sec.
[03/04 10:38:19] epoch:[  9/30 ] train step:700  loss: 0.79943 lr: 0.001000 batch_cost: 0.35431 sec, reader_cost: 0.00256 sec, ips: 45.15865 instance/sec.
[03/04 10:38:23] epoch:[  9/30 ] train step:710  loss: 0.92921 lr: 0.001000 batch_cost: 0.35518 sec, reader_cost: 0.00248 sec, ips: 45.04737 instance/sec.
[03/04 10:38:26] epoch:[  9/30 ] train step:720  loss: 0.89619 lr: 0.001000 batch_cost: 0.35288 sec, reader_cost: 0.00013 sec, ips: 45.34070 instance/sec.
[03/04 10:38:30] epoch:[  9/30 ] train step:730  loss: 0.82040 lr: 0.001000 batch_cost: 0.35630 sec, reader_cost: 0.00257 sec, ips: 44.90611 instance/sec.
[03/04 10:38:34] epoch:[  9/30 ] train step:740  loss: 0.87207 lr: 0.001000 batch_cost: 0.35472 sec, reader_cost: 0.00231 sec, ips: 45.10544 instance/sec.
[03/04 10:38:37] epoch:[  9/30 ] train step:750  loss: 1.24068 lr: 0.001000 batch_cost: 0.35767 sec, reader_cost: 0.00239 sec, ips: 44.73432 instance/sec.
[03/04 10:38:41] epoch:[  9/30 ] train step:760  loss: 0.99975 lr: 0.001000 batch_cost: 0.35072 sec, reader_cost: 0.00014 sec, ips: 45.62054 instance/sec.
[03/04 10:38:44] epoch:[  9/30 ] train step:770  loss: 0.97762 lr: 0.001000 batch_cost: 0.35759 sec, reader_cost: 0.00232 sec, ips: 44.74434 instance/sec.
[03/04 10:38:48] epoch:[  9/30 ] train step:780  loss: 0.97527 lr: 0.001000 batch_cost: 0.35167 sec, reader_cost: 0.00006 sec, ips: 45.49775 instance/sec.
[03/04 10:38:50] END epoch:9   train loss_avg: 0.95304  avg_batch_cost: 0.35218 sec, avg_reader_cost: 0.00007 sec, batch_cost_sum: 280.45359 sec, avg_ips: 44.89869 instance/sec.
[03/04 10:38:52] epoch:[ 10/30 ] train step:0    loss: 0.97140 lr: 0.001000 batch_cost: 1.46284 sec, reader_cost: 1.09831 sec, ips: 10.93762 instance/sec.
[03/04 10:38:55] epoch:[ 10/30 ] train step:10   loss: 0.68300 lr: 0.001000 batch_cost: 0.35490 sec, reader_cost: 0.00012 sec, ips: 45.08362 instance/sec.
[03/04 10:38:59] epoch:[ 10/30 ] train step:20   loss: 0.85718 lr: 0.001000 batch_cost: 0.35437 sec, reader_cost: 0.00012 sec, ips: 45.15096 instance/sec.
[03/04 10:39:02] epoch:[ 10/30 ] train step:30   loss: 0.86021 lr: 0.001000 batch_cost: 0.35506 sec, reader_cost: 0.00227 sec, ips: 45.06258 instance/sec.
[03/04 10:39:06] epoch:[ 10/30 ] train step:40   loss: 1.18979 lr: 0.001000 batch_cost: 0.35335 sec, reader_cost: 0.00010 sec, ips: 45.28077 instance/sec.
[03/04 10:39:09] epoch:[ 10/30 ] train step:50   loss: 1.31416 lr: 0.001000 batch_cost: 0.35595 sec, reader_cost: 0.00218 sec, ips: 44.95063 instance/sec.
[03/04 10:39:13] epoch:[ 10/30 ] train step:60   loss: 1.18660 lr: 0.001000 batch_cost: 0.35358 sec, reader_cost: 0.00011 sec, ips: 45.25134 instance/sec.
[03/04 10:39:16] epoch:[ 10/30 ] train step:70   loss: 0.86772 lr: 0.001000 batch_cost: 0.35338 sec, reader_cost: 0.00010 sec, ips: 45.27701 instance/sec.
[03/04 10:39:20] epoch:[ 10/30 ] train step:80   loss: 0.68638 lr: 0.001000 batch_cost: 0.35467 sec, reader_cost: 0.00011 sec, ips: 45.11272 instance/sec.
[03/04 10:39:23] epoch:[ 10/30 ] train step:90   loss: 0.92977 lr: 0.001000 batch_cost: 0.35466 sec, reader_cost: 0.00256 sec, ips: 45.11396 instance/sec.
[03/04 10:39:27] epoch:[ 10/30 ] train step:100  loss: 0.81780 lr: 0.001000 batch_cost: 0.35294 sec, reader_cost: 0.00010 sec, ips: 45.33305 instance/sec.
[03/04 10:39:30] epoch:[ 10/30 ] train step:110  loss: 0.91038 lr: 0.001000 batch_cost: 0.35497 sec, reader_cost: 0.00010 sec, ips: 45.07442 instance/sec.
[03/04 10:39:34] epoch:[ 10/30 ] train step:120  loss: 1.03902 lr: 0.001000 batch_cost: 0.35294 sec, reader_cost: 0.00010 sec, ips: 45.33314 instance/sec.
[03/04 10:39:38] epoch:[ 10/30 ] train step:130  loss: 0.73263 lr: 0.001000 batch_cost: 0.35492 sec, reader_cost: 0.00230 sec, ips: 45.08111 instance/sec.
[03/04 10:39:41] epoch:[ 10/30 ] train step:140  loss: 0.78889 lr: 0.001000 batch_cost: 0.35151 sec, reader_cost: 0.00012 sec, ips: 45.51809 instance/sec.
[03/04 10:39:45] epoch:[ 10/30 ] train step:150  loss: 0.77556 lr: 0.001000 batch_cost: 0.35328 sec, reader_cost: 0.00010 sec, ips: 45.29012 instance/sec.
[03/04 10:39:48] epoch:[ 10/30 ] train step:160  loss: 0.85860 lr: 0.001000 batch_cost: 0.35884 sec, reader_cost: 0.00059 sec, ips: 44.58871 instance/sec.
[03/04 10:39:52] epoch:[ 10/30 ] train step:170  loss: 0.91207 lr: 0.001000 batch_cost: 0.35446 sec, reader_cost: 0.00012 sec, ips: 45.13860 instance/sec.
[03/04 10:39:55] epoch:[ 10/30 ] train step:180  loss: 1.11029 lr: 0.001000 batch_cost: 0.35563 sec, reader_cost: 0.00235 sec, ips: 44.99038 instance/sec.
[03/04 10:39:59] epoch:[ 10/30 ] train step:190  loss: 1.03858 lr: 0.001000 batch_cost: 0.35369 sec, reader_cost: 0.00014 sec, ips: 45.23703 instance/sec.
[03/04 10:40:02] epoch:[ 10/30 ] train step:200  loss: 0.97662 lr: 0.001000 batch_cost: 0.35208 sec, reader_cost: 0.00010 sec, ips: 45.44420 instance/sec.
[03/04 10:40:06] epoch:[ 10/30 ] train step:210  loss: 0.89859 lr: 0.001000 batch_cost: 0.35497 sec, reader_cost: 0.00263 sec, ips: 45.07384 instance/sec.
[03/04 10:40:09] epoch:[ 10/30 ] train step:220  loss: 0.82236 lr: 0.001000 batch_cost: 0.35349 sec, reader_cost: 0.00026 sec, ips: 45.26327 instance/sec.
[03/04 10:40:13] epoch:[ 10/30 ] train step:230  loss: 0.93051 lr: 0.001000 batch_cost: 0.35287 sec, reader_cost: 0.00013 sec, ips: 45.34248 instance/sec.
[03/04 10:40:17] epoch:[ 10/30 ] train step:240  loss: 0.88027 lr: 0.001000 batch_cost: 0.35315 sec, reader_cost: 0.00022 sec, ips: 45.30679 instance/sec.
[03/04 10:40:20] epoch:[ 10/30 ] train step:250  loss: 1.02196 lr: 0.001000 batch_cost: 0.35566 sec, reader_cost: 0.00248 sec, ips: 44.98688 instance/sec.
[03/04 10:40:24] epoch:[ 10/30 ] train step:260  loss: 1.13890 lr: 0.001000 batch_cost: 0.35608 sec, reader_cost: 0.00236 sec, ips: 44.93405 instance/sec.
[03/04 10:40:27] epoch:[ 10/30 ] train step:270  loss: 0.86097 lr: 0.001000 batch_cost: 0.35398 sec, reader_cost: 0.00010 sec, ips: 45.20029 instance/sec.
[03/04 10:40:31] epoch:[ 10/30 ] train step:280  loss: 0.87815 lr: 0.001000 batch_cost: 0.35444 sec, reader_cost: 0.00010 sec, ips: 45.14182 instance/sec.
[03/04 10:40:34] epoch:[ 10/30 ] train step:290  loss: 0.95697 lr: 0.001000 batch_cost: 0.35523 sec, reader_cost: 0.00260 sec, ips: 45.04141 instance/sec.
[03/04 10:40:38] epoch:[ 10/30 ] train step:300  loss: 1.12524 lr: 0.001000 batch_cost: 0.35546 sec, reader_cost: 0.00042 sec, ips: 45.01208 instance/sec.
[03/04 10:40:41] epoch:[ 10/30 ] train step:310  loss: 1.06972 lr: 0.001000 batch_cost: 0.35486 sec, reader_cost: 0.00227 sec, ips: 45.08871 instance/sec.
[03/04 10:40:45] epoch:[ 10/30 ] train step:320  loss: 0.84487 lr: 0.001000 batch_cost: 0.35518 sec, reader_cost: 0.00012 sec, ips: 45.04731 instance/sec.
[03/04 10:40:48] epoch:[ 10/30 ] train step:330  loss: 0.94211 lr: 0.001000 batch_cost: 0.35884 sec, reader_cost: 0.00271 sec, ips: 44.58871 instance/sec.
[03/04 10:40:52] epoch:[ 10/30 ] train step:340  loss: 0.80686 lr: 0.001000 batch_cost: 0.35618 sec, reader_cost: 0.00259 sec, ips: 44.92093 instance/sec.
[03/04 10:40:56] epoch:[ 10/30 ] train step:350  loss: 1.00315 lr: 0.001000 batch_cost: 0.35455 sec, reader_cost: 0.00010 sec, ips: 45.12807 instance/sec.
[03/04 10:40:59] epoch:[ 10/30 ] train step:360  loss: 0.89250 lr: 0.001000 batch_cost: 0.35614 sec, reader_cost: 0.00012 sec, ips: 44.92644 instance/sec.
[03/04 10:41:03] epoch:[ 10/30 ] train step:370  loss: 1.22421 lr: 0.001000 batch_cost: 0.35297 sec, reader_cost: 0.00230 sec, ips: 45.32998 instance/sec.
[03/04 10:41:06] epoch:[ 10/30 ] train step:380  loss: 0.64166 lr: 0.001000 batch_cost: 0.35614 sec, reader_cost: 0.00267 sec, ips: 44.92638 instance/sec.
[03/04 10:41:10] epoch:[ 10/30 ] train step:390  loss: 0.93707 lr: 0.001000 batch_cost: 0.35506 sec, reader_cost: 0.00252 sec, ips: 45.06298 instance/sec.
[03/04 10:41:13] epoch:[ 10/30 ] train step:400  loss: 0.92146 lr: 0.001000 batch_cost: 0.35675 sec, reader_cost: 0.00260 sec, ips: 44.84900 instance/sec.
[03/04 10:41:17] epoch:[ 10/30 ] train step:410  loss: 0.90545 lr: 0.001000 batch_cost: 0.35360 sec, reader_cost: 0.00031 sec, ips: 45.24832 instance/sec.
[03/04 10:41:20] epoch:[ 10/30 ] train step:420  loss: 1.11110 lr: 0.001000 batch_cost: 0.35373 sec, reader_cost: 0.00265 sec, ips: 45.23282 instance/sec.
[03/04 10:41:24] epoch:[ 10/30 ] train step:430  loss: 1.14229 lr: 0.001000 batch_cost: 0.35499 sec, reader_cost: 0.00012 sec, ips: 45.07227 instance/sec.
[03/04 10:41:28] epoch:[ 10/30 ] train step:440  loss: 0.95111 lr: 0.001000 batch_cost: 0.35433 sec, reader_cost: 0.00258 sec, ips: 45.15543 instance/sec.
[03/04 10:41:31] epoch:[ 10/30 ] train step:450  loss: 0.70446 lr: 0.001000 batch_cost: 0.35399 sec, reader_cost: 0.00248 sec, ips: 45.19879 instance/sec.
[03/04 10:41:35] epoch:[ 10/30 ] train step:460  loss: 1.02212 lr: 0.001000 batch_cost: 0.35296 sec, reader_cost: 0.00238 sec, ips: 45.33096 instance/sec.
[03/04 10:41:38] epoch:[ 10/30 ] train step:470  loss: 0.80521 lr: 0.001000 batch_cost: 0.35558 sec, reader_cost: 0.00012 sec, ips: 44.99653 instance/sec.
[03/04 10:41:42] epoch:[ 10/30 ] train step:480  loss: 0.99812 lr: 0.001000 batch_cost: 0.35553 sec, reader_cost: 0.00251 sec, ips: 45.00284 instance/sec.
[03/04 10:41:45] epoch:[ 10/30 ] train step:490  loss: 0.92733 lr: 0.001000 batch_cost: 0.35547 sec, reader_cost: 0.00237 sec, ips: 45.01102 instance/sec.
[03/04 10:41:49] epoch:[ 10/30 ] train step:500  loss: 1.27790 lr: 0.001000 batch_cost: 0.35597 sec, reader_cost: 0.00253 sec, ips: 44.94756 instance/sec.
[03/04 10:41:52] epoch:[ 10/30 ] train step:510  loss: 1.12922 lr: 0.001000 batch_cost: 0.35497 sec, reader_cost: 0.00010 sec, ips: 45.07381 instance/sec.
[03/04 10:41:56] epoch:[ 10/30 ] train step:520  loss: 0.90208 lr: 0.001000 batch_cost: 0.35347 sec, reader_cost: 0.00254 sec, ips: 45.26577 instance/sec.
[03/04 10:41:59] epoch:[ 10/30 ] train step:530  loss: 0.80766 lr: 0.001000 batch_cost: 0.35755 sec, reader_cost: 0.00256 sec, ips: 44.74861 instance/sec.
[03/04 10:42:03] epoch:[ 10/30 ] train step:540  loss: 0.86223 lr: 0.001000 batch_cost: 0.35572 sec, reader_cost: 0.00028 sec, ips: 44.97892 instance/sec.
[03/04 10:42:07] epoch:[ 10/30 ] train step:550  loss: 0.83434 lr: 0.001000 batch_cost: 0.35567 sec, reader_cost: 0.00246 sec, ips: 44.98549 instance/sec.
[03/04 10:42:10] epoch:[ 10/30 ] train step:560  loss: 1.01338 lr: 0.001000 batch_cost: 0.35358 sec, reader_cost: 0.00227 sec, ips: 45.25167 instance/sec.
[03/04 10:42:14] epoch:[ 10/30 ] train step:570  loss: 0.92994 lr: 0.001000 batch_cost: 0.35542 sec, reader_cost: 0.00011 sec, ips: 45.01733 instance/sec.
[03/04 10:42:17] epoch:[ 10/30 ] train step:580  loss: 0.86812 lr: 0.001000 batch_cost: 0.35348 sec, reader_cost: 0.00023 sec, ips: 45.26413 instance/sec.
[03/04 10:42:21] epoch:[ 10/30 ] train step:590  loss: 0.98426 lr: 0.001000 batch_cost: 0.35613 sec, reader_cost: 0.00010 sec, ips: 44.92689 instance/sec.
[03/04 10:42:24] epoch:[ 10/30 ] train step:600  loss: 0.92626 lr: 0.001000 batch_cost: 0.35397 sec, reader_cost: 0.00261 sec, ips: 45.20163 instance/sec.
[03/04 10:42:28] epoch:[ 10/30 ] train step:610  loss: 0.90543 lr: 0.001000 batch_cost: 0.35544 sec, reader_cost: 0.00269 sec, ips: 45.01488 instance/sec.
[03/04 10:42:31] epoch:[ 10/30 ] train step:620  loss: 1.00656 lr: 0.001000 batch_cost: 0.35396 sec, reader_cost: 0.00024 sec, ips: 45.20233 instance/sec.
[03/04 10:42:35] epoch:[ 10/30 ] train step:630  loss: 1.12283 lr: 0.001000 batch_cost: 0.35306 sec, reader_cost: 0.00010 sec, ips: 45.31780 instance/sec.
[03/04 10:42:39] epoch:[ 10/30 ] train step:640  loss: 1.20008 lr: 0.001000 batch_cost: 0.35680 sec, reader_cost: 0.00442 sec, ips: 44.84289 instance/sec.
[03/04 10:42:42] epoch:[ 10/30 ] train step:650  loss: 0.92429 lr: 0.001000 batch_cost: 0.35759 sec, reader_cost: 0.00262 sec, ips: 44.74413 instance/sec.
[03/04 10:42:46] epoch:[ 10/30 ] train step:660  loss: 0.90630 lr: 0.001000 batch_cost: 0.35507 sec, reader_cost: 0.00258 sec, ips: 45.06092 instance/sec.
[03/04 10:42:49] epoch:[ 10/30 ] train step:670  loss: 0.78846 lr: 0.001000 batch_cost: 0.35424 sec, reader_cost: 0.00252 sec, ips: 45.16719 instance/sec.
[03/04 10:42:53] epoch:[ 10/30 ] train step:680  loss: 0.91299 lr: 0.001000 batch_cost: 0.35325 sec, reader_cost: 0.00054 sec, ips: 45.29410 instance/sec.
[03/04 10:42:56] epoch:[ 10/30 ] train step:690  loss: 0.85565 lr: 0.001000 batch_cost: 0.35458 sec, reader_cost: 0.00234 sec, ips: 45.12330 instance/sec.
[03/04 10:43:00] epoch:[ 10/30 ] train step:700  loss: 0.79391 lr: 0.001000 batch_cost: 0.35619 sec, reader_cost: 0.00265 sec, ips: 44.91976 instance/sec.
[03/04 10:43:03] epoch:[ 10/30 ] train step:710  loss: 1.39193 lr: 0.001000 batch_cost: 0.35525 sec, reader_cost: 0.00229 sec, ips: 45.03920 instance/sec.
[03/04 10:43:07] epoch:[ 10/30 ] train step:720  loss: 0.82618 lr: 0.001000 batch_cost: 0.35566 sec, reader_cost: 0.00270 sec, ips: 44.98652 instance/sec.
[03/04 10:43:10] epoch:[ 10/30 ] train step:730  loss: 1.14003 lr: 0.001000 batch_cost: 0.35347 sec, reader_cost: 0.00250 sec, ips: 45.26526 instance/sec.
[03/04 10:43:14] epoch:[ 10/30 ] train step:740  loss: 0.79015 lr: 0.001000 batch_cost: 0.36345 sec, reader_cost: 0.00256 sec, ips: 44.02244 instance/sec.
[03/04 10:43:18] epoch:[ 10/30 ] train step:750  loss: 0.80759 lr: 0.001000 batch_cost: 0.35481 sec, reader_cost: 0.00260 sec, ips: 45.09501 instance/sec.
[03/04 10:43:21] epoch:[ 10/30 ] train step:760  loss: 0.79004 lr: 0.001000 batch_cost: 0.35829 sec, reader_cost: 0.00274 sec, ips: 44.65621 instance/sec.
[03/04 10:43:25] epoch:[ 10/30 ] train step:770  loss: 0.79819 lr: 0.001000 batch_cost: 0.35465 sec, reader_cost: 0.00015 sec, ips: 45.11508 instance/sec.
[03/04 10:43:28] epoch:[ 10/30 ] train step:780  loss: 0.85934 lr: 0.001000 batch_cost: 0.35319 sec, reader_cost: 0.00006 sec, ips: 45.30122 instance/sec.
[03/04 10:43:30] END epoch:10  train loss_avg: 0.93383  avg_batch_cost: 0.35194 sec, avg_reader_cost: 0.00005 sec, batch_cost_sum: 280.25159 sec, avg_ips: 44.93106 instance/sec.
[03/04 10:43:32] epoch:[ 11/30 ] train step:0    loss: 1.02745 lr: 0.001000 batch_cost: 1.27746 sec, reader_cost: 0.90713 sec, ips: 12.52483 instance/sec.
[03/04 10:43:35] epoch:[ 11/30 ] train step:10   loss: 1.09530 lr: 0.001000 batch_cost: 0.35565 sec, reader_cost: 0.00228 sec, ips: 44.98742 instance/sec.
[03/04 10:43:39] epoch:[ 11/30 ] train step:20   loss: 0.92648 lr: 0.001000 batch_cost: 0.35785 sec, reader_cost: 0.00052 sec, ips: 44.71188 instance/sec.
[03/04 10:43:43] epoch:[ 11/30 ] train step:30   loss: 0.79652 lr: 0.001000 batch_cost: 0.35531 sec, reader_cost: 0.00031 sec, ips: 45.03065 instance/sec.
[03/04 10:43:46] epoch:[ 11/30 ] train step:40   loss: 1.02291 lr: 0.001000 batch_cost: 0.35460 sec, reader_cost: 0.00017 sec, ips: 45.12139 instance/sec.
[03/04 10:43:50] epoch:[ 11/30 ] train step:50   loss: 0.84947 lr: 0.001000 batch_cost: 0.35590 sec, reader_cost: 0.00014 sec, ips: 44.95605 instance/sec.
[03/04 10:43:53] epoch:[ 11/30 ] train step:60   loss: 0.98308 lr: 0.001000 batch_cost: 0.35549 sec, reader_cost: 0.00017 sec, ips: 45.00839 instance/sec.
[03/04 10:43:57] epoch:[ 11/30 ] train step:70   loss: 0.86254 lr: 0.001000 batch_cost: 0.35773 sec, reader_cost: 0.00249 sec, ips: 44.72627 instance/sec.
[03/04 10:44:00] epoch:[ 11/30 ] train step:80   loss: 1.02383 lr: 0.001000 batch_cost: 0.35485 sec, reader_cost: 0.00016 sec, ips: 45.08992 instance/sec.
[03/04 10:44:04] epoch:[ 11/30 ] train step:90   loss: 0.82875 lr: 0.001000 batch_cost: 0.35906 sec, reader_cost: 0.00227 sec, ips: 44.56026 instance/sec.
[03/04 10:44:08] epoch:[ 11/30 ] train step:100  loss: 0.95211 lr: 0.001000 batch_cost: 0.35578 sec, reader_cost: 0.00014 sec, ips: 44.97211 instance/sec.
[03/04 10:44:11] epoch:[ 11/30 ] train step:110  loss: 0.88317 lr: 0.001000 batch_cost: 0.35487 sec, reader_cost: 0.00016 sec, ips: 45.08710 instance/sec.
[03/04 10:44:15] epoch:[ 11/30 ] train step:120  loss: 1.33586 lr: 0.001000 batch_cost: 0.35802 sec, reader_cost: 0.00214 sec, ips: 44.69086 instance/sec.
[03/04 10:44:18] epoch:[ 11/30 ] train step:130  loss: 0.75112 lr: 0.001000 batch_cost: 0.35480 sec, reader_cost: 0.00016 sec, ips: 45.09574 instance/sec.
[03/04 10:44:22] epoch:[ 11/30 ] train step:140  loss: 0.82303 lr: 0.001000 batch_cost: 0.35617 sec, reader_cost: 0.00043 sec, ips: 44.92286 instance/sec.
[03/04 10:44:25] epoch:[ 11/30 ] train step:150  loss: 0.91004 lr: 0.001000 batch_cost: 0.35715 sec, reader_cost: 0.00249 sec, ips: 44.79897 instance/sec.
[03/04 10:44:29] epoch:[ 11/30 ] train step:160  loss: 0.78521 lr: 0.001000 batch_cost: 0.35795 sec, reader_cost: 0.00221 sec, ips: 44.69901 instance/sec.
[03/04 10:44:32] epoch:[ 11/30 ] train step:170  loss: 0.75023 lr: 0.001000 batch_cost: 0.35767 sec, reader_cost: 0.00255 sec, ips: 44.73381 instance/sec.
[03/04 10:44:36] epoch:[ 11/30 ] train step:180  loss: 0.79027 lr: 0.001000 batch_cost: 0.35673 sec, reader_cost: 0.00273 sec, ips: 44.85194 instance/sec.
[03/04 10:44:40] epoch:[ 11/30 ] train step:190  loss: 0.87101 lr: 0.001000 batch_cost: 0.35609 sec, reader_cost: 0.00254 sec, ips: 44.93302 instance/sec.
[03/04 10:44:43] epoch:[ 11/30 ] train step:200  loss: 0.80760 lr: 0.001000 batch_cost: 0.35409 sec, reader_cost: 0.00043 sec, ips: 45.18583 instance/sec.
[03/04 10:44:47] epoch:[ 11/30 ] train step:210  loss: 1.07098 lr: 0.001000 batch_cost: 0.35703 sec, reader_cost: 0.00017 sec, ips: 44.81477 instance/sec.
[03/04 10:44:50] epoch:[ 11/30 ] train step:220  loss: 0.76423 lr: 0.001000 batch_cost: 0.35580 sec, reader_cost: 0.00018 sec, ips: 44.96855 instance/sec.
[03/04 10:44:54] epoch:[ 11/30 ] train step:230  loss: 0.83071 lr: 0.001000 batch_cost: 0.35725 sec, reader_cost: 0.00014 sec, ips: 44.78666 instance/sec.
[03/04 10:44:57] epoch:[ 11/30 ] train step:240  loss: 0.86066 lr: 0.001000 batch_cost: 0.35747 sec, reader_cost: 0.00227 sec, ips: 44.75849 instance/sec.
[03/04 10:45:01] epoch:[ 11/30 ] train step:250  loss: 1.29952 lr: 0.001000 batch_cost: 0.35655 sec, reader_cost: 0.00027 sec, ips: 44.87491 instance/sec.
[03/04 10:45:05] epoch:[ 11/30 ] train step:260  loss: 0.82562 lr: 0.001000 batch_cost: 0.35628 sec, reader_cost: 0.00017 sec, ips: 44.90852 instance/sec.
[03/04 10:45:08] epoch:[ 11/30 ] train step:270  loss: 0.85507 lr: 0.001000 batch_cost: 0.35792 sec, reader_cost: 0.00249 sec, ips: 44.70285 instance/sec.
[03/04 10:45:12] epoch:[ 11/30 ] train step:280  loss: 0.76678 lr: 0.001000 batch_cost: 0.35846 sec, reader_cost: 0.00228 sec, ips: 44.63584 instance/sec.
[03/04 10:45:15] epoch:[ 11/30 ] train step:290  loss: 0.89613 lr: 0.001000 batch_cost: 0.35521 sec, reader_cost: 0.00239 sec, ips: 45.04371 instance/sec.
[03/04 10:45:19] epoch:[ 11/30 ] train step:300  loss: 1.04720 lr: 0.001000 batch_cost: 0.35224 sec, reader_cost: 0.00023 sec, ips: 45.42298 instance/sec.
[03/04 10:45:22] epoch:[ 11/30 ] train step:310  loss: 0.94452 lr: 0.001000 batch_cost: 0.35654 sec, reader_cost: 0.00043 sec, ips: 44.87569 instance/sec.
[03/04 10:45:26] epoch:[ 11/30 ] train step:320  loss: 0.78789 lr: 0.001000 batch_cost: 0.36261 sec, reader_cost: 0.00244 sec, ips: 44.12465 instance/sec.
[03/04 10:45:30] epoch:[ 11/30 ] train step:330  loss: 0.88280 lr: 0.001000 batch_cost: 0.35630 sec, reader_cost: 0.00030 sec, ips: 44.90614 instance/sec.
[03/04 10:45:33] epoch:[ 11/30 ] train step:340  loss: 1.03490 lr: 0.001000 batch_cost: 0.35936 sec, reader_cost: 0.00235 sec, ips: 44.52387 instance/sec.
[03/04 10:45:37] epoch:[ 11/30 ] train step:350  loss: 0.98353 lr: 0.001000 batch_cost: 0.35782 sec, reader_cost: 0.00269 sec, ips: 44.71531 instance/sec.
[03/04 10:45:40] epoch:[ 11/30 ] train step:360  loss: 0.91114 lr: 0.001000 batch_cost: 0.36078 sec, reader_cost: 0.00265 sec, ips: 44.34818 instance/sec.
[03/04 10:45:44] epoch:[ 11/30 ] train step:370  loss: 1.03171 lr: 0.001000 batch_cost: 0.35693 sec, reader_cost: 0.00246 sec, ips: 44.82659 instance/sec.
[03/04 10:45:48] epoch:[ 11/30 ] train step:380  loss: 0.96512 lr: 0.001000 batch_cost: 0.35483 sec, reader_cost: 0.00243 sec, ips: 45.09204 instance/sec.
[03/04 10:45:51] epoch:[ 11/30 ] train step:390  loss: 0.89445 lr: 0.001000 batch_cost: 0.35785 sec, reader_cost: 0.00239 sec, ips: 44.71119 instance/sec.
[03/04 10:45:55] epoch:[ 11/30 ] train step:400  loss: 1.25782 lr: 0.001000 batch_cost: 0.35569 sec, reader_cost: 0.00228 sec, ips: 44.98251 instance/sec.
[03/04 10:45:58] epoch:[ 11/30 ] train step:410  loss: 0.77477 lr: 0.001000 batch_cost: 0.35834 sec, reader_cost: 0.00234 sec, ips: 44.64979 instance/sec.
[03/04 10:46:02] epoch:[ 11/30 ] train step:420  loss: 0.98247 lr: 0.001000 batch_cost: 0.35539 sec, reader_cost: 0.00019 sec, ips: 45.02132 instance/sec.
[03/04 10:46:05] epoch:[ 11/30 ] train step:430  loss: 0.98791 lr: 0.001000 batch_cost: 0.35826 sec, reader_cost: 0.00244 sec, ips: 44.65990 instance/sec.
[03/04 10:46:09] epoch:[ 11/30 ] train step:440  loss: 1.08863 lr: 0.001000 batch_cost: 0.35776 sec, reader_cost: 0.00268 sec, ips: 44.72249 instance/sec.
[03/04 10:46:13] epoch:[ 11/30 ] train step:450  loss: 1.05474 lr: 0.001000 batch_cost: 0.35571 sec, reader_cost: 0.00252 sec, ips: 44.98061 instance/sec.
[03/04 10:46:16] epoch:[ 11/30 ] train step:460  loss: 0.83929 lr: 0.001000 batch_cost: 0.35889 sec, reader_cost: 0.00254 sec, ips: 44.58193 instance/sec.
[03/04 10:46:20] epoch:[ 11/30 ] train step:470  loss: 0.81165 lr: 0.001000 batch_cost: 0.35671 sec, reader_cost: 0.00232 sec, ips: 44.85464 instance/sec.
[03/04 10:46:23] epoch:[ 11/30 ] train step:480  loss: 0.86625 lr: 0.001000 batch_cost: 0.35639 sec, reader_cost: 0.00270 sec, ips: 44.89422 instance/sec.
[03/04 10:46:27] epoch:[ 11/30 ] train step:490  loss: 0.84224 lr: 0.001000 batch_cost: 0.36347 sec, reader_cost: 0.00243 sec, ips: 44.02030 instance/sec.
[03/04 10:46:30] epoch:[ 11/30 ] train step:500  loss: 0.86249 lr: 0.001000 batch_cost: 0.35372 sec, reader_cost: 0.00242 sec, ips: 45.23386 instance/sec.
[03/04 10:46:34] epoch:[ 11/30 ] train step:510  loss: 0.99571 lr: 0.001000 batch_cost: 0.35978 sec, reader_cost: 0.00248 sec, ips: 44.47111 instance/sec.
[03/04 10:46:38] epoch:[ 11/30 ] train step:520  loss: 0.95915 lr: 0.001000 batch_cost: 0.35642 sec, reader_cost: 0.00271 sec, ips: 44.89145 instance/sec.
[03/04 10:46:41] epoch:[ 11/30 ] train step:530  loss: 0.91615 lr: 0.001000 batch_cost: 0.35430 sec, reader_cost: 0.00013 sec, ips: 45.15947 instance/sec.
[03/04 10:46:45] epoch:[ 11/30 ] train step:540  loss: 0.76870 lr: 0.001000 batch_cost: 0.35402 sec, reader_cost: 0.00013 sec, ips: 45.19566 instance/sec.
[03/04 10:46:48] epoch:[ 11/30 ] train step:550  loss: 1.04944 lr: 0.001000 batch_cost: 0.35454 sec, reader_cost: 0.00013 sec, ips: 45.12849 instance/sec.
[03/04 10:46:52] epoch:[ 11/30 ] train step:560  loss: 0.88660 lr: 0.001000 batch_cost: 0.35833 sec, reader_cost: 0.00251 sec, ips: 44.65164 instance/sec.
[03/04 10:46:55] epoch:[ 11/30 ] train step:570  loss: 0.98892 lr: 0.001000 batch_cost: 0.35411 sec, reader_cost: 0.00255 sec, ips: 45.18361 instance/sec.
[03/04 10:46:59] epoch:[ 11/30 ] train step:580  loss: 0.88650 lr: 0.001000 batch_cost: 0.35882 sec, reader_cost: 0.00277 sec, ips: 44.59058 instance/sec.
[03/04 10:47:03] epoch:[ 11/30 ] train step:590  loss: 1.24240 lr: 0.001000 batch_cost: 0.35739 sec, reader_cost: 0.00247 sec, ips: 44.76960 instance/sec.
[03/04 10:47:06] epoch:[ 11/30 ] train step:600  loss: 1.04548 lr: 0.001000 batch_cost: 0.35849 sec, reader_cost: 0.00275 sec, ips: 44.63159 instance/sec.
[03/04 10:47:10] epoch:[ 11/30 ] train step:610  loss: 0.79126 lr: 0.001000 batch_cost: 0.35782 sec, reader_cost: 0.00271 sec, ips: 44.71495 instance/sec.
[03/04 10:47:13] epoch:[ 11/30 ] train step:620  loss: 0.82846 lr: 0.001000 batch_cost: 0.35668 sec, reader_cost: 0.00030 sec, ips: 44.85809 instance/sec.
[03/04 10:47:17] epoch:[ 11/30 ] train step:630  loss: 1.08184 lr: 0.001000 batch_cost: 0.35984 sec, reader_cost: 0.00019 sec, ips: 44.46377 instance/sec.
[03/04 10:47:20] epoch:[ 11/30 ] train step:640  loss: 1.13697 lr: 0.001000 batch_cost: 0.35621 sec, reader_cost: 0.00252 sec, ips: 44.91702 instance/sec.
[03/04 10:47:24] epoch:[ 11/30 ] train step:650  loss: 1.21441 lr: 0.001000 batch_cost: 0.35492 sec, reader_cost: 0.00029 sec, ips: 45.08068 instance/sec.
[03/04 10:47:28] epoch:[ 11/30 ] train step:660  loss: 0.91746 lr: 0.001000 batch_cost: 0.35808 sec, reader_cost: 0.00018 sec, ips: 44.68238 instance/sec.
[03/04 10:47:31] epoch:[ 11/30 ] train step:670  loss: 0.86875 lr: 0.001000 batch_cost: 0.35880 sec, reader_cost: 0.00238 sec, ips: 44.59369 instance/sec.
[03/04 10:47:35] epoch:[ 11/30 ] train step:680  loss: 0.78658 lr: 0.001000 batch_cost: 0.36134 sec, reader_cost: 0.00253 sec, ips: 44.27915 instance/sec.
[03/04 10:47:38] epoch:[ 11/30 ] train step:690  loss: 0.96994 lr: 0.001000 batch_cost: 0.35717 sec, reader_cost: 0.00278 sec, ips: 44.79682 instance/sec.
[03/04 10:47:42] epoch:[ 11/30 ] train step:700  loss: 1.01549 lr: 0.001000 batch_cost: 0.35843 sec, reader_cost: 0.00277 sec, ips: 44.63931 instance/sec.
[03/04 10:47:45] epoch:[ 11/30 ] train step:710  loss: 0.92494 lr: 0.001000 batch_cost: 0.35887 sec, reader_cost: 0.00249 sec, ips: 44.58430 instance/sec.
[03/04 10:47:49] epoch:[ 11/30 ] train step:720  loss: 1.07832 lr: 0.001000 batch_cost: 0.35772 sec, reader_cost: 0.00261 sec, ips: 44.72794 instance/sec.
[03/04 10:47:53] epoch:[ 11/30 ] train step:730  loss: 0.93125 lr: 0.001000 batch_cost: 0.36027 sec, reader_cost: 0.00245 sec, ips: 44.41090 instance/sec.
[03/04 10:47:56] epoch:[ 11/30 ] train step:740  loss: 0.87545 lr: 0.001000 batch_cost: 0.35610 sec, reader_cost: 0.00262 sec, ips: 44.93143 instance/sec.
[03/04 10:48:00] epoch:[ 11/30 ] train step:750  loss: 0.96701 lr: 0.001000 batch_cost: 0.35507 sec, reader_cost: 0.00051 sec, ips: 45.06201 instance/sec.
[03/04 10:48:03] epoch:[ 11/30 ] train step:760  loss: 0.89100 lr: 0.001000 batch_cost: 0.35944 sec, reader_cost: 0.00220 sec, ips: 44.51403 instance/sec.
[03/04 10:48:07] epoch:[ 11/30 ] train step:770  loss: 0.86639 lr: 0.001000 batch_cost: 0.35488 sec, reader_cost: 0.00023 sec, ips: 45.08514 instance/sec.
[03/04 10:48:10] epoch:[ 11/30 ] train step:780  loss: 0.97815 lr: 0.001000 batch_cost: 0.35493 sec, reader_cost: 0.00008 sec, ips: 45.07878 instance/sec.
[03/04 10:48:13] END epoch:11  train loss_avg: 0.92251  avg_batch_cost: 0.35338 sec, avg_reader_cost: 0.00007 sec, batch_cost_sum: 281.98165 sec, avg_ips: 44.65539 instance/sec.
[03/04 10:48:14] epoch:[ 12/30 ] train step:0    loss: 0.88488 lr: 0.001000 batch_cost: 1.35813 sec, reader_cost: 0.98798 sec, ips: 11.78087 instance/sec.
[03/04 10:48:18] epoch:[ 12/30 ] train step:10   loss: 0.68759 lr: 0.001000 batch_cost: 0.35734 sec, reader_cost: 0.00043 sec, ips: 44.77545 instance/sec.
[03/04 10:48:21] epoch:[ 12/30 ] train step:20   loss: 0.89532 lr: 0.001000 batch_cost: 0.35858 sec, reader_cost: 0.00236 sec, ips: 44.62043 instance/sec.
[03/04 10:48:25] epoch:[ 12/30 ] train step:30   loss: 0.88628 lr: 0.001000 batch_cost: 0.35748 sec, reader_cost: 0.00014 sec, ips: 44.75810 instance/sec.
[03/04 10:48:29] epoch:[ 12/30 ] train step:40   loss: 0.86740 lr: 0.001000 batch_cost: 0.35815 sec, reader_cost: 0.00222 sec, ips: 44.67396 instance/sec.
[03/04 10:48:32] epoch:[ 12/30 ] train step:50   loss: 0.74590 lr: 0.001000 batch_cost: 0.35810 sec, reader_cost: 0.00239 sec, ips: 44.68086 instance/sec.
[03/04 10:48:36] epoch:[ 12/30 ] train step:60   loss: 0.74354 lr: 0.001000 batch_cost: 0.35563 sec, reader_cost: 0.00014 sec, ips: 44.99032 instance/sec.
[03/04 10:48:39] epoch:[ 12/30 ] train step:70   loss: 0.74546 lr: 0.001000 batch_cost: 0.35638 sec, reader_cost: 0.00015 sec, ips: 44.89572 instance/sec.
[03/04 10:48:43] epoch:[ 12/30 ] train step:80   loss: 0.80335 lr: 0.001000 batch_cost: 0.35923 sec, reader_cost: 0.00239 sec, ips: 44.53911 instance/sec.
[03/04 10:48:46] epoch:[ 12/30 ] train step:90   loss: 0.88073 lr: 0.001000 batch_cost: 0.35886 sec, reader_cost: 0.00238 sec, ips: 44.58527 instance/sec.
[03/04 10:48:50] epoch:[ 12/30 ] train step:100  loss: 0.74996 lr: 0.001000 batch_cost: 0.35521 sec, reader_cost: 0.00013 sec, ips: 45.04404 instance/sec.
[03/04 10:48:54] epoch:[ 12/30 ] train step:110  loss: 0.86887 lr: 0.001000 batch_cost: 0.35425 sec, reader_cost: 0.00013 sec, ips: 45.16603 instance/sec.
[03/04 10:48:57] epoch:[ 12/30 ] train step:120  loss: 0.99270 lr: 0.001000 batch_cost: 0.35561 sec, reader_cost: 0.00013 sec, ips: 44.99364 instance/sec.
[03/04 10:49:01] epoch:[ 12/30 ] train step:130  loss: 0.80433 lr: 0.001000 batch_cost: 0.35810 sec, reader_cost: 0.00248 sec, ips: 44.68068 instance/sec.
[03/04 10:49:04] epoch:[ 12/30 ] train step:140  loss: 1.10395 lr: 0.001000 batch_cost: 0.35720 sec, reader_cost: 0.00014 sec, ips: 44.79293 instance/sec.
[03/04 10:49:08] epoch:[ 12/30 ] train step:150  loss: 1.00697 lr: 0.001000 batch_cost: 0.35548 sec, reader_cost: 0.00011 sec, ips: 45.00969 instance/sec.
[03/04 10:49:11] epoch:[ 12/30 ] train step:160  loss: 0.77570 lr: 0.001000 batch_cost: 0.35879 sec, reader_cost: 0.00237 sec, ips: 44.59375 instance/sec.
[03/04 10:49:15] epoch:[ 12/30 ] train step:170  loss: 0.71019 lr: 0.001000 batch_cost: 0.35894 sec, reader_cost: 0.00233 sec, ips: 44.57603 instance/sec.
[03/04 10:49:19] epoch:[ 12/30 ] train step:180  loss: 0.79688 lr: 0.001000 batch_cost: 0.35427 sec, reader_cost: 0.00024 sec, ips: 45.16348 instance/sec.
[03/04 10:49:22] epoch:[ 12/30 ] train step:190  loss: 1.06372 lr: 0.001000 batch_cost: 0.35533 sec, reader_cost: 0.00012 sec, ips: 45.02908 instance/sec.
[03/04 10:49:26] epoch:[ 12/30 ] train step:200  loss: 0.74219 lr: 0.001000 batch_cost: 0.35859 sec, reader_cost: 0.00015 sec, ips: 44.61907 instance/sec.
[03/04 10:49:29] epoch:[ 12/30 ] train step:210  loss: 0.73478 lr: 0.001000 batch_cost: 0.35797 sec, reader_cost: 0.00232 sec, ips: 44.69684 instance/sec.
[03/04 10:49:33] epoch:[ 12/30 ] train step:220  loss: 0.78734 lr: 0.001000 batch_cost: 0.35863 sec, reader_cost: 0.00257 sec, ips: 44.61429 instance/sec.
[03/04 10:49:36] epoch:[ 12/30 ] train step:230  loss: 0.88376 lr: 0.001000 batch_cost: 0.35490 sec, reader_cost: 0.00012 sec, ips: 45.08259 instance/sec.
[03/04 10:49:40] epoch:[ 12/30 ] train step:240  loss: 0.80372 lr: 0.001000 batch_cost: 0.35561 sec, reader_cost: 0.00231 sec, ips: 44.99309 instance/sec.
[03/04 10:49:44] epoch:[ 12/30 ] train step:250  loss: 1.05766 lr: 0.001000 batch_cost: 0.35905 sec, reader_cost: 0.00245 sec, ips: 44.56147 instance/sec.
[03/04 10:49:47] epoch:[ 12/30 ] train step:260  loss: 0.80438 lr: 0.001000 batch_cost: 0.35588 sec, reader_cost: 0.00238 sec, ips: 44.95852 instance/sec.
[03/04 10:49:51] epoch:[ 12/30 ] train step:270  loss: 0.70974 lr: 0.001000 batch_cost: 0.35765 sec, reader_cost: 0.00246 sec, ips: 44.73677 instance/sec.
[03/04 10:49:54] epoch:[ 12/30 ] train step:280  loss: 0.95399 lr: 0.001000 batch_cost: 0.35774 sec, reader_cost: 0.00251 sec, ips: 44.72466 instance/sec.
[03/04 10:49:58] epoch:[ 12/30 ] train step:290  loss: 1.03660 lr: 0.001000 batch_cost: 0.35861 sec, reader_cost: 0.00235 sec, ips: 44.61613 instance/sec.
[03/04 10:50:01] epoch:[ 12/30 ] train step:300  loss: 0.57639 lr: 0.001000 batch_cost: 0.35830 sec, reader_cost: 0.00256 sec, ips: 44.65499 instance/sec.
[03/04 10:50:05] epoch:[ 12/30 ] train step:310  loss: 0.83000 lr: 0.001000 batch_cost: 0.35780 sec, reader_cost: 0.00226 sec, ips: 44.71760 instance/sec.
[03/04 10:50:09] epoch:[ 12/30 ] train step:320  loss: 1.30483 lr: 0.001000 batch_cost: 0.35782 sec, reader_cost: 0.00013 sec, ips: 44.71513 instance/sec.
[03/04 10:50:12] epoch:[ 12/30 ] train step:330  loss: 0.80634 lr: 0.001000 batch_cost: 0.35917 sec, reader_cost: 0.00030 sec, ips: 44.54656 instance/sec.
[03/04 10:50:16] epoch:[ 12/30 ] train step:340  loss: 0.84471 lr: 0.001000 batch_cost: 0.35639 sec, reader_cost: 0.00246 sec, ips: 44.89488 instance/sec.
[03/04 10:50:19] epoch:[ 12/30 ] train step:350  loss: 0.73196 lr: 0.001000 batch_cost: 0.35770 sec, reader_cost: 0.00245 sec, ips: 44.72991 instance/sec.
[03/04 10:50:23] epoch:[ 12/30 ] train step:360  loss: 0.81329 lr: 0.001000 batch_cost: 0.35613 sec, reader_cost: 0.00016 sec, ips: 44.92728 instance/sec.
[03/04 10:50:26] epoch:[ 12/30 ] train step:370  loss: 0.91710 lr: 0.001000 batch_cost: 0.36096 sec, reader_cost: 0.00246 sec, ips: 44.32662 instance/sec.
[03/04 10:50:30] epoch:[ 12/30 ] train step:380  loss: 0.72319 lr: 0.001000 batch_cost: 0.35463 sec, reader_cost: 0.00261 sec, ips: 45.11714 instance/sec.
[03/04 10:50:34] epoch:[ 12/30 ] train step:390  loss: 0.74452 lr: 0.001000 batch_cost: 0.35672 sec, reader_cost: 0.00251 sec, ips: 44.85341 instance/sec.
[03/04 10:50:37] epoch:[ 12/30 ] train step:400  loss: 0.72024 lr: 0.001000 batch_cost: 0.35594 sec, reader_cost: 0.00012 sec, ips: 44.95180 instance/sec.
[03/04 10:50:41] epoch:[ 12/30 ] train step:410  loss: 0.95103 lr: 0.001000 batch_cost: 0.35836 sec, reader_cost: 0.00231 sec, ips: 44.64780 instance/sec.
[03/04 10:50:44] epoch:[ 12/30 ] train step:420  loss: 1.11701 lr: 0.001000 batch_cost: 0.35962 sec, reader_cost: 0.00260 sec, ips: 44.49134 instance/sec.
[03/04 10:50:48] epoch:[ 12/30 ] train step:430  loss: 0.96587 lr: 0.001000 batch_cost: 0.35964 sec, reader_cost: 0.00033 sec, ips: 44.48859 instance/sec.
[03/04 10:50:51] epoch:[ 12/30 ] train step:440  loss: 0.74560 lr: 0.001000 batch_cost: 0.35368 sec, reader_cost: 0.00014 sec, ips: 45.23923 instance/sec.
[03/04 10:50:55] epoch:[ 12/30 ] train step:450  loss: 0.83064 lr: 0.001000 batch_cost: 0.35938 sec, reader_cost: 0.00245 sec, ips: 44.52121 instance/sec.
[03/04 10:50:59] epoch:[ 12/30 ] train step:460  loss: 0.88817 lr: 0.001000 batch_cost: 0.35716 sec, reader_cost: 0.00260 sec, ips: 44.79799 instance/sec.
[03/04 10:51:02] epoch:[ 12/30 ] train step:470  loss: 0.84327 lr: 0.001000 batch_cost: 0.35868 sec, reader_cost: 0.00227 sec, ips: 44.60741 instance/sec.
[03/04 10:51:06] epoch:[ 12/30 ] train step:480  loss: 0.85064 lr: 0.001000 batch_cost: 0.35618 sec, reader_cost: 0.00011 sec, ips: 44.92114 instance/sec.
[03/04 10:51:09] epoch:[ 12/30 ] train step:490  loss: 1.03272 lr: 0.001000 batch_cost: 0.36096 sec, reader_cost: 0.00233 sec, ips: 44.32680 instance/sec.
[03/04 10:51:13] epoch:[ 12/30 ] train step:500  loss: 0.82694 lr: 0.001000 batch_cost: 0.35622 sec, reader_cost: 0.00225 sec, ips: 44.91585 instance/sec.
[03/04 10:51:16] epoch:[ 12/30 ] train step:510  loss: 0.93075 lr: 0.001000 batch_cost: 0.35585 sec, reader_cost: 0.00254 sec, ips: 44.96298 instance/sec.
[03/04 10:51:20] epoch:[ 12/30 ] train step:520  loss: 0.88153 lr: 0.001000 batch_cost: 0.36051 sec, reader_cost: 0.00254 sec, ips: 44.38179 instance/sec.
[03/04 10:51:24] epoch:[ 12/30 ] train step:530  loss: 0.96285 lr: 0.001000 batch_cost: 0.35804 sec, reader_cost: 0.00252 sec, ips: 44.68758 instance/sec.
[03/04 10:51:27] epoch:[ 12/30 ] train step:540  loss: 0.77831 lr: 0.001000 batch_cost: 0.35618 sec, reader_cost: 0.00238 sec, ips: 44.92099 instance/sec.
[03/04 10:51:31] epoch:[ 12/30 ] train step:550  loss: 1.74260 lr: 0.001000 batch_cost: 0.35594 sec, reader_cost: 0.00253 sec, ips: 44.95171 instance/sec.
[03/04 10:51:34] epoch:[ 12/30 ] train step:560  loss: 0.87935 lr: 0.001000 batch_cost: 0.35909 sec, reader_cost: 0.00276 sec, ips: 44.55763 instance/sec.
[03/04 10:51:38] epoch:[ 12/30 ] train step:570  loss: 0.87939 lr: 0.001000 batch_cost: 0.35945 sec, reader_cost: 0.00247 sec, ips: 44.51226 instance/sec.
[03/04 10:51:41] epoch:[ 12/30 ] train step:580  loss: 0.83969 lr: 0.001000 batch_cost: 0.35626 sec, reader_cost: 0.00269 sec, ips: 44.91137 instance/sec.
[03/04 10:51:45] epoch:[ 12/30 ] train step:590  loss: 1.06308 lr: 0.001000 batch_cost: 0.35513 sec, reader_cost: 0.00051 sec, ips: 45.05420 instance/sec.
[03/04 10:51:49] epoch:[ 12/30 ] train step:600  loss: 0.90806 lr: 0.001000 batch_cost: 0.35830 sec, reader_cost: 0.00261 sec, ips: 44.65591 instance/sec.
[03/04 10:51:52] epoch:[ 12/30 ] train step:610  loss: 0.72971 lr: 0.001000 batch_cost: 0.35921 sec, reader_cost: 0.00249 sec, ips: 44.54248 instance/sec.
[03/04 10:51:56] epoch:[ 12/30 ] train step:620  loss: 0.92824 lr: 0.001000 batch_cost: 0.35867 sec, reader_cost: 0.00245 sec, ips: 44.60981 instance/sec.
[03/04 10:51:59] epoch:[ 12/30 ] train step:630  loss: 0.88239 lr: 0.001000 batch_cost: 0.35667 sec, reader_cost: 0.00256 sec, ips: 44.85932 instance/sec.
[03/04 10:52:03] epoch:[ 12/30 ] train step:640  loss: 0.94523 lr: 0.001000 batch_cost: 0.35599 sec, reader_cost: 0.00231 sec, ips: 44.94545 instance/sec.
[03/04 10:52:07] epoch:[ 12/30 ] train step:650  loss: 0.75670 lr: 0.001000 batch_cost: 0.36043 sec, reader_cost: 0.00220 sec, ips: 44.39139 instance/sec.
[03/04 10:52:10] epoch:[ 12/30 ] train step:660  loss: 0.73937 lr: 0.001000 batch_cost: 0.35800 sec, reader_cost: 0.00227 sec, ips: 44.69321 instance/sec.
[03/04 10:52:14] epoch:[ 12/30 ] train step:670  loss: 0.82318 lr: 0.001000 batch_cost: 0.35762 sec, reader_cost: 0.00024 sec, ips: 44.74044 instance/sec.
[03/04 10:52:17] epoch:[ 12/30 ] train step:680  loss: 0.94559 lr: 0.001000 batch_cost: 0.35491 sec, reader_cost: 0.00264 sec, ips: 45.08165 instance/sec.
[03/04 10:52:21] epoch:[ 12/30 ] train step:690  loss: 0.80008 lr: 0.001000 batch_cost: 0.35898 sec, reader_cost: 0.00238 sec, ips: 44.57053 instance/sec.
[03/04 10:52:24] epoch:[ 12/30 ] train step:700  loss: 0.87144 lr: 0.001000 batch_cost: 0.35778 sec, reader_cost: 0.00249 sec, ips: 44.72022 instance/sec.
[03/04 10:52:28] epoch:[ 12/30 ] train step:710  loss: 0.77669 lr: 0.001000 batch_cost: 0.35762 sec, reader_cost: 0.00255 sec, ips: 44.73993 instance/sec.
[03/04 10:52:32] epoch:[ 12/30 ] train step:720  loss: 0.89227 lr: 0.001000 batch_cost: 0.35676 sec, reader_cost: 0.00245 sec, ips: 44.84837 instance/sec.
[03/04 10:52:35] epoch:[ 12/30 ] train step:730  loss: 0.99818 lr: 0.001000 batch_cost: 0.35899 sec, reader_cost: 0.00257 sec, ips: 44.56994 instance/sec.
[03/04 10:52:39] epoch:[ 12/30 ] train step:740  loss: 0.97270 lr: 0.001000 batch_cost: 0.35787 sec, reader_cost: 0.00265 sec, ips: 44.70869 instance/sec.
[03/04 10:52:42] epoch:[ 12/30 ] train step:750  loss: 0.95715 lr: 0.001000 batch_cost: 0.35430 sec, reader_cost: 0.00014 sec, ips: 45.15898 instance/sec.
[03/04 10:52:46] epoch:[ 12/30 ] train step:760  loss: 0.82991 lr: 0.001000 batch_cost: 0.35876 sec, reader_cost: 0.00240 sec, ips: 44.59796 instance/sec.
[03/04 10:52:49] epoch:[ 12/30 ] train step:770  loss: 0.84381 lr: 0.001000 batch_cost: 0.36006 sec, reader_cost: 0.00234 sec, ips: 44.43675 instance/sec.
[03/04 10:52:53] epoch:[ 12/30 ] train step:780  loss: 1.04211 lr: 0.001000 batch_cost: 0.35455 sec, reader_cost: 0.00011 sec, ips: 45.12770 instance/sec.
[03/04 10:52:55] END epoch:12  train loss_avg: 0.91453  avg_batch_cost: 0.35464 sec, avg_reader_cost: 0.00006 sec, batch_cost_sum: 282.16551 sec, avg_ips: 44.62629 instance/sec.
[03/04 10:52:57] epoch:[ 13/30 ] train step:0    loss: 0.68320 lr: 0.001000 batch_cost: 1.17225 sec, reader_cost: 0.80702 sec, ips: 13.64892 instance/sec.
[03/04 10:53:00] epoch:[ 13/30 ] train step:10   loss: 0.79215 lr: 0.001000 batch_cost: 0.35661 sec, reader_cost: 0.00222 sec, ips: 44.86708 instance/sec.
[03/04 10:53:04] epoch:[ 13/30 ] train step:20   loss: 0.98504 lr: 0.001000 batch_cost: 0.35542 sec, reader_cost: 0.00223 sec, ips: 45.01694 instance/sec.
[03/04 10:53:07] epoch:[ 13/30 ] train step:30   loss: 0.81576 lr: 0.001000 batch_cost: 0.35763 sec, reader_cost: 0.00226 sec, ips: 44.73951 instance/sec.
[03/04 10:53:11] epoch:[ 13/30 ] train step:40   loss: 0.85057 lr: 0.001000 batch_cost: 0.35562 sec, reader_cost: 0.00016 sec, ips: 44.99189 instance/sec.
[03/04 10:53:14] epoch:[ 13/30 ] train step:50   loss: 0.97245 lr: 0.001000 batch_cost: 0.35716 sec, reader_cost: 0.00237 sec, ips: 44.79841 instance/sec.
[03/04 10:53:18] epoch:[ 13/30 ] train step:60   loss: 0.79352 lr: 0.001000 batch_cost: 0.35671 sec, reader_cost: 0.00234 sec, ips: 44.85377 instance/sec.
[03/04 10:53:21] epoch:[ 13/30 ] train step:70   loss: 0.85877 lr: 0.001000 batch_cost: 0.35647 sec, reader_cost: 0.00016 sec, ips: 44.88419 instance/sec.
[03/04 10:53:25] epoch:[ 13/30 ] train step:80   loss: 0.81015 lr: 0.001000 batch_cost: 0.35432 sec, reader_cost: 0.00219 sec, ips: 45.15643 instance/sec.
[03/04 10:53:29] epoch:[ 13/30 ] train step:90   loss: 0.70318 lr: 0.001000 batch_cost: 0.35912 sec, reader_cost: 0.00270 sec, ips: 44.55360 instance/sec.
[03/04 10:53:32] epoch:[ 13/30 ] train step:100  loss: 0.72522 lr: 0.001000 batch_cost: 0.35496 sec, reader_cost: 0.00212 sec, ips: 45.07505 instance/sec.
[03/04 10:53:36] epoch:[ 13/30 ] train step:110  loss: 0.86368 lr: 0.001000 batch_cost: 0.35536 sec, reader_cost: 0.00219 sec, ips: 45.02509 instance/sec.
[03/04 10:53:39] epoch:[ 13/30 ] train step:120  loss: 0.80732 lr: 0.001000 batch_cost: 0.35477 sec, reader_cost: 0.00061 sec, ips: 45.09995 instance/sec.
[03/04 10:53:43] epoch:[ 13/30 ] train step:130  loss: 0.79506 lr: 0.001000 batch_cost: 0.35604 sec, reader_cost: 0.00279 sec, ips: 44.93823 instance/sec.
[03/04 10:53:46] epoch:[ 13/30 ] train step:140  loss: 0.70327 lr: 0.001000 batch_cost: 0.35693 sec, reader_cost: 0.00234 sec, ips: 44.82701 instance/sec.
[03/04 10:53:50] epoch:[ 13/30 ] train step:150  loss: 0.85749 lr: 0.001000 batch_cost: 0.35755 sec, reader_cost: 0.00267 sec, ips: 44.74933 instance/sec.
[03/04 10:53:54] epoch:[ 13/30 ] train step:160  loss: 0.87624 lr: 0.001000 batch_cost: 0.35701 sec, reader_cost: 0.00224 sec, ips: 44.81728 instance/sec.
[03/04 10:53:57] epoch:[ 13/30 ] train step:170  loss: 1.33191 lr: 0.001000 batch_cost: 0.35697 sec, reader_cost: 0.00211 sec, ips: 44.82148 instance/sec.
[03/04 10:54:01] epoch:[ 13/30 ] train step:180  loss: 0.87006 lr: 0.001000 batch_cost: 0.35945 sec, reader_cost: 0.00215 sec, ips: 44.51235 instance/sec.
[03/04 10:54:04] epoch:[ 13/30 ] train step:190  loss: 0.87037 lr: 0.001000 batch_cost: 0.35694 sec, reader_cost: 0.00236 sec, ips: 44.82579 instance/sec.
[03/04 10:54:08] epoch:[ 13/30 ] train step:200  loss: 0.93745 lr: 0.001000 batch_cost: 0.35462 sec, reader_cost: 0.00228 sec, ips: 45.11869 instance/sec.
[03/04 10:54:11] epoch:[ 13/30 ] train step:210  loss: 0.93004 lr: 0.001000 batch_cost: 0.35668 sec, reader_cost: 0.00266 sec, ips: 44.85752 instance/sec.
[03/04 10:54:15] epoch:[ 13/30 ] train step:220  loss: 1.23029 lr: 0.001000 batch_cost: 0.35662 sec, reader_cost: 0.00233 sec, ips: 44.86531 instance/sec.
[03/04 10:54:18] epoch:[ 13/30 ] train step:230  loss: 0.76848 lr: 0.001000 batch_cost: 0.35551 sec, reader_cost: 0.00255 sec, ips: 45.00589 instance/sec.
[03/04 10:54:22] epoch:[ 13/30 ] train step:240  loss: 0.74934 lr: 0.001000 batch_cost: 0.35430 sec, reader_cost: 0.00231 sec, ips: 45.16001 instance/sec.
[03/04 10:54:26] epoch:[ 13/30 ] train step:250  loss: 1.15036 lr: 0.001000 batch_cost: 0.35803 sec, reader_cost: 0.00247 sec, ips: 44.68928 instance/sec.
[03/04 10:54:29] epoch:[ 13/30 ] train step:260  loss: 1.08386 lr: 0.001000 batch_cost: 0.35527 sec, reader_cost: 0.00222 sec, ips: 45.03597 instance/sec.
[03/04 10:54:33] epoch:[ 13/30 ] train step:270  loss: 0.81624 lr: 0.001000 batch_cost: 0.35656 sec, reader_cost: 0.00049 sec, ips: 44.87374 instance/sec.
[03/04 10:54:36] epoch:[ 13/30 ] train step:280  loss: 0.75272 lr: 0.001000 batch_cost: 0.35708 sec, reader_cost: 0.00223 sec, ips: 44.80825 instance/sec.
[03/04 10:54:40] epoch:[ 13/30 ] train step:290  loss: 0.77910 lr: 0.001000 batch_cost: 0.35297 sec, reader_cost: 0.00040 sec, ips: 45.32903 instance/sec.
[03/04 10:54:43] epoch:[ 13/30 ] train step:300  loss: 0.94573 lr: 0.001000 batch_cost: 0.35765 sec, reader_cost: 0.00218 sec, ips: 44.73686 instance/sec.
[03/04 10:54:47] epoch:[ 13/30 ] train step:310  loss: 0.88385 lr: 0.001000 batch_cost: 0.35563 sec, reader_cost: 0.00230 sec, ips: 44.99098 instance/sec.
[03/04 10:54:50] epoch:[ 13/30 ] train step:320  loss: 0.73594 lr: 0.001000 batch_cost: 0.35582 sec, reader_cost: 0.00016 sec, ips: 44.96626 instance/sec.
[03/04 10:54:54] epoch:[ 13/30 ] train step:330  loss: 1.08619 lr: 0.001000 batch_cost: 0.35525 sec, reader_cost: 0.00260 sec, ips: 45.03839 instance/sec.
[03/04 10:54:58] epoch:[ 13/30 ] train step:340  loss: 0.75341 lr: 0.001000 batch_cost: 0.35781 sec, reader_cost: 0.00246 sec, ips: 44.71593 instance/sec.
[03/04 10:55:01] epoch:[ 13/30 ] train step:350  loss: 0.81105 lr: 0.001000 batch_cost: 0.35493 sec, reader_cost: 0.00030 sec, ips: 45.07920 instance/sec.
[03/04 10:55:05] epoch:[ 13/30 ] train step:360  loss: 0.86144 lr: 0.001000 batch_cost: 0.35946 sec, reader_cost: 0.00244 sec, ips: 44.51117 instance/sec.
[03/04 10:55:08] epoch:[ 13/30 ] train step:370  loss: 0.90028 lr: 0.001000 batch_cost: 0.35572 sec, reader_cost: 0.00272 sec, ips: 44.97922 instance/sec.
[03/04 10:55:12] epoch:[ 13/30 ] train step:380  loss: 0.82258 lr: 0.001000 batch_cost: 0.35566 sec, reader_cost: 0.00213 sec, ips: 44.98715 instance/sec.
[03/04 10:55:15] epoch:[ 13/30 ] train step:390  loss: 0.91088 lr: 0.001000 batch_cost: 0.35599 sec, reader_cost: 0.00222 sec, ips: 44.94524 instance/sec.
[03/04 10:55:19] epoch:[ 13/30 ] train step:400  loss: 1.24353 lr: 0.001000 batch_cost: 0.35868 sec, reader_cost: 0.00260 sec, ips: 44.60741 instance/sec.
[03/04 10:55:23] epoch:[ 13/30 ] train step:410  loss: 0.98306 lr: 0.001000 batch_cost: 0.36223 sec, reader_cost: 0.00259 sec, ips: 44.17132 instance/sec.
[03/04 10:55:26] epoch:[ 13/30 ] train step:420  loss: 0.98274 lr: 0.001000 batch_cost: 0.35530 sec, reader_cost: 0.00252 sec, ips: 45.03274 instance/sec.
[03/04 10:55:30] epoch:[ 13/30 ] train step:430  loss: 0.85536 lr: 0.001000 batch_cost: 0.35818 sec, reader_cost: 0.00238 sec, ips: 44.67021 instance/sec.
[03/04 10:55:33] epoch:[ 13/30 ] train step:440  loss: 0.86572 lr: 0.001000 batch_cost: 0.35450 sec, reader_cost: 0.00246 sec, ips: 45.13444 instance/sec.
[03/04 10:55:37] epoch:[ 13/30 ] train step:450  loss: 0.84178 lr: 0.001000 batch_cost: 0.35898 sec, reader_cost: 0.00260 sec, ips: 44.57091 instance/sec.
[03/04 10:55:40] epoch:[ 13/30 ] train step:460  loss: 0.53011 lr: 0.001000 batch_cost: 0.35485 sec, reader_cost: 0.00014 sec, ips: 45.08913 instance/sec.
[03/04 10:55:44] epoch:[ 13/30 ] train step:470  loss: 1.12181 lr: 0.001000 batch_cost: 0.35642 sec, reader_cost: 0.00223 sec, ips: 44.89145 instance/sec.
[03/04 10:55:47] epoch:[ 13/30 ] train step:480  loss: 0.86852 lr: 0.001000 batch_cost: 0.35709 sec, reader_cost: 0.00234 sec, ips: 44.80612 instance/sec.
[03/04 10:55:51] epoch:[ 13/30 ] train step:490  loss: 0.92038 lr: 0.001000 batch_cost: 0.35634 sec, reader_cost: 0.00274 sec, ips: 44.90035 instance/sec.
[03/04 10:55:55] epoch:[ 13/30 ] train step:500  loss: 0.85888 lr: 0.001000 batch_cost: 0.35791 sec, reader_cost: 0.00246 sec, ips: 44.70458 instance/sec.
[03/04 10:55:58] epoch:[ 13/30 ] train step:510  loss: 1.02149 lr: 0.001000 batch_cost: 0.35338 sec, reader_cost: 0.00233 sec, ips: 45.27686 instance/sec.
[03/04 10:56:02] epoch:[ 13/30 ] train step:520  loss: 0.84283 lr: 0.001000 batch_cost: 0.35679 sec, reader_cost: 0.00016 sec, ips: 44.84439 instance/sec.
[03/04 10:56:05] epoch:[ 13/30 ] train step:530  loss: 0.98273 lr: 0.001000 batch_cost: 0.35492 sec, reader_cost: 0.00261 sec, ips: 45.08080 instance/sec.
[03/04 10:56:09] epoch:[ 13/30 ] train step:540  loss: 0.79712 lr: 0.001000 batch_cost: 0.35637 sec, reader_cost: 0.00257 sec, ips: 44.89674 instance/sec.
[03/04 10:56:12] epoch:[ 13/30 ] train step:550  loss: 0.76207 lr: 0.001000 batch_cost: 0.35651 sec, reader_cost: 0.00233 sec, ips: 44.87954 instance/sec.
[03/04 10:56:16] epoch:[ 13/30 ] train step:560  loss: 0.86207 lr: 0.001000 batch_cost: 0.35515 sec, reader_cost: 0.00233 sec, ips: 45.05154 instance/sec.
[03/04 10:56:20] epoch:[ 13/30 ] train step:570  loss: 0.62128 lr: 0.001000 batch_cost: 0.35594 sec, reader_cost: 0.00257 sec, ips: 44.95093 instance/sec.
[03/04 10:56:23] epoch:[ 13/30 ] train step:580  loss: 1.09472 lr: 0.001000 batch_cost: 0.35503 sec, reader_cost: 0.00017 sec, ips: 45.06615 instance/sec.
[03/04 10:56:27] epoch:[ 13/30 ] train step:590  loss: 1.28290 lr: 0.001000 batch_cost: 0.35732 sec, reader_cost: 0.00233 sec, ips: 44.77721 instance/sec.
[03/04 10:56:30] epoch:[ 13/30 ] train step:600  loss: 0.91327 lr: 0.001000 batch_cost: 0.35577 sec, reader_cost: 0.00234 sec, ips: 44.97256 instance/sec.
[03/04 10:56:34] epoch:[ 13/30 ] train step:610  loss: 0.84180 lr: 0.001000 batch_cost: 0.35673 sec, reader_cost: 0.00014 sec, ips: 44.85245 instance/sec.
[03/04 10:56:37] epoch:[ 13/30 ] train step:620  loss: 0.87505 lr: 0.001000 batch_cost: 0.35865 sec, reader_cost: 0.00251 sec, ips: 44.61124 instance/sec.
[03/04 10:56:41] epoch:[ 13/30 ] train step:630  loss: 0.99346 lr: 0.001000 batch_cost: 0.35685 sec, reader_cost: 0.00221 sec, ips: 44.83663 instance/sec.
[03/04 10:56:44] epoch:[ 13/30 ] train step:640  loss: 0.74758 lr: 0.001000 batch_cost: 0.35641 sec, reader_cost: 0.00229 sec, ips: 44.89206 instance/sec.
[03/04 10:56:48] epoch:[ 13/30 ] train step:650  loss: 1.15649 lr: 0.001000 batch_cost: 0.35609 sec, reader_cost: 0.00270 sec, ips: 44.93269 instance/sec.
[03/04 10:56:52] epoch:[ 13/30 ] train step:660  loss: 1.09482 lr: 0.001000 batch_cost: 0.35761 sec, reader_cost: 0.00244 sec, ips: 44.74178 instance/sec.
[03/04 10:56:55] epoch:[ 13/30 ] train step:670  loss: 0.88002 lr: 0.001000 batch_cost: 0.35567 sec, reader_cost: 0.00234 sec, ips: 44.98546 instance/sec.
[03/04 10:56:59] epoch:[ 13/30 ] train step:680  loss: 1.23799 lr: 0.001000 batch_cost: 0.35950 sec, reader_cost: 0.00249 sec, ips: 44.50565 instance/sec.
[03/04 10:57:02] epoch:[ 13/30 ] train step:690  loss: 0.81959 lr: 0.001000 batch_cost: 0.35498 sec, reader_cost: 0.00270 sec, ips: 45.07324 instance/sec.
[03/04 10:57:06] epoch:[ 13/30 ] train step:700  loss: 0.83889 lr: 0.001000 batch_cost: 0.35802 sec, reader_cost: 0.00017 sec, ips: 44.68976 instance/sec.
[03/04 10:57:09] epoch:[ 13/30 ] train step:710  loss: 1.11329 lr: 0.001000 batch_cost: 0.35703 sec, reader_cost: 0.00239 sec, ips: 44.81426 instance/sec.
[03/04 10:57:13] epoch:[ 13/30 ] train step:720  loss: 0.83920 lr: 0.001000 batch_cost: 0.35581 sec, reader_cost: 0.00219 sec, ips: 44.96792 instance/sec.
[03/04 10:57:17] epoch:[ 13/30 ] train step:730  loss: 0.92109 lr: 0.001000 batch_cost: 0.35741 sec, reader_cost: 0.00263 sec, ips: 44.76691 instance/sec.
[03/04 10:57:20] epoch:[ 13/30 ] train step:740  loss: 0.87148 lr: 0.001000 batch_cost: 0.36106 sec, reader_cost: 0.00577 sec, ips: 44.31450 instance/sec.
[03/04 10:57:24] epoch:[ 13/30 ] train step:750  loss: 0.89187 lr: 0.001000 batch_cost: 0.35747 sec, reader_cost: 0.00242 sec, ips: 44.75879 instance/sec.
[03/04 10:57:27] epoch:[ 13/30 ] train step:760  loss: 0.76797 lr: 0.001000 batch_cost: 0.35467 sec, reader_cost: 0.00247 sec, ips: 45.11253 instance/sec.
[03/04 10:57:31] epoch:[ 13/30 ] train step:770  loss: 0.92687 lr: 0.001000 batch_cost: 0.35775 sec, reader_cost: 0.00272 sec, ips: 44.72419 instance/sec.
[03/04 10:57:34] epoch:[ 13/30 ] train step:780  loss: 0.86542 lr: 0.001000 batch_cost: 0.35069 sec, reader_cost: 0.00006 sec, ips: 45.62470 instance/sec.
[03/04 10:57:37] END epoch:13  train loss_avg: 0.90269  avg_batch_cost: 0.35155 sec, avg_reader_cost: 0.00005 sec, batch_cost_sum: 281.02387 sec, avg_ips: 44.80758 instance/sec.
[03/04 10:57:38] epoch:[ 14/30 ] train step:0    loss: 0.83978 lr: 0.001000 batch_cost: 1.15310 sec, reader_cost: 0.77783 sec, ips: 13.87567 instance/sec.
[03/04 10:57:41] epoch:[ 14/30 ] train step:10   loss: 0.82512 lr: 0.001000 batch_cost: 0.35533 sec, reader_cost: 0.00239 sec, ips: 45.02905 instance/sec.
[03/04 10:57:45] epoch:[ 14/30 ] train step:20   loss: 0.75675 lr: 0.001000 batch_cost: 0.35459 sec, reader_cost: 0.00212 sec, ips: 45.12245 instance/sec.
[03/04 10:57:49] epoch:[ 14/30 ] train step:30   loss: 0.74301 lr: 0.001000 batch_cost: 0.35769 sec, reader_cost: 0.00220 sec, ips: 44.73098 instance/sec.
[03/04 10:57:52] epoch:[ 14/30 ] train step:40   loss: 1.47795 lr: 0.001000 batch_cost: 0.35678 sec, reader_cost: 0.00220 sec, ips: 44.84562 instance/sec.
[03/04 10:57:56] epoch:[ 14/30 ] train step:50   loss: 0.87839 lr: 0.001000 batch_cost: 0.35657 sec, reader_cost: 0.00209 sec, ips: 44.87137 instance/sec.
[03/04 10:57:59] epoch:[ 14/30 ] train step:60   loss: 0.70972 lr: 0.001000 batch_cost: 0.35363 sec, reader_cost: 0.00231 sec, ips: 45.24475 instance/sec.
[03/04 10:58:03] epoch:[ 14/30 ] train step:70   loss: 0.73469 lr: 0.001000 batch_cost: 0.35944 sec, reader_cost: 0.00220 sec, ips: 44.51350 instance/sec.
[03/04 10:58:06] epoch:[ 14/30 ] train step:80   loss: 0.69756 lr: 0.001000 batch_cost: 0.35689 sec, reader_cost: 0.00221 sec, ips: 44.83222 instance/sec.
[03/04 10:58:10] epoch:[ 14/30 ] train step:90   loss: 0.99392 lr: 0.001000 batch_cost: 0.35391 sec, reader_cost: 0.00235 sec, ips: 45.20954 instance/sec.
[03/04 10:58:13] epoch:[ 14/30 ] train step:100  loss: 0.74823 lr: 0.001000 batch_cost: 0.35529 sec, reader_cost: 0.00218 sec, ips: 45.03358 instance/sec.
[03/04 10:58:17] epoch:[ 14/30 ] train step:110  loss: 0.86562 lr: 0.001000 batch_cost: 0.35422 sec, reader_cost: 0.00015 sec, ips: 45.16928 instance/sec.
[03/04 10:58:21] epoch:[ 14/30 ] train step:120  loss: 0.86555 lr: 0.001000 batch_cost: 0.35628 sec, reader_cost: 0.00220 sec, ips: 44.90813 instance/sec.
[03/04 10:58:24] epoch:[ 14/30 ] train step:130  loss: 0.89550 lr: 0.001000 batch_cost: 0.35610 sec, reader_cost: 0.00015 sec, ips: 44.93152 instance/sec.
[03/04 10:58:28] epoch:[ 14/30 ] train step:140  loss: 0.85930 lr: 0.001000 batch_cost: 0.35687 sec, reader_cost: 0.00225 sec, ips: 44.83483 instance/sec.
[03/04 10:58:31] epoch:[ 14/30 ] train step:150  loss: 0.81807 lr: 0.001000 batch_cost: 0.35578 sec, reader_cost: 0.00226 sec, ips: 44.97178 instance/sec.
[03/04 10:58:35] epoch:[ 14/30 ] train step:160  loss: 0.71220 lr: 0.001000 batch_cost: 0.35852 sec, reader_cost: 0.00216 sec, ips: 44.62824 instance/sec.
[03/04 10:58:38] epoch:[ 14/30 ] train step:170  loss: 0.78834 lr: 0.001000 batch_cost: 0.35544 sec, reader_cost: 0.00224 sec, ips: 45.01434 instance/sec.
[03/04 10:58:42] epoch:[ 14/30 ] train step:180  loss: 0.81906 lr: 0.001000 batch_cost: 0.35449 sec, reader_cost: 0.00220 sec, ips: 45.13590 instance/sec.
[03/04 10:58:46] epoch:[ 14/30 ] train step:190  loss: 0.83663 lr: 0.001000 batch_cost: 0.35562 sec, reader_cost: 0.00207 sec, ips: 44.99231 instance/sec.
[03/04 10:58:49] epoch:[ 14/30 ] train step:200  loss: 0.73978 lr: 0.001000 batch_cost: 0.35685 sec, reader_cost: 0.00228 sec, ips: 44.83648 instance/sec.
[03/04 10:58:53] epoch:[ 14/30 ] train step:210  loss: 0.80131 lr: 0.001000 batch_cost: 0.35832 sec, reader_cost: 0.00231 sec, ips: 44.65241 instance/sec.
[03/04 10:58:56] epoch:[ 14/30 ] train step:220  loss: 0.76080 lr: 0.001000 batch_cost: 0.35559 sec, reader_cost: 0.00226 sec, ips: 44.99566 instance/sec.
[03/04 10:59:00] epoch:[ 14/30 ] train step:230  loss: 0.80717 lr: 0.001000 batch_cost: 0.35978 sec, reader_cost: 0.00226 sec, ips: 44.47185 instance/sec.
[03/04 10:59:03] epoch:[ 14/30 ] train step:240  loss: 0.70700 lr: 0.001000 batch_cost: 0.35593 sec, reader_cost: 0.00225 sec, ips: 44.95238 instance/sec.
[03/04 10:59:07] epoch:[ 14/30 ] train step:250  loss: 0.90280 lr: 0.001000 batch_cost: 0.35701 sec, reader_cost: 0.00211 sec, ips: 44.81642 instance/sec.
[03/04 10:59:10] epoch:[ 14/30 ] train step:260  loss: 0.92264 lr: 0.001000 batch_cost: 0.35476 sec, reader_cost: 0.00227 sec, ips: 45.10095 instance/sec.
[03/04 10:59:14] epoch:[ 14/30 ] train step:270  loss: 0.89606 lr: 0.001000 batch_cost: 0.35481 sec, reader_cost: 0.00221 sec, ips: 45.09513 instance/sec.
[03/04 10:59:18] epoch:[ 14/30 ] train step:280  loss: 0.62883 lr: 0.001000 batch_cost: 0.35544 sec, reader_cost: 0.00016 sec, ips: 45.01455 instance/sec.
[03/04 10:59:21] epoch:[ 14/30 ] train step:290  loss: 0.92973 lr: 0.001000 batch_cost: 0.35556 sec, reader_cost: 0.00217 sec, ips: 44.99973 instance/sec.
[03/04 10:59:25] epoch:[ 14/30 ] train step:300  loss: 0.77040 lr: 0.001000 batch_cost: 0.35610 sec, reader_cost: 0.00239 sec, ips: 44.93161 instance/sec.
[03/04 10:59:28] epoch:[ 14/30 ] train step:310  loss: 0.78688 lr: 0.001000 batch_cost: 0.35647 sec, reader_cost: 0.00227 sec, ips: 44.88428 instance/sec.
[03/04 10:59:32] epoch:[ 14/30 ] train step:320  loss: 0.90203 lr: 0.001000 batch_cost: 0.35798 sec, reader_cost: 0.00221 sec, ips: 44.69562 instance/sec.
[03/04 10:59:35] epoch:[ 14/30 ] train step:330  loss: 0.81067 lr: 0.001000 batch_cost: 0.35631 sec, reader_cost: 0.00214 sec, ips: 44.90488 instance/sec.
[03/04 10:59:39] epoch:[ 14/30 ] train step:340  loss: 1.08178 lr: 0.001000 batch_cost: 0.35715 sec, reader_cost: 0.00217 sec, ips: 44.79877 instance/sec.
[03/04 10:59:42] epoch:[ 14/30 ] train step:350  loss: 0.86172 lr: 0.001000 batch_cost: 0.35580 sec, reader_cost: 0.00214 sec, ips: 44.96943 instance/sec.
[03/04 10:59:46] epoch:[ 14/30 ] train step:360  loss: 0.75347 lr: 0.001000 batch_cost: 0.35608 sec, reader_cost: 0.00229 sec, ips: 44.93387 instance/sec.
[03/04 10:59:50] epoch:[ 14/30 ] train step:370  loss: 0.89653 lr: 0.001000 batch_cost: 0.35787 sec, reader_cost: 0.00285 sec, ips: 44.70863 instance/sec.
[03/04 10:59:53] epoch:[ 14/30 ] train step:380  loss: 0.98892 lr: 0.001000 batch_cost: 0.35545 sec, reader_cost: 0.00239 sec, ips: 45.01322 instance/sec.
[03/04 10:59:57] epoch:[ 14/30 ] train step:390  loss: 0.90629 lr: 0.001000 batch_cost: 0.35566 sec, reader_cost: 0.00015 sec, ips: 44.98703 instance/sec.
[03/04 11:00:00] epoch:[ 14/30 ] train step:400  loss: 0.89292 lr: 0.001000 batch_cost: 0.35631 sec, reader_cost: 0.00234 sec, ips: 44.90503 instance/sec.
[03/04 11:00:04] epoch:[ 14/30 ] train step:410  loss: 1.36964 lr: 0.001000 batch_cost: 0.35900 sec, reader_cost: 0.00214 sec, ips: 44.56852 instance/sec.
[03/04 11:00:07] epoch:[ 14/30 ] train step:420  loss: 0.82622 lr: 0.001000 batch_cost: 0.35467 sec, reader_cost: 0.00219 sec, ips: 45.11256 instance/sec.
[03/04 11:00:11] epoch:[ 14/30 ] train step:430  loss: 0.89186 lr: 0.001000 batch_cost: 0.35685 sec, reader_cost: 0.00215 sec, ips: 44.83681 instance/sec.
[03/04 11:00:15] epoch:[ 14/30 ] train step:440  loss: 1.05164 lr: 0.001000 batch_cost: 0.35617 sec, reader_cost: 0.00017 sec, ips: 44.92235 instance/sec.
[03/04 11:00:18] epoch:[ 14/30 ] train step:450  loss: 0.83038 lr: 0.001000 batch_cost: 0.35687 sec, reader_cost: 0.00233 sec, ips: 44.83441 instance/sec.
[03/04 11:00:22] epoch:[ 14/30 ] train step:460  loss: 0.83590 lr: 0.001000 batch_cost: 0.35434 sec, reader_cost: 0.00236 sec, ips: 45.15400 instance/sec.
[03/04 11:00:25] epoch:[ 14/30 ] train step:470  loss: 1.27118 lr: 0.001000 batch_cost: 0.35748 sec, reader_cost: 0.00270 sec, ips: 44.75726 instance/sec.
[03/04 11:00:29] epoch:[ 14/30 ] train step:480  loss: 0.95890 lr: 0.001000 batch_cost: 0.35772 sec, reader_cost: 0.00014 sec, ips: 44.72758 instance/sec.
[03/04 11:00:32] epoch:[ 14/30 ] train step:490  loss: 0.84531 lr: 0.001000 batch_cost: 0.35487 sec, reader_cost: 0.00215 sec, ips: 45.08650 instance/sec.
[03/04 11:00:36] epoch:[ 14/30 ] train step:500  loss: 0.79678 lr: 0.001000 batch_cost: 0.35760 sec, reader_cost: 0.00229 sec, ips: 44.74333 instance/sec.
[03/04 11:00:39] epoch:[ 14/30 ] train step:510  loss: 0.85414 lr: 0.001000 batch_cost: 0.35594 sec, reader_cost: 0.00229 sec, ips: 44.95126 instance/sec.
[03/04 11:00:43] epoch:[ 14/30 ] train step:520  loss: 0.91998 lr: 0.001000 batch_cost: 0.35641 sec, reader_cost: 0.00230 sec, ips: 44.89269 instance/sec.
[03/04 11:00:47] epoch:[ 14/30 ] train step:530  loss: 0.82014 lr: 0.001000 batch_cost: 0.35799 sec, reader_cost: 0.00221 sec, ips: 44.69392 instance/sec.
[03/04 11:00:50] epoch:[ 14/30 ] train step:540  loss: 0.69467 lr: 0.001000 batch_cost: 0.35423 sec, reader_cost: 0.00012 sec, ips: 45.16859 instance/sec.
[03/04 11:00:54] epoch:[ 14/30 ] train step:550  loss: 0.76857 lr: 0.001000 batch_cost: 0.35951 sec, reader_cost: 0.00227 sec, ips: 44.50515 instance/sec.
[03/04 11:00:57] epoch:[ 14/30 ] train step:560  loss: 0.97459 lr: 0.001000 batch_cost: 0.36078 sec, reader_cost: 0.00016 sec, ips: 44.34815 instance/sec.
[03/04 11:01:01] epoch:[ 14/30 ] train step:570  loss: 0.80205 lr: 0.001000 batch_cost: 0.35720 sec, reader_cost: 0.00041 sec, ips: 44.79276 instance/sec.
[03/04 11:01:04] epoch:[ 14/30 ] train step:580  loss: 0.87356 lr: 0.001000 batch_cost: 0.35476 sec, reader_cost: 0.00234 sec, ips: 45.10123 instance/sec.
[03/04 11:01:08] epoch:[ 14/30 ] train step:590  loss: 0.86143 lr: 0.001000 batch_cost: 0.35510 sec, reader_cost: 0.00230 sec, ips: 45.05798 instance/sec.
[03/04 11:01:12] epoch:[ 14/30 ] train step:600  loss: 1.12128 lr: 0.001000 batch_cost: 0.35421 sec, reader_cost: 0.00016 sec, ips: 45.17062 instance/sec.
[03/04 11:01:15] epoch:[ 14/30 ] train step:610  loss: 1.14233 lr: 0.001000 batch_cost: 0.35607 sec, reader_cost: 0.00243 sec, ips: 44.93441 instance/sec.
[03/04 11:01:19] epoch:[ 14/30 ] train step:620  loss: 0.82028 lr: 0.001000 batch_cost: 0.35864 sec, reader_cost: 0.00233 sec, ips: 44.61242 instance/sec.
[03/04 11:01:22] epoch:[ 14/30 ] train step:630  loss: 0.96373 lr: 0.001000 batch_cost: 0.35565 sec, reader_cost: 0.00243 sec, ips: 44.98742 instance/sec.
[03/04 11:01:26] epoch:[ 14/30 ] train step:640  loss: 0.82557 lr: 0.001000 batch_cost: 0.35841 sec, reader_cost: 0.00237 sec, ips: 44.64118 instance/sec.
[03/04 11:01:29] epoch:[ 14/30 ] train step:650  loss: 0.84137 lr: 0.001000 batch_cost: 0.35403 sec, reader_cost: 0.00016 sec, ips: 45.19362 instance/sec.
[03/04 11:01:33] epoch:[ 14/30 ] train step:660  loss: 1.11924 lr: 0.001000 batch_cost: 0.35309 sec, reader_cost: 0.00022 sec, ips: 45.31397 instance/sec.
[03/04 11:01:37] epoch:[ 14/30 ] train step:670  loss: 0.81235 lr: 0.001000 batch_cost: 0.35599 sec, reader_cost: 0.00228 sec, ips: 44.94491 instance/sec.
[03/04 11:01:40] epoch:[ 14/30 ] train step:680  loss: 0.82280 lr: 0.001000 batch_cost: 0.35712 sec, reader_cost: 0.00242 sec, ips: 44.80349 instance/sec.
[03/04 11:01:44] epoch:[ 14/30 ] train step:690  loss: 0.83202 lr: 0.001000 batch_cost: 0.35580 sec, reader_cost: 0.00226 sec, ips: 44.96964 instance/sec.
[03/04 11:01:47] epoch:[ 14/30 ] train step:700  loss: 0.85734 lr: 0.001000 batch_cost: 0.35582 sec, reader_cost: 0.00232 sec, ips: 44.96659 instance/sec.
[03/04 11:01:51] epoch:[ 14/30 ] train step:710  loss: 0.96926 lr: 0.001000 batch_cost: 0.35870 sec, reader_cost: 0.00234 sec, ips: 44.60599 instance/sec.
[03/04 11:01:54] epoch:[ 14/30 ] train step:720  loss: 0.88193 lr: 0.001000 batch_cost: 0.35760 sec, reader_cost: 0.00255 sec, ips: 44.74217 instance/sec.
[03/04 11:01:58] epoch:[ 14/30 ] train step:730  loss: 0.79659 lr: 0.001000 batch_cost: 0.35829 sec, reader_cost: 0.00021 sec, ips: 44.65693 instance/sec.
[03/04 11:02:01] epoch:[ 14/30 ] train step:740  loss: 0.70457 lr: 0.001000 batch_cost: 0.35365 sec, reader_cost: 0.00010 sec, ips: 45.24264 instance/sec.
[03/04 11:02:05] epoch:[ 14/30 ] train step:750  loss: 0.95809 lr: 0.001000 batch_cost: 0.35618 sec, reader_cost: 0.00014 sec, ips: 44.92099 instance/sec.
[03/04 11:02:09] epoch:[ 14/30 ] train step:760  loss: 0.81589 lr: 0.001000 batch_cost: 0.35673 sec, reader_cost: 0.00227 sec, ips: 44.85149 instance/sec.
[03/04 11:02:12] epoch:[ 14/30 ] train step:770  loss: 0.73974 lr: 0.001000 batch_cost: 0.35551 sec, reader_cost: 0.00237 sec, ips: 45.00604 instance/sec.
[03/04 11:02:16] epoch:[ 14/30 ] train step:780  loss: 0.89261 lr: 0.001000 batch_cost: 0.35147 sec, reader_cost: 0.00005 sec, ips: 45.52324 instance/sec.
[03/04 11:02:18] END epoch:14  train loss_avg: 0.89125  avg_batch_cost: 0.35483 sec, avg_reader_cost: 0.00008 sec, batch_cost_sum: 281.01860 sec, avg_ips: 44.80842 instance/sec.
[03/04 11:02:19] epoch:[ 15/30 ] train step:0    loss: 0.98957 lr: 0.001000 batch_cost: 1.04796 sec, reader_cost: 0.68162 sec, ips: 15.26780 instance/sec.
[03/04 11:02:23] epoch:[ 15/30 ] train step:10   loss: 0.78625 lr: 0.001000 batch_cost: 0.35941 sec, reader_cost: 0.00578 sec, ips: 44.51719 instance/sec.
[03/04 11:02:26] epoch:[ 15/30 ] train step:20   loss: 0.95581 lr: 0.001000 batch_cost: 0.35895 sec, reader_cost: 0.00226 sec, ips: 44.57473 instance/sec.
[03/04 11:02:30] epoch:[ 15/30 ] train step:30   loss: 0.74826 lr: 0.001000 batch_cost: 0.35702 sec, reader_cost: 0.00215 sec, ips: 44.81531 instance/sec.
[03/04 11:02:33] epoch:[ 15/30 ] train step:40   loss: 0.87790 lr: 0.001000 batch_cost: 0.35435 sec, reader_cost: 0.00225 sec, ips: 45.15366 instance/sec.
[03/04 11:02:37] epoch:[ 15/30 ] train step:50   loss: 0.92680 lr: 0.001000 batch_cost: 0.35653 sec, reader_cost: 0.00219 sec, ips: 44.87693 instance/sec.
[03/04 11:02:40] epoch:[ 15/30 ] train step:60   loss: 0.91094 lr: 0.001000 batch_cost: 0.35516 sec, reader_cost: 0.00020 sec, ips: 45.05006 instance/sec.
[03/04 11:02:44] epoch:[ 15/30 ] train step:70   loss: 0.75745 lr: 0.001000 batch_cost: 0.35881 sec, reader_cost: 0.00222 sec, ips: 44.59191 instance/sec.
[03/04 11:02:48] epoch:[ 15/30 ] train step:80   loss: 0.89564 lr: 0.001000 batch_cost: 0.35517 sec, reader_cost: 0.00216 sec, ips: 45.04836 instance/sec.
[03/04 11:02:51] epoch:[ 15/30 ] train step:90   loss: 0.83358 lr: 0.001000 batch_cost: 0.35625 sec, reader_cost: 0.00018 sec, ips: 44.91218 instance/sec.
[03/04 11:02:55] epoch:[ 15/30 ] train step:100  loss: 0.83656 lr: 0.001000 batch_cost: 0.35582 sec, reader_cost: 0.00228 sec, ips: 44.96608 instance/sec.
[03/04 11:02:58] epoch:[ 15/30 ] train step:110  loss: 1.01694 lr: 0.001000 batch_cost: 0.35526 sec, reader_cost: 0.00016 sec, ips: 45.03772 instance/sec.
[03/04 11:03:02] epoch:[ 15/30 ] train step:120  loss: 0.70369 lr: 0.001000 batch_cost: 0.35650 sec, reader_cost: 0.00215 sec, ips: 44.88059 instance/sec.
[03/04 11:03:05] epoch:[ 15/30 ] train step:130  loss: 0.87138 lr: 0.001000 batch_cost: 0.35696 sec, reader_cost: 0.00217 sec, ips: 44.82261 instance/sec.
[03/04 11:03:09] epoch:[ 15/30 ] train step:140  loss: 0.94805 lr: 0.001000 batch_cost: 0.35883 sec, reader_cost: 0.00272 sec, ips: 44.58919 instance/sec.
[03/04 11:03:13] epoch:[ 15/30 ] train step:150  loss: 0.78217 lr: 0.001000 batch_cost: 0.35650 sec, reader_cost: 0.00222 sec, ips: 44.88059 instance/sec.
[03/04 11:03:16] epoch:[ 15/30 ] train step:160  loss: 0.90551 lr: 0.001000 batch_cost: 0.35842 sec, reader_cost: 0.00221 sec, ips: 44.64062 instance/sec.
[03/04 11:03:20] epoch:[ 15/30 ] train step:170  loss: 0.81642 lr: 0.001000 batch_cost: 0.35482 sec, reader_cost: 0.00015 sec, ips: 45.09392 instance/sec.
[03/04 11:03:23] epoch:[ 15/30 ] train step:180  loss: 1.13916 lr: 0.001000 batch_cost: 0.35857 sec, reader_cost: 0.00221 sec, ips: 44.62209 instance/sec.
[03/04 11:03:27] epoch:[ 15/30 ] train step:190  loss: 0.89454 lr: 0.001000 batch_cost: 0.35642 sec, reader_cost: 0.00238 sec, ips: 44.89046 instance/sec.
[03/04 11:03:30] epoch:[ 15/30 ] train step:200  loss: 0.92542 lr: 0.001000 batch_cost: 0.35561 sec, reader_cost: 0.00016 sec, ips: 44.99367 instance/sec.
[03/04 11:03:34] epoch:[ 15/30 ] train step:210  loss: 0.81963 lr: 0.001000 batch_cost: 0.35783 sec, reader_cost: 0.00232 sec, ips: 44.71453 instance/sec.
[03/04 11:03:37] epoch:[ 15/30 ] train step:220  loss: 0.81879 lr: 0.001000 batch_cost: 0.35614 sec, reader_cost: 0.00229 sec, ips: 44.92662 instance/sec.
[03/04 11:03:41] epoch:[ 15/30 ] train step:230  loss: 0.81846 lr: 0.001000 batch_cost: 0.35458 sec, reader_cost: 0.00012 sec, ips: 45.12436 instance/sec.
[03/04 11:03:45] epoch:[ 15/30 ] train step:240  loss: 0.84563 lr: 0.001000 batch_cost: 0.35478 sec, reader_cost: 0.00046 sec, ips: 45.09874 instance/sec.
[03/04 11:03:48] epoch:[ 15/30 ] train step:250  loss: 0.88044 lr: 0.001000 batch_cost: 0.35895 sec, reader_cost: 0.00230 sec, ips: 44.57444 instance/sec.
[03/04 11:03:52] epoch:[ 15/30 ] train step:260  loss: 0.88712 lr: 0.001000 batch_cost: 0.35399 sec, reader_cost: 0.00015 sec, ips: 45.19946 instance/sec.
[03/04 11:03:55] epoch:[ 15/30 ] train step:270  loss: 0.87826 lr: 0.001000 batch_cost: 0.35581 sec, reader_cost: 0.00246 sec, ips: 44.96804 instance/sec.
[03/04 11:03:59] epoch:[ 15/30 ] train step:280  loss: 0.79356 lr: 0.001000 batch_cost: 0.35554 sec, reader_cost: 0.00015 sec, ips: 45.00151 instance/sec.
[03/04 11:04:02] epoch:[ 15/30 ] train step:290  loss: 1.02026 lr: 0.001000 batch_cost: 0.35630 sec, reader_cost: 0.00213 sec, ips: 44.90593 instance/sec.
[03/04 11:04:06] epoch:[ 15/30 ] train step:300  loss: 0.97533 lr: 0.001000 batch_cost: 0.35648 sec, reader_cost: 0.00214 sec, ips: 44.88287 instance/sec.
[03/04 11:04:10] epoch:[ 15/30 ] train step:310  loss: 0.74369 lr: 0.001000 batch_cost: 0.35690 sec, reader_cost: 0.00208 sec, ips: 44.83034 instance/sec.
[03/04 11:04:13] epoch:[ 15/30 ] train step:320  loss: 0.81597 lr: 0.001000 batch_cost: 0.35832 sec, reader_cost: 0.00212 sec, ips: 44.65229 instance/sec.
[03/04 11:04:17] epoch:[ 15/30 ] train step:330  loss: 1.36312 lr: 0.001000 batch_cost: 0.35513 sec, reader_cost: 0.00042 sec, ips: 45.05378 instance/sec.
[03/04 11:04:20] epoch:[ 15/30 ] train step:340  loss: 0.94436 lr: 0.001000 batch_cost: 0.35736 sec, reader_cost: 0.00217 sec, ips: 44.77228 instance/sec.
[03/04 11:04:24] epoch:[ 15/30 ] train step:350  loss: 0.81477 lr: 0.001000 batch_cost: 0.35594 sec, reader_cost: 0.00236 sec, ips: 44.95105 instance/sec.
[03/04 11:04:27] epoch:[ 15/30 ] train step:360  loss: 0.87115 lr: 0.001000 batch_cost: 0.35705 sec, reader_cost: 0.00225 sec, ips: 44.81187 instance/sec.
[03/04 11:04:31] epoch:[ 15/30 ] train step:370  loss: 0.85429 lr: 0.001000 batch_cost: 0.35625 sec, reader_cost: 0.00217 sec, ips: 44.91221 instance/sec.
[03/04 11:04:34] epoch:[ 15/30 ] train step:380  loss: 0.79105 lr: 0.001000 batch_cost: 0.35515 sec, reader_cost: 0.00227 sec, ips: 45.05087 instance/sec.
[03/04 11:04:38] epoch:[ 15/30 ] train step:390  loss: 0.78969 lr: 0.001000 batch_cost: 0.35656 sec, reader_cost: 0.00234 sec, ips: 44.87323 instance/sec.
[03/04 11:04:42] epoch:[ 15/30 ] train step:400  loss: 0.90773 lr: 0.001000 batch_cost: 0.35406 sec, reader_cost: 0.00016 sec, ips: 45.19070 instance/sec.
[03/04 11:04:45] epoch:[ 15/30 ] train step:410  loss: 1.00731 lr: 0.001000 batch_cost: 0.35833 sec, reader_cost: 0.00232 sec, ips: 44.65214 instance/sec.
[03/04 11:04:49] epoch:[ 15/30 ] train step:420  loss: 0.91854 lr: 0.001000 batch_cost: 0.35551 sec, reader_cost: 0.00015 sec, ips: 45.00568 instance/sec.
[03/04 11:04:52] epoch:[ 15/30 ] train step:430  loss: 0.93707 lr: 0.001000 batch_cost: 0.35528 sec, reader_cost: 0.00228 sec, ips: 45.03543 instance/sec.
[03/04 11:04:56] epoch:[ 15/30 ] train step:440  loss: 0.99668 lr: 0.001000 batch_cost: 0.35823 sec, reader_cost: 0.00222 sec, ips: 44.66421 instance/sec.
[03/04 11:04:59] epoch:[ 15/30 ] train step:450  loss: 0.60420 lr: 0.001000 batch_cost: 0.35597 sec, reader_cost: 0.00217 sec, ips: 44.94759 instance/sec.
[03/04 11:05:03] epoch:[ 15/30 ] train step:460  loss: 0.81048 lr: 0.001000 batch_cost: 0.35868 sec, reader_cost: 0.00232 sec, ips: 44.60744 instance/sec.
[03/04 11:05:07] epoch:[ 15/30 ] train step:470  loss: 1.03635 lr: 0.001000 batch_cost: 0.35401 sec, reader_cost: 0.00232 sec, ips: 45.19602 instance/sec.
[03/04 11:05:10] epoch:[ 15/30 ] train step:480  loss: 0.70600 lr: 0.001000 batch_cost: 0.35741 sec, reader_cost: 0.00229 sec, ips: 44.76592 instance/sec.
[03/04 11:05:14] epoch:[ 15/30 ] train step:490  loss: 0.91731 lr: 0.001000 batch_cost: 0.35658 sec, reader_cost: 0.00223 sec, ips: 44.87119 instance/sec.
[03/04 11:05:17] epoch:[ 15/30 ] train step:500  loss: 1.07402 lr: 0.001000 batch_cost: 0.35489 sec, reader_cost: 0.00226 sec, ips: 45.08389 instance/sec.
[03/04 11:05:21] epoch:[ 15/30 ] train step:510  loss: 0.80676 lr: 0.001000 batch_cost: 0.35447 sec, reader_cost: 0.00253 sec, ips: 45.13796 instance/sec.
[03/04 11:05:24] epoch:[ 15/30 ] train step:520  loss: 1.01872 lr: 0.001000 batch_cost: 0.35516 sec, reader_cost: 0.00246 sec, ips: 45.05027 instance/sec.
[03/04 11:05:28] epoch:[ 15/30 ] train step:530  loss: 0.86455 lr: 0.001000 batch_cost: 0.36293 sec, reader_cost: 0.00260 sec, ips: 44.08563 instance/sec.
[03/04 11:05:32] epoch:[ 15/30 ] train step:540  loss: 0.87001 lr: 0.001000 batch_cost: 0.35557 sec, reader_cost: 0.00241 sec, ips: 44.99804 instance/sec.
[03/04 11:05:35] epoch:[ 15/30 ] train step:550  loss: 0.79955 lr: 0.001000 batch_cost: 0.35509 sec, reader_cost: 0.00242 sec, ips: 45.05850 instance/sec.
[03/04 11:05:39] epoch:[ 15/30 ] train step:560  loss: 0.78751 lr: 0.001000 batch_cost: 0.35441 sec, reader_cost: 0.00245 sec, ips: 45.14577 instance/sec.
[03/04 11:05:42] epoch:[ 15/30 ] train step:570  loss: 0.72419 lr: 0.001000 batch_cost: 0.36015 sec, reader_cost: 0.00240 sec, ips: 44.42536 instance/sec.
[03/04 11:05:46] epoch:[ 15/30 ] train step:580  loss: 0.83107 lr: 0.001000 batch_cost: 0.35350 sec, reader_cost: 0.00081 sec, ips: 45.26181 instance/sec.
[03/04 11:05:49] epoch:[ 15/30 ] train step:590  loss: 0.93672 lr: 0.001000 batch_cost: 0.35446 sec, reader_cost: 0.00241 sec, ips: 45.13848 instance/sec.
[03/04 11:05:53] epoch:[ 15/30 ] train step:600  loss: 0.84324 lr: 0.001000 batch_cost: 0.35671 sec, reader_cost: 0.00238 sec, ips: 44.85467 instance/sec.
[03/04 11:05:56] epoch:[ 15/30 ] train step:610  loss: 1.00176 lr: 0.001000 batch_cost: 0.35573 sec, reader_cost: 0.00241 sec, ips: 44.97823 instance/sec.
[03/04 11:06:00] epoch:[ 15/30 ] train step:620  loss: 0.77615 lr: 0.001000 batch_cost: 0.35629 sec, reader_cost: 0.00248 sec, ips: 44.90699 instance/sec.
[03/04 11:06:04] epoch:[ 15/30 ] train step:630  loss: 0.59925 lr: 0.001000 batch_cost: 0.35249 sec, reader_cost: 0.00032 sec, ips: 45.39097 instance/sec.
[03/04 11:06:07] epoch:[ 15/30 ] train step:640  loss: 0.97229 lr: 0.001000 batch_cost: 0.35727 sec, reader_cost: 0.00235 sec, ips: 44.78424 instance/sec.
[03/04 11:06:11] epoch:[ 15/30 ] train step:650  loss: 0.86941 lr: 0.001000 batch_cost: 0.35382 sec, reader_cost: 0.00243 sec, ips: 45.22109 instance/sec.
[03/04 11:06:14] epoch:[ 15/30 ] train step:660  loss: 0.76389 lr: 0.001000 batch_cost: 0.35719 sec, reader_cost: 0.00227 sec, ips: 44.79440 instance/sec.
[03/04 11:06:18] epoch:[ 15/30 ] train step:670  loss: 0.60818 lr: 0.001000 batch_cost: 0.35425 sec, reader_cost: 0.00261 sec, ips: 45.16588 instance/sec.
[03/04 11:06:21] epoch:[ 15/30 ] train step:680  loss: 0.69270 lr: 0.001000 batch_cost: 0.35911 sec, reader_cost: 0.00250 sec, ips: 44.55470 instance/sec.
[03/04 11:06:25] epoch:[ 15/30 ] train step:690  loss: 0.83034 lr: 0.001000 batch_cost: 0.35532 sec, reader_cost: 0.00235 sec, ips: 45.02977 instance/sec.
[03/04 11:06:28] epoch:[ 15/30 ] train step:700  loss: 0.79450 lr: 0.001000 batch_cost: 0.35715 sec, reader_cost: 0.00264 sec, ips: 44.79951 instance/sec.
[03/04 11:06:32] epoch:[ 15/30 ] train step:710  loss: 0.90598 lr: 0.001000 batch_cost: 0.35255 sec, reader_cost: 0.00014 sec, ips: 45.38406 instance/sec.
[03/04 11:06:36] epoch:[ 15/30 ] train step:720  loss: 0.94152 lr: 0.001000 batch_cost: 0.35352 sec, reader_cost: 0.00255 sec, ips: 45.25878 instance/sec.
[03/04 11:06:39] epoch:[ 15/30 ] train step:730  loss: 0.67458 lr: 0.001000 batch_cost: 0.35556 sec, reader_cost: 0.00250 sec, ips: 44.99934 instance/sec.
[03/04 11:06:43] epoch:[ 15/30 ] train step:740  loss: 0.76969 lr: 0.001000 batch_cost: 0.35428 sec, reader_cost: 0.00027 sec, ips: 45.16226 instance/sec.
[03/04 11:06:46] epoch:[ 15/30 ] train step:750  loss: 0.74777 lr: 0.001000 batch_cost: 0.35620 sec, reader_cost: 0.00242 sec, ips: 44.91892 instance/sec.
[03/04 11:06:50] epoch:[ 15/30 ] train step:760  loss: 1.04949 lr: 0.001000 batch_cost: 0.35372 sec, reader_cost: 0.00242 sec, ips: 45.23359 instance/sec.
[03/04 11:06:53] epoch:[ 15/30 ] train step:770  loss: 0.89312 lr: 0.001000 batch_cost: 0.35451 sec, reader_cost: 0.00250 sec, ips: 45.13216 instance/sec.
[03/04 11:06:57] epoch:[ 15/30 ] train step:780  loss: 0.98405 lr: 0.001000 batch_cost: 0.35099 sec, reader_cost: 0.00005 sec, ips: 45.58500 instance/sec.
[03/04 11:06:59] END epoch:15  train loss_avg: 0.88104  avg_batch_cost: 0.35142 sec, avg_reader_cost: 0.00006 sec, batch_cost_sum: 280.84204 sec, avg_ips: 44.83659 instance/sec.
[03/04 11:07:01] epoch:[ 16/30 ] train step:0    loss: 0.86869 lr: 0.000100 batch_cost: 1.31300 sec, reader_cost: 0.95004 sec, ips: 12.18583 instance/sec.
[03/04 11:07:04] epoch:[ 16/30 ] train step:10   loss: 1.21857 lr: 0.000100 batch_cost: 0.35664 sec, reader_cost: 0.00263 sec, ips: 44.86321 instance/sec.
[03/04 11:07:08] epoch:[ 16/30 ] train step:20   loss: 0.95330 lr: 0.000100 batch_cost: 0.35619 sec, reader_cost: 0.00013 sec, ips: 44.91970 instance/sec.
[03/04 11:07:11] epoch:[ 16/30 ] train step:30   loss: 0.68946 lr: 0.000100 batch_cost: 0.35614 sec, reader_cost: 0.00012 sec, ips: 44.92592 instance/sec.
[03/04 11:07:15] epoch:[ 16/30 ] train step:40   loss: 0.76836 lr: 0.000100 batch_cost: 0.35550 sec, reader_cost: 0.00246 sec, ips: 45.00640 instance/sec.
[03/04 11:07:18] epoch:[ 16/30 ] train step:50   loss: 0.75983 lr: 0.000100 batch_cost: 0.35737 sec, reader_cost: 0.00019 sec, ips: 44.77130 instance/sec.
[03/04 11:07:22] epoch:[ 16/30 ] train step:60   loss: 0.83785 lr: 0.000100 batch_cost: 0.35448 sec, reader_cost: 0.00013 sec, ips: 45.13632 instance/sec.
[03/04 11:07:25] epoch:[ 16/30 ] train step:70   loss: 0.84671 lr: 0.000100 batch_cost: 0.35682 sec, reader_cost: 0.00219 sec, ips: 44.84073 instance/sec.
[03/04 11:07:29] epoch:[ 16/30 ] train step:80   loss: 1.22971 lr: 0.000100 batch_cost: 0.35249 sec, reader_cost: 0.00012 sec, ips: 45.39170 instance/sec.
[03/04 11:07:32] epoch:[ 16/30 ] train step:90   loss: 0.75830 lr: 0.000100 batch_cost: 0.35860 sec, reader_cost: 0.00260 sec, ips: 44.61845 instance/sec.
[03/04 11:07:36] epoch:[ 16/30 ] train step:100  loss: 0.87463 lr: 0.000100 batch_cost: 0.35377 sec, reader_cost: 0.00012 sec, ips: 45.22706 instance/sec.
[03/04 11:07:40] epoch:[ 16/30 ] train step:110  loss: 0.63005 lr: 0.000100 batch_cost: 0.35483 sec, reader_cost: 0.00014 sec, ips: 45.09210 instance/sec.
[03/04 11:07:43] epoch:[ 16/30 ] train step:120  loss: 0.67114 lr: 0.000100 batch_cost: 0.35187 sec, reader_cost: 0.00011 sec, ips: 45.47071 instance/sec.
[03/04 11:07:47] epoch:[ 16/30 ] train step:130  loss: 1.26947 lr: 0.000100 batch_cost: 0.35602 sec, reader_cost: 0.00252 sec, ips: 44.94094 instance/sec.
[03/04 11:07:50] epoch:[ 16/30 ] train step:140  loss: 0.79045 lr: 0.000100 batch_cost: 0.35641 sec, reader_cost: 0.00015 sec, ips: 44.89224 instance/sec.
[03/04 11:07:54] epoch:[ 16/30 ] train step:150  loss: 1.35160 lr: 0.000100 batch_cost: 0.35348 sec, reader_cost: 0.00014 sec, ips: 45.26416 instance/sec.
[03/04 11:07:57] epoch:[ 16/30 ] train step:160  loss: 0.73991 lr: 0.000100 batch_cost: 0.35574 sec, reader_cost: 0.00238 sec, ips: 44.97726 instance/sec.
[03/04 11:08:01] epoch:[ 16/30 ] train step:170  loss: 0.74462 lr: 0.000100 batch_cost: 0.35573 sec, reader_cost: 0.00018 sec, ips: 44.97853 instance/sec.
[03/04 11:08:04] epoch:[ 16/30 ] train step:180  loss: 0.77377 lr: 0.000100 batch_cost: 0.35639 sec, reader_cost: 0.00013 sec, ips: 44.89422 instance/sec.
[03/04 11:08:08] epoch:[ 16/30 ] train step:190  loss: 0.75146 lr: 0.000100 batch_cost: 0.35436 sec, reader_cost: 0.00014 sec, ips: 45.15163 instance/sec.
[03/04 11:08:12] epoch:[ 16/30 ] train step:200  loss: 0.87698 lr: 0.000100 batch_cost: 0.35575 sec, reader_cost: 0.00261 sec, ips: 44.97551 instance/sec.
[03/04 11:08:15] epoch:[ 16/30 ] train step:210  loss: 0.81370 lr: 0.000100 batch_cost: 0.35618 sec, reader_cost: 0.00238 sec, ips: 44.92081 instance/sec.
[03/04 11:08:19] epoch:[ 16/30 ] train step:220  loss: 0.89002 lr: 0.000100 batch_cost: 0.35690 sec, reader_cost: 0.00013 sec, ips: 44.82998 instance/sec.
[03/04 11:08:22] epoch:[ 16/30 ] train step:230  loss: 0.77973 lr: 0.000100 batch_cost: 0.35221 sec, reader_cost: 0.00013 sec, ips: 45.42744 instance/sec.
[03/04 11:08:26] epoch:[ 16/30 ] train step:240  loss: 1.27870 lr: 0.000100 batch_cost: 0.35242 sec, reader_cost: 0.00013 sec, ips: 45.40076 instance/sec.
[03/04 11:08:29] epoch:[ 16/30 ] train step:250  loss: 0.70007 lr: 0.000100 batch_cost: 0.35775 sec, reader_cost: 0.00248 sec, ips: 44.72439 instance/sec.
[03/04 11:08:33] epoch:[ 16/30 ] train step:260  loss: 0.68743 lr: 0.000100 batch_cost: 0.35512 sec, reader_cost: 0.00013 sec, ips: 45.05553 instance/sec.
[03/04 11:08:36] epoch:[ 16/30 ] train step:270  loss: 0.84183 lr: 0.000100 batch_cost: 0.35435 sec, reader_cost: 0.00015 sec, ips: 45.15369 instance/sec.
[03/04 11:08:40] epoch:[ 16/30 ] train step:280  loss: 0.86523 lr: 0.000100 batch_cost: 0.35758 sec, reader_cost: 0.00024 sec, ips: 44.74512 instance/sec.
[03/04 11:08:44] epoch:[ 16/30 ] train step:290  loss: 0.93216 lr: 0.000100 batch_cost: 0.35632 sec, reader_cost: 0.00245 sec, ips: 44.90371 instance/sec.
[03/04 11:08:47] epoch:[ 16/30 ] train step:300  loss: 1.03284 lr: 0.000100 batch_cost: 0.35444 sec, reader_cost: 0.00011 sec, ips: 45.14130 instance/sec.
[03/04 11:08:51] epoch:[ 16/30 ] train step:310  loss: 0.82950 lr: 0.000100 batch_cost: 0.35386 sec, reader_cost: 0.00014 sec, ips: 45.21600 instance/sec.
[03/04 11:08:54] epoch:[ 16/30 ] train step:320  loss: 0.87799 lr: 0.000100 batch_cost: 0.35644 sec, reader_cost: 0.00239 sec, ips: 44.88776 instance/sec.
[03/04 11:08:58] epoch:[ 16/30 ] train step:330  loss: 0.97759 lr: 0.000100 batch_cost: 0.35576 sec, reader_cost: 0.00036 sec, ips: 44.97392 instance/sec.
[03/04 11:09:01] epoch:[ 16/30 ] train step:340  loss: 0.79132 lr: 0.000100 batch_cost: 0.35503 sec, reader_cost: 0.00015 sec, ips: 45.06703 instance/sec.
[03/04 11:09:05] epoch:[ 16/30 ] train step:350  loss: 0.78251 lr: 0.000100 batch_cost: 0.35769 sec, reader_cost: 0.00015 sec, ips: 44.73137 instance/sec.
[03/04 11:09:08] epoch:[ 16/30 ] train step:360  loss: 0.73947 lr: 0.000100 batch_cost: 0.35446 sec, reader_cost: 0.00024 sec, ips: 45.13857 instance/sec.
[03/04 11:09:12] epoch:[ 16/30 ] train step:370  loss: 0.74164 lr: 0.000100 batch_cost: 0.35337 sec, reader_cost: 0.00016 sec, ips: 45.27772 instance/sec.
[03/04 11:09:16] epoch:[ 16/30 ] train step:380  loss: 0.66931 lr: 0.000100 batch_cost: 0.35419 sec, reader_cost: 0.00010 sec, ips: 45.17315 instance/sec.
[03/04 11:09:19] epoch:[ 16/30 ] train step:390  loss: 1.19699 lr: 0.000100 batch_cost: 0.35315 sec, reader_cost: 0.00014 sec, ips: 45.30599 instance/sec.
[03/04 11:09:23] epoch:[ 16/30 ] train step:400  loss: 0.78208 lr: 0.000100 batch_cost: 0.35451 sec, reader_cost: 0.00026 sec, ips: 45.13332 instance/sec.
[03/04 11:09:26] epoch:[ 16/30 ] train step:410  loss: 0.79804 lr: 0.000100 batch_cost: 0.35800 sec, reader_cost: 0.00016 sec, ips: 44.69255 instance/sec.
[03/04 11:09:30] epoch:[ 16/30 ] train step:420  loss: 0.73832 lr: 0.000100 batch_cost: 0.35850 sec, reader_cost: 0.00016 sec, ips: 44.62990 instance/sec.
[03/04 11:09:33] epoch:[ 16/30 ] train step:430  loss: 0.85357 lr: 0.000100 batch_cost: 0.35538 sec, reader_cost: 0.00012 sec, ips: 45.02210 instance/sec.
[03/04 11:09:37] epoch:[ 16/30 ] train step:440  loss: 0.75529 lr: 0.000100 batch_cost: 0.35803 sec, reader_cost: 0.00252 sec, ips: 44.68925 instance/sec.
[03/04 11:09:40] epoch:[ 16/30 ] train step:450  loss: 0.68436 lr: 0.000100 batch_cost: 0.35583 sec, reader_cost: 0.00015 sec, ips: 44.96527 instance/sec.
[03/04 11:09:44] epoch:[ 16/30 ] train step:460  loss: 0.76976 lr: 0.000100 batch_cost: 0.35678 sec, reader_cost: 0.00051 sec, ips: 44.84619 instance/sec.
[03/04 11:09:48] epoch:[ 16/30 ] train step:470  loss: 0.95560 lr: 0.000100 batch_cost: 0.35476 sec, reader_cost: 0.00249 sec, ips: 45.10144 instance/sec.
[03/04 11:09:51] epoch:[ 16/30 ] train step:480  loss: 0.84976 lr: 0.000100 batch_cost: 0.35695 sec, reader_cost: 0.00258 sec, ips: 44.82381 instance/sec.
[03/04 11:09:55] epoch:[ 16/30 ] train step:490  loss: 0.63805 lr: 0.000100 batch_cost: 0.35576 sec, reader_cost: 0.00015 sec, ips: 44.97407 instance/sec.
[03/04 11:09:58] epoch:[ 16/30 ] train step:500  loss: 0.89133 lr: 0.000100 batch_cost: 0.35421 sec, reader_cost: 0.00012 sec, ips: 45.17038 instance/sec.
[03/04 11:10:02] epoch:[ 16/30 ] train step:510  loss: 0.59906 lr: 0.000100 batch_cost: 0.35618 sec, reader_cost: 0.00269 sec, ips: 44.92162 instance/sec.
[03/04 11:10:05] epoch:[ 16/30 ] train step:520  loss: 0.78910 lr: 0.000100 batch_cost: 0.35539 sec, reader_cost: 0.00254 sec, ips: 45.02138 instance/sec.
[03/04 11:10:09] epoch:[ 16/30 ] train step:530  loss: 0.85265 lr: 0.000100 batch_cost: 0.35728 sec, reader_cost: 0.00253 sec, ips: 44.78253 instance/sec.
[03/04 11:10:13] epoch:[ 16/30 ] train step:540  loss: 1.13608 lr: 0.000100 batch_cost: 0.35160 sec, reader_cost: 0.00012 sec, ips: 45.50624 instance/sec.
[03/04 11:10:16] epoch:[ 16/30 ] train step:550  loss: 0.74614 lr: 0.000100 batch_cost: 0.35588 sec, reader_cost: 0.00230 sec, ips: 44.95957 instance/sec.
[03/04 11:10:20] epoch:[ 16/30 ] train step:560  loss: 0.90596 lr: 0.000100 batch_cost: 0.35306 sec, reader_cost: 0.00265 sec, ips: 45.31823 instance/sec.
[03/04 11:10:23] epoch:[ 16/30 ] train step:570  loss: 0.71967 lr: 0.000100 batch_cost: 0.35768 sec, reader_cost: 0.00016 sec, ips: 44.73328 instance/sec.
[03/04 11:10:27] epoch:[ 16/30 ] train step:580  loss: 0.76557 lr: 0.000100 batch_cost: 0.35496 sec, reader_cost: 0.00012 sec, ips: 45.07523 instance/sec.
[03/04 11:10:30] epoch:[ 16/30 ] train step:590  loss: 0.68451 lr: 0.000100 batch_cost: 0.35437 sec, reader_cost: 0.00234 sec, ips: 45.15078 instance/sec.
[03/04 11:10:34] epoch:[ 16/30 ] train step:600  loss: 0.84159 lr: 0.000100 batch_cost: 0.35392 sec, reader_cost: 0.00236 sec, ips: 45.20796 instance/sec.
[03/04 11:10:37] epoch:[ 16/30 ] train step:610  loss: 0.76863 lr: 0.000100 batch_cost: 0.35616 sec, reader_cost: 0.00259 sec, ips: 44.92382 instance/sec.
[03/04 11:10:41] epoch:[ 16/30 ] train step:620  loss: 0.58484 lr: 0.000100 batch_cost: 0.35637 sec, reader_cost: 0.00232 sec, ips: 44.89734 instance/sec.
[03/04 11:10:45] epoch:[ 16/30 ] train step:630  loss: 0.83270 lr: 0.000100 batch_cost: 0.35460 sec, reader_cost: 0.00023 sec, ips: 45.12133 instance/sec.
[03/04 11:10:48] epoch:[ 16/30 ] train step:640  loss: 0.67940 lr: 0.000100 batch_cost: 0.35852 sec, reader_cost: 0.00268 sec, ips: 44.62824 instance/sec.
[03/04 11:10:52] epoch:[ 16/30 ] train step:650  loss: 0.70769 lr: 0.000100 batch_cost: 0.35553 sec, reader_cost: 0.00245 sec, ips: 45.00371 instance/sec.
[03/04 11:10:55] epoch:[ 16/30 ] train step:660  loss: 0.69359 lr: 0.000100 batch_cost: 0.35695 sec, reader_cost: 0.00012 sec, ips: 44.82408 instance/sec.
[03/04 11:10:59] epoch:[ 16/30 ] train step:670  loss: 0.94938 lr: 0.000100 batch_cost: 0.35189 sec, reader_cost: 0.00024 sec, ips: 45.46816 instance/sec.
[03/04 11:11:02] epoch:[ 16/30 ] train step:680  loss: 0.73621 lr: 0.000100 batch_cost: 0.35812 sec, reader_cost: 0.00244 sec, ips: 44.67747 instance/sec.
[03/04 11:11:06] epoch:[ 16/30 ] train step:690  loss: 0.74883 lr: 0.000100 batch_cost: 0.35639 sec, reader_cost: 0.00254 sec, ips: 44.89437 instance/sec.
[03/04 11:11:09] epoch:[ 16/30 ] train step:700  loss: 0.74997 lr: 0.000100 batch_cost: 0.35309 sec, reader_cost: 0.00012 sec, ips: 45.31474 instance/sec.
[03/04 11:11:13] epoch:[ 16/30 ] train step:710  loss: 0.81901 lr: 0.000100 batch_cost: 0.35506 sec, reader_cost: 0.00266 sec, ips: 45.06231 instance/sec.
[03/04 11:11:17] epoch:[ 16/30 ] train step:720  loss: 0.96751 lr: 0.000100 batch_cost: 0.35777 sec, reader_cost: 0.00268 sec, ips: 44.72174 instance/sec.
[03/04 11:11:20] epoch:[ 16/30 ] train step:730  loss: 0.71677 lr: 0.000100 batch_cost: 0.35666 sec, reader_cost: 0.00257 sec, ips: 44.86121 instance/sec.
[03/04 11:11:24] epoch:[ 16/30 ] train step:740  loss: 0.77663 lr: 0.000100 batch_cost: 0.35647 sec, reader_cost: 0.00225 sec, ips: 44.88485 instance/sec.
[03/04 11:11:27] epoch:[ 16/30 ] train step:750  loss: 0.79181 lr: 0.000100 batch_cost: 0.35728 sec, reader_cost: 0.00254 sec, ips: 44.78301 instance/sec.
[03/04 11:11:31] epoch:[ 16/30 ] train step:760  loss: 0.95165 lr: 0.000100 batch_cost: 0.35579 sec, reader_cost: 0.00024 sec, ips: 44.97072 instance/sec.
[03/04 11:11:34] epoch:[ 16/30 ] train step:770  loss: 0.70392 lr: 0.000100 batch_cost: 0.35969 sec, reader_cost: 0.00279 sec, ips: 44.48314 instance/sec.
[03/04 11:11:38] epoch:[ 16/30 ] train step:780  loss: 0.82118 lr: 0.000100 batch_cost: 0.35078 sec, reader_cost: 0.00008 sec, ips: 45.61270 instance/sec.
[03/04 11:11:40] END epoch:16  train loss_avg: 0.83132  avg_batch_cost: 0.35189 sec, avg_reader_cost: 0.00007 sec, batch_cost_sum: 280.74388 sec, avg_ips: 44.85227 instance/sec.
[03/04 11:11:42] epoch:[ 17/30 ] train step:0    loss: 0.56441 lr: 0.000100 batch_cost: 1.28870 sec, reader_cost: 0.92087 sec, ips: 12.41563 instance/sec.
[03/04 11:11:45] epoch:[ 17/30 ] train step:10   loss: 0.86339 lr: 0.000100 batch_cost: 0.35931 sec, reader_cost: 0.00238 sec, ips: 44.52963 instance/sec.
[03/04 11:11:49] epoch:[ 17/30 ] train step:20   loss: 0.86335 lr: 0.000100 batch_cost: 0.35698 sec, reader_cost: 0.00235 sec, ips: 44.82028 instance/sec.
[03/04 11:11:52] epoch:[ 17/30 ] train step:30   loss: 0.94779 lr: 0.000100 batch_cost: 0.35673 sec, reader_cost: 0.00247 sec, ips: 44.85164 instance/sec.
[03/04 11:11:56] epoch:[ 17/30 ] train step:40   loss: 0.87089 lr: 0.000100 batch_cost: 0.35678 sec, reader_cost: 0.00136 sec, ips: 44.84577 instance/sec.
[03/04 11:11:59] epoch:[ 17/30 ] train step:50   loss: 0.88939 lr: 0.000100 batch_cost: 0.35230 sec, reader_cost: 0.00009 sec, ips: 45.41560 instance/sec.
[03/04 11:12:03] epoch:[ 17/30 ] train step:60   loss: 0.76494 lr: 0.000100 batch_cost: 0.35623 sec, reader_cost: 0.00219 sec, ips: 44.91474 instance/sec.
[03/04 11:12:07] epoch:[ 17/30 ] train step:70   loss: 1.03137 lr: 0.000100 batch_cost: 0.35698 sec, reader_cost: 0.00217 sec, ips: 44.82037 instance/sec.
[03/04 11:12:10] epoch:[ 17/30 ] train step:80   loss: 0.85075 lr: 0.000100 batch_cost: 0.35570 sec, reader_cost: 0.00215 sec, ips: 44.98145 instance/sec.
[03/04 11:12:14] epoch:[ 17/30 ] train step:90   loss: 0.82847 lr: 0.000100 batch_cost: 0.35546 sec, reader_cost: 0.00015 sec, ips: 45.01250 instance/sec.
[03/04 11:12:17] epoch:[ 17/30 ] train step:100  loss: 0.76324 lr: 0.000100 batch_cost: 0.35826 sec, reader_cost: 0.00256 sec, ips: 44.66008 instance/sec.
[03/04 11:12:21] epoch:[ 17/30 ] train step:110  loss: 0.79906 lr: 0.000100 batch_cost: 0.36158 sec, reader_cost: 0.00222 sec, ips: 44.24964 instance/sec.
[03/04 11:12:24] epoch:[ 17/30 ] train step:120  loss: 0.64818 lr: 0.000100 batch_cost: 0.35398 sec, reader_cost: 0.00209 sec, ips: 45.20035 instance/sec.
[03/04 11:12:28] epoch:[ 17/30 ] train step:130  loss: 0.88954 lr: 0.000100 batch_cost: 0.35891 sec, reader_cost: 0.00241 sec, ips: 44.57956 instance/sec.
[03/04 11:12:32] epoch:[ 17/30 ] train step:140  loss: 1.02274 lr: 0.000100 batch_cost: 0.35390 sec, reader_cost: 0.00012 sec, ips: 45.21088 instance/sec.
[03/04 11:12:35] epoch:[ 17/30 ] train step:150  loss: 0.69539 lr: 0.000100 batch_cost: 0.35535 sec, reader_cost: 0.00231 sec, ips: 45.02627 instance/sec.
[03/04 11:12:39] epoch:[ 17/30 ] train step:160  loss: 0.69851 lr: 0.000100 batch_cost: 0.35665 sec, reader_cost: 0.00016 sec, ips: 44.86202 instance/sec.
[03/04 11:12:42] epoch:[ 17/30 ] train step:170  loss: 0.86028 lr: 0.000100 batch_cost: 0.35802 sec, reader_cost: 0.00247 sec, ips: 44.68993 instance/sec.
[03/04 11:12:46] epoch:[ 17/30 ] train step:180  loss: 0.79821 lr: 0.000100 batch_cost: 0.35692 sec, reader_cost: 0.00238 sec, ips: 44.82845 instance/sec.
[03/04 11:12:49] epoch:[ 17/30 ] train step:190  loss: 0.74273 lr: 0.000100 batch_cost: 0.35460 sec, reader_cost: 0.00016 sec, ips: 45.12127 instance/sec.
[03/04 11:12:53] epoch:[ 17/30 ] train step:200  loss: 0.89156 lr: 0.000100 batch_cost: 0.35869 sec, reader_cost: 0.00228 sec, ips: 44.60655 instance/sec.
[03/04 11:12:56] epoch:[ 17/30 ] train step:210  loss: 0.83862 lr: 0.000100 batch_cost: 0.35512 sec, reader_cost: 0.00238 sec, ips: 45.05490 instance/sec.
[03/04 11:13:00] epoch:[ 17/30 ] train step:220  loss: 1.02489 lr: 0.000100 batch_cost: 0.35752 sec, reader_cost: 0.00228 sec, ips: 44.75228 instance/sec.
[03/04 11:13:04] epoch:[ 17/30 ] train step:230  loss: 0.69132 lr: 0.000100 batch_cost: 0.35753 sec, reader_cost: 0.00014 sec, ips: 44.75106 instance/sec.
[03/04 11:13:07] epoch:[ 17/30 ] train step:240  loss: 0.72832 lr: 0.000100 batch_cost: 0.35658 sec, reader_cost: 0.00268 sec, ips: 44.87047 instance/sec.
[03/04 11:13:11] epoch:[ 17/30 ] train step:250  loss: 0.74017 lr: 0.000100 batch_cost: 0.35975 sec, reader_cost: 0.00262 sec, ips: 44.47595 instance/sec.
[03/04 11:13:14] epoch:[ 17/30 ] train step:260  loss: 0.93803 lr: 0.000100 batch_cost: 0.35676 sec, reader_cost: 0.00240 sec, ips: 44.84837 instance/sec.
[03/04 11:13:18] epoch:[ 17/30 ] train step:270  loss: 0.71496 lr: 0.000100 batch_cost: 0.35871 sec, reader_cost: 0.00260 sec, ips: 44.60368 instance/sec.
[03/04 11:13:21] epoch:[ 17/30 ] train step:280  loss: 0.80932 lr: 0.000100 batch_cost: 0.35788 sec, reader_cost: 0.00242 sec, ips: 44.70729 instance/sec.
[03/04 11:13:25] epoch:[ 17/30 ] train step:290  loss: 1.03350 lr: 0.000100 batch_cost: 0.35439 sec, reader_cost: 0.00041 sec, ips: 45.14823 instance/sec.
[03/04 11:13:29] epoch:[ 17/30 ] train step:300  loss: 1.36084 lr: 0.000100 batch_cost: 0.35694 sec, reader_cost: 0.00235 sec, ips: 44.82531 instance/sec.
[03/04 11:13:32] epoch:[ 17/30 ] train step:310  loss: 0.98390 lr: 0.000100 batch_cost: 0.35771 sec, reader_cost: 0.00222 sec, ips: 44.72934 instance/sec.
[03/04 11:13:36] epoch:[ 17/30 ] train step:320  loss: 0.82752 lr: 0.000100 batch_cost: 0.35795 sec, reader_cost: 0.00245 sec, ips: 44.69836 instance/sec.
[03/04 11:13:39] epoch:[ 17/30 ] train step:330  loss: 0.73882 lr: 0.000100 batch_cost: 0.35740 sec, reader_cost: 0.00237 sec, ips: 44.76807 instance/sec.
[03/04 11:13:43] epoch:[ 17/30 ] train step:340  loss: 0.72364 lr: 0.000100 batch_cost: 0.35713 sec, reader_cost: 0.00016 sec, ips: 44.80128 instance/sec.
[03/04 11:13:46] epoch:[ 17/30 ] train step:350  loss: 0.80113 lr: 0.000100 batch_cost: 0.35745 sec, reader_cost: 0.00215 sec, ips: 44.76150 instance/sec.
[03/04 11:13:50] epoch:[ 17/30 ] train step:360  loss: 0.95332 lr: 0.000100 batch_cost: 0.35575 sec, reader_cost: 0.00014 sec, ips: 44.97600 instance/sec.
[03/04 11:13:54] epoch:[ 17/30 ] train step:370  loss: 0.87230 lr: 0.000100 batch_cost: 0.35672 sec, reader_cost: 0.00027 sec, ips: 44.85371 instance/sec.
[03/04 11:13:57] epoch:[ 17/30 ] train step:380  loss: 0.74254 lr: 0.000100 batch_cost: 0.35707 sec, reader_cost: 0.00241 sec, ips: 44.80920 instance/sec.
[03/04 11:14:01] epoch:[ 17/30 ] train step:390  loss: 0.88316 lr: 0.000100 batch_cost: 0.36025 sec, reader_cost: 0.00218 sec, ips: 44.41416 instance/sec.
[03/04 11:14:04] epoch:[ 17/30 ] train step:400  loss: 1.08242 lr: 0.000100 batch_cost: 0.35650 sec, reader_cost: 0.00220 sec, ips: 44.88131 instance/sec.
[03/04 11:14:08] epoch:[ 17/30 ] train step:410  loss: 0.71139 lr: 0.000100 batch_cost: 0.35550 sec, reader_cost: 0.00020 sec, ips: 45.00706 instance/sec.
[03/04 11:14:11] epoch:[ 17/30 ] train step:420  loss: 0.64214 lr: 0.000100 batch_cost: 0.35595 sec, reader_cost: 0.00015 sec, ips: 44.94970 instance/sec.
[03/04 11:14:15] epoch:[ 17/30 ] train step:430  loss: 0.74291 lr: 0.000100 batch_cost: 0.35568 sec, reader_cost: 0.00220 sec, ips: 44.98411 instance/sec.
[03/04 11:14:19] epoch:[ 17/30 ] train step:440  loss: 0.77081 lr: 0.000100 batch_cost: 0.35886 sec, reader_cost: 0.00227 sec, ips: 44.58613 instance/sec.
[03/04 11:14:22] epoch:[ 17/30 ] train step:450  loss: 0.84920 lr: 0.000100 batch_cost: 0.35637 sec, reader_cost: 0.00228 sec, ips: 44.89728 instance/sec.
[03/04 11:14:26] epoch:[ 17/30 ] train step:460  loss: 0.82584 lr: 0.000100 batch_cost: 0.35783 sec, reader_cost: 0.00237 sec, ips: 44.71450 instance/sec.
[03/04 11:14:29] epoch:[ 17/30 ] train step:470  loss: 0.73693 lr: 0.000100 batch_cost: 0.35585 sec, reader_cost: 0.00232 sec, ips: 44.96283 instance/sec.
[03/04 11:14:33] epoch:[ 17/30 ] train step:480  loss: 0.86451 lr: 0.000100 batch_cost: 0.35547 sec, reader_cost: 0.00016 sec, ips: 45.01099 instance/sec.
[03/04 11:14:36] epoch:[ 17/30 ] train step:490  loss: 0.72731 lr: 0.000100 batch_cost: 0.35614 sec, reader_cost: 0.00011 sec, ips: 44.92626 instance/sec.
[03/04 11:14:40] epoch:[ 17/30 ] train step:500  loss: 0.97796 lr: 0.000100 batch_cost: 0.35412 sec, reader_cost: 0.00244 sec, ips: 45.18197 instance/sec.
[03/04 11:14:44] epoch:[ 17/30 ] train step:510  loss: 0.84964 lr: 0.000100 batch_cost: 0.35724 sec, reader_cost: 0.00250 sec, ips: 44.78836 instance/sec.
[03/04 11:14:47] epoch:[ 17/30 ] train step:520  loss: 0.84511 lr: 0.000100 batch_cost: 0.35633 sec, reader_cost: 0.00246 sec, ips: 44.90242 instance/sec.
[03/04 11:14:51] epoch:[ 17/30 ] train step:530  loss: 0.77818 lr: 0.000100 batch_cost: 0.35303 sec, reader_cost: 0.00015 sec, ips: 45.32181 instance/sec.
[03/04 11:14:54] epoch:[ 17/30 ] train step:540  loss: 0.68580 lr: 0.000100 batch_cost: 0.35803 sec, reader_cost: 0.00258 sec, ips: 44.68937 instance/sec.
[03/04 11:14:58] epoch:[ 17/30 ] train step:550  loss: 0.80163 lr: 0.000100 batch_cost: 0.35788 sec, reader_cost: 0.00249 sec, ips: 44.70804 instance/sec.
[03/04 11:15:01] epoch:[ 17/30 ] train step:560  loss: 0.73946 lr: 0.000100 batch_cost: 0.35654 sec, reader_cost: 0.00249 sec, ips: 44.87512 instance/sec.
[03/04 11:15:05] epoch:[ 17/30 ] train step:570  loss: 1.17872 lr: 0.000100 batch_cost: 0.35321 sec, reader_cost: 0.00013 sec, ips: 45.29828 instance/sec.
[03/04 11:15:08] epoch:[ 17/30 ] train step:580  loss: 0.96825 lr: 0.000100 batch_cost: 0.35708 sec, reader_cost: 0.00244 sec, ips: 44.80786 instance/sec.
[03/04 11:15:12] epoch:[ 17/30 ] train step:590  loss: 0.74837 lr: 0.000100 batch_cost: 0.35128 sec, reader_cost: 0.00022 sec, ips: 45.54824 instance/sec.
[03/04 11:15:16] epoch:[ 17/30 ] train step:600  loss: 1.21851 lr: 0.000100 batch_cost: 0.35616 sec, reader_cost: 0.00242 sec, ips: 44.92400 instance/sec.
[03/04 11:15:19] epoch:[ 17/30 ] train step:610  loss: 0.83293 lr: 0.000100 batch_cost: 0.35425 sec, reader_cost: 0.00227 sec, ips: 45.16561 instance/sec.
[03/04 11:15:23] epoch:[ 17/30 ] train step:620  loss: 0.81536 lr: 0.000100 batch_cost: 0.35622 sec, reader_cost: 0.00025 sec, ips: 44.91621 instance/sec.
[03/04 11:15:26] epoch:[ 17/30 ] train step:630  loss: 0.91074 lr: 0.000100 batch_cost: 0.35284 sec, reader_cost: 0.00012 sec, ips: 45.34680 instance/sec.
[03/04 11:15:30] epoch:[ 17/30 ] train step:640  loss: 0.94357 lr: 0.000100 batch_cost: 0.35605 sec, reader_cost: 0.00237 sec, ips: 44.93736 instance/sec.
[03/04 11:15:33] epoch:[ 17/30 ] train step:650  loss: 0.86485 lr: 0.000100 batch_cost: 0.35426 sec, reader_cost: 0.00240 sec, ips: 45.16442 instance/sec.
[03/04 11:15:37] epoch:[ 17/30 ] train step:660  loss: 0.71131 lr: 0.000100 batch_cost: 0.35692 sec, reader_cost: 0.00247 sec, ips: 44.82770 instance/sec.
[03/04 11:15:40] epoch:[ 17/30 ] train step:670  loss: 0.67871 lr: 0.000100 batch_cost: 0.35263 sec, reader_cost: 0.00021 sec, ips: 45.37295 instance/sec.
[03/04 11:15:44] epoch:[ 17/30 ] train step:680  loss: 0.94100 lr: 0.000100 batch_cost: 0.35739 sec, reader_cost: 0.00254 sec, ips: 44.76882 instance/sec.
[03/04 11:15:47] epoch:[ 17/30 ] train step:690  loss: 0.68710 lr: 0.000100 batch_cost: 0.35520 sec, reader_cost: 0.00246 sec, ips: 45.04483 instance/sec.
[03/04 11:15:51] epoch:[ 17/30 ] train step:700  loss: 0.82881 lr: 0.000100 batch_cost: 0.35441 sec, reader_cost: 0.00261 sec, ips: 45.14567 instance/sec.
[03/04 11:15:55] epoch:[ 17/30 ] train step:710  loss: 0.79913 lr: 0.000100 batch_cost: 0.35336 sec, reader_cost: 0.00010 sec, ips: 45.28001 instance/sec.
[03/04 11:15:58] epoch:[ 17/30 ] train step:720  loss: 0.65466 lr: 0.000100 batch_cost: 0.35484 sec, reader_cost: 0.00252 sec, ips: 45.09080 instance/sec.
[03/04 11:16:02] epoch:[ 17/30 ] train step:730  loss: 0.81802 lr: 0.000100 batch_cost: 0.35405 sec, reader_cost: 0.00011 sec, ips: 45.19170 instance/sec.
[03/04 11:16:05] epoch:[ 17/30 ] train step:740  loss: 0.95315 lr: 0.000100 batch_cost: 0.35282 sec, reader_cost: 0.00013 sec, ips: 45.34943 instance/sec.
[03/04 11:16:09] epoch:[ 17/30 ] train step:750  loss: 0.92104 lr: 0.000100 batch_cost: 0.35529 sec, reader_cost: 0.00251 sec, ips: 45.03416 instance/sec.
[03/04 11:16:12] epoch:[ 17/30 ] train step:760  loss: 0.91456 lr: 0.000100 batch_cost: 0.35351 sec, reader_cost: 0.00250 sec, ips: 45.26010 instance/sec.
[03/04 11:16:16] epoch:[ 17/30 ] train step:770  loss: 0.96483 lr: 0.000100 batch_cost: 0.35393 sec, reader_cost: 0.00018 sec, ips: 45.20656 instance/sec.
[03/04 11:16:19] epoch:[ 17/30 ] train step:780  loss: 0.77952 lr: 0.000100 batch_cost: 0.35229 sec, reader_cost: 0.00005 sec, ips: 45.41689 instance/sec.
[03/04 11:16:22] END epoch:17  train loss_avg: 0.81703  avg_batch_cost: 0.34894 sec, avg_reader_cost: 0.00016 sec, batch_cost_sum: 281.22218 sec, avg_ips: 44.77599 instance/sec.
[03/04 11:16:23] epoch:[ 18/30 ] train step:0    loss: 0.77270 lr: 0.000100 batch_cost: 1.33445 sec, reader_cost: 0.96743 sec, ips: 11.98993 instance/sec.
[03/04 11:16:27] epoch:[ 18/30 ] train step:10   loss: 0.80745 lr: 0.000100 batch_cost: 0.35938 sec, reader_cost: 0.00544 sec, ips: 44.52159 instance/sec.
[03/04 11:16:30] epoch:[ 18/30 ] train step:20   loss: 0.74713 lr: 0.000100 batch_cost: 0.35327 sec, reader_cost: 0.00011 sec, ips: 45.29144 instance/sec.
[03/04 11:16:34] epoch:[ 18/30 ] train step:30   loss: 0.76900 lr: 0.000100 batch_cost: 0.35455 sec, reader_cost: 0.00010 sec, ips: 45.12773 instance/sec.
[03/04 11:16:37] epoch:[ 18/30 ] train step:40   loss: 0.90642 lr: 0.000100 batch_cost: 0.35444 sec, reader_cost: 0.00011 sec, ips: 45.14154 instance/sec.
[03/04 11:16:41] epoch:[ 18/30 ] train step:50   loss: 0.78736 lr: 0.000100 batch_cost: 0.35544 sec, reader_cost: 0.00217 sec, ips: 45.01519 instance/sec.
[03/04 11:16:44] epoch:[ 18/30 ] train step:60   loss: 0.78395 lr: 0.000100 batch_cost: 0.35240 sec, reader_cost: 0.00008 sec, ips: 45.40273 instance/sec.
[03/04 11:16:48] epoch:[ 18/30 ] train step:70   loss: 0.84214 lr: 0.000100 batch_cost: 0.35299 sec, reader_cost: 0.00011 sec, ips: 45.32756 instance/sec.
[03/04 11:16:51] epoch:[ 18/30 ] train step:80   loss: 0.92018 lr: 0.000100 batch_cost: 0.35532 sec, reader_cost: 0.00012 sec, ips: 45.02974 instance/sec.
[03/04 11:16:55] epoch:[ 18/30 ] train step:90   loss: 0.68504 lr: 0.000100 batch_cost: 0.35261 sec, reader_cost: 0.00013 sec, ips: 45.37599 instance/sec.
[03/04 11:16:59] epoch:[ 18/30 ] train step:100  loss: 0.95692 lr: 0.000100 batch_cost: 0.35545 sec, reader_cost: 0.00219 sec, ips: 45.01340 instance/sec.
[03/04 11:17:02] epoch:[ 18/30 ] train step:110  loss: 0.71505 lr: 0.000100 batch_cost: 0.35776 sec, reader_cost: 0.00249 sec, ips: 44.72278 instance/sec.
[03/04 11:17:06] epoch:[ 18/30 ] train step:120  loss: 1.06970 lr: 0.000100 batch_cost: 0.35439 sec, reader_cost: 0.00013 sec, ips: 45.14859 instance/sec.
[03/04 11:17:09] epoch:[ 18/30 ] train step:130  loss: 0.75421 lr: 0.000100 batch_cost: 0.35489 sec, reader_cost: 0.00219 sec, ips: 45.08435 instance/sec.
[03/04 11:17:13] epoch:[ 18/30 ] train step:140  loss: 0.85082 lr: 0.000100 batch_cost: 0.35418 sec, reader_cost: 0.00011 sec, ips: 45.17464 instance/sec.
[03/04 11:17:16] epoch:[ 18/30 ] train step:150  loss: 0.95114 lr: 0.000100 batch_cost: 0.35681 sec, reader_cost: 0.00247 sec, ips: 44.84160 instance/sec.
[03/04 11:17:20] epoch:[ 18/30 ] train step:160  loss: 0.73343 lr: 0.000100 batch_cost: 0.35372 sec, reader_cost: 0.00011 sec, ips: 45.23413 instance/sec.
[03/04 11:17:23] epoch:[ 18/30 ] train step:170  loss: 0.71646 lr: 0.000100 batch_cost: 0.35508 sec, reader_cost: 0.00008 sec, ips: 45.06004 instance/sec.
[03/04 11:17:27] epoch:[ 18/30 ] train step:180  loss: 0.80226 lr: 0.000100 batch_cost: 0.35163 sec, reader_cost: 0.00011 sec, ips: 45.50188 instance/sec.
[03/04 11:17:30] epoch:[ 18/30 ] train step:190  loss: 1.03413 lr: 0.000100 batch_cost: 0.35377 sec, reader_cost: 0.00011 sec, ips: 45.22660 instance/sec.
[03/04 11:17:34] epoch:[ 18/30 ] train step:200  loss: 0.82813 lr: 0.000100 batch_cost: 0.35133 sec, reader_cost: 0.00010 sec, ips: 45.54122 instance/sec.
[03/04 11:17:37] epoch:[ 18/30 ] train step:210  loss: 0.89693 lr: 0.000100 batch_cost: 0.35421 sec, reader_cost: 0.00011 sec, ips: 45.17141 instance/sec.
[03/04 11:17:41] epoch:[ 18/30 ] train step:220  loss: 0.91154 lr: 0.000100 batch_cost: 0.35275 sec, reader_cost: 0.00010 sec, ips: 45.35753 instance/sec.
[03/04 11:17:45] epoch:[ 18/30 ] train step:230  loss: 0.75643 lr: 0.000100 batch_cost: 0.35339 sec, reader_cost: 0.00011 sec, ips: 45.27625 instance/sec.
[03/04 11:17:48] epoch:[ 18/30 ] train step:240  loss: 0.63327 lr: 0.000100 batch_cost: 0.35331 sec, reader_cost: 0.00013 sec, ips: 45.28600 instance/sec.
[03/04 11:17:52] epoch:[ 18/30 ] train step:250  loss: 0.78525 lr: 0.000100 batch_cost: 0.35303 sec, reader_cost: 0.00012 sec, ips: 45.32166 instance/sec.
[03/04 11:17:55] epoch:[ 18/30 ] train step:260  loss: 0.89961 lr: 0.000100 batch_cost: 0.35429 sec, reader_cost: 0.00011 sec, ips: 45.16053 instance/sec.
[03/04 11:17:59] epoch:[ 18/30 ] train step:270  loss: 0.86288 lr: 0.000100 batch_cost: 0.35388 sec, reader_cost: 0.00012 sec, ips: 45.21350 instance/sec.
[03/04 11:18:02] epoch:[ 18/30 ] train step:280  loss: 0.83217 lr: 0.000100 batch_cost: 0.35305 sec, reader_cost: 0.00012 sec, ips: 45.31985 instance/sec.
[03/04 11:18:06] epoch:[ 18/30 ] train step:290  loss: 0.78158 lr: 0.000100 batch_cost: 0.35375 sec, reader_cost: 0.00010 sec, ips: 45.23029 instance/sec.
[03/04 11:18:09] epoch:[ 18/30 ] train step:300  loss: 0.72073 lr: 0.000100 batch_cost: 0.35711 sec, reader_cost: 0.00237 sec, ips: 44.80421 instance/sec.
[03/04 11:18:13] epoch:[ 18/30 ] train step:310  loss: 0.75302 lr: 0.000100 batch_cost: 0.35503 sec, reader_cost: 0.00012 sec, ips: 45.06673 instance/sec.
[03/04 11:18:16] epoch:[ 18/30 ] train step:320  loss: 0.62862 lr: 0.000100 batch_cost: 0.35372 sec, reader_cost: 0.00013 sec, ips: 45.23346 instance/sec.
[03/04 11:18:20] epoch:[ 18/30 ] train step:330  loss: 0.84860 lr: 0.000100 batch_cost: 0.35805 sec, reader_cost: 0.00244 sec, ips: 44.68633 instance/sec.
[03/04 11:18:24] epoch:[ 18/30 ] train step:340  loss: 0.81362 lr: 0.000100 batch_cost: 0.35562 sec, reader_cost: 0.00019 sec, ips: 44.99146 instance/sec.
[03/04 11:18:27] epoch:[ 18/30 ] train step:350  loss: 0.84483 lr: 0.000100 batch_cost: 0.35644 sec, reader_cost: 0.00014 sec, ips: 44.88803 instance/sec.
[03/04 11:18:31] epoch:[ 18/30 ] train step:360  loss: 1.05228 lr: 0.000100 batch_cost: 0.35560 sec, reader_cost: 0.00015 sec, ips: 44.99496 instance/sec.
[03/04 11:18:34] epoch:[ 18/30 ] train step:370  loss: 0.81679 lr: 0.000100 batch_cost: 0.35465 sec, reader_cost: 0.00015 sec, ips: 45.11493 instance/sec.
[03/04 11:18:38] epoch:[ 18/30 ] train step:380  loss: 0.78794 lr: 0.000100 batch_cost: 0.35374 sec, reader_cost: 0.00044 sec, ips: 45.23139 instance/sec.
[03/04 11:18:41] epoch:[ 18/30 ] train step:390  loss: 0.68466 lr: 0.000100 batch_cost: 0.35670 sec, reader_cost: 0.00011 sec, ips: 44.85614 instance/sec.
[03/04 11:18:45] epoch:[ 18/30 ] train step:400  loss: 0.70093 lr: 0.000100 batch_cost: 0.35385 sec, reader_cost: 0.00014 sec, ips: 45.21658 instance/sec.
[03/04 11:18:48] epoch:[ 18/30 ] train step:410  loss: 0.81778 lr: 0.000100 batch_cost: 0.35664 sec, reader_cost: 0.00236 sec, ips: 44.86342 instance/sec.
[03/04 11:18:52] epoch:[ 18/30 ] train step:420  loss: 0.73132 lr: 0.000100 batch_cost: 0.35616 sec, reader_cost: 0.00237 sec, ips: 44.92304 instance/sec.
[03/04 11:18:56] epoch:[ 18/30 ] train step:430  loss: 1.05098 lr: 0.000100 batch_cost: 0.35427 sec, reader_cost: 0.00254 sec, ips: 45.16275 instance/sec.
[03/04 11:18:59] epoch:[ 18/30 ] train step:440  loss: 0.76186 lr: 0.000100 batch_cost: 0.36083 sec, reader_cost: 0.00265 sec, ips: 44.34162 instance/sec.
[03/04 11:19:03] epoch:[ 18/30 ] train step:450  loss: 0.56170 lr: 0.000100 batch_cost: 0.35521 sec, reader_cost: 0.00011 sec, ips: 45.04401 instance/sec.
[03/04 11:19:06] epoch:[ 18/30 ] train step:460  loss: 0.75147 lr: 0.000100 batch_cost: 0.35486 sec, reader_cost: 0.00236 sec, ips: 45.08862 instance/sec.
[03/04 11:19:10] epoch:[ 18/30 ] train step:470  loss: 0.69587 lr: 0.000100 batch_cost: 0.35558 sec, reader_cost: 0.00244 sec, ips: 44.99689 instance/sec.
[03/04 11:19:13] epoch:[ 18/30 ] train step:480  loss: 0.67764 lr: 0.000100 batch_cost: 0.35352 sec, reader_cost: 0.00013 sec, ips: 45.25958 instance/sec.
[03/04 11:19:17] epoch:[ 18/30 ] train step:490  loss: 0.67959 lr: 0.000100 batch_cost: 0.35329 sec, reader_cost: 0.00042 sec, ips: 45.28884 instance/sec.
[03/04 11:19:20] epoch:[ 18/30 ] train step:500  loss: 0.78225 lr: 0.000100 batch_cost: 0.35657 sec, reader_cost: 0.00256 sec, ips: 44.87224 instance/sec.
[03/04 11:19:24] epoch:[ 18/30 ] train step:510  loss: 0.79382 lr: 0.000100 batch_cost: 0.35725 sec, reader_cost: 0.00230 sec, ips: 44.78594 instance/sec.
[03/04 11:19:27] epoch:[ 18/30 ] train step:520  loss: 0.74275 lr: 0.000100 batch_cost: 0.35607 sec, reader_cost: 0.00256 sec, ips: 44.93498 instance/sec.
[03/04 11:19:31] epoch:[ 18/30 ] train step:530  loss: 0.70130 lr: 0.000100 batch_cost: 0.35359 sec, reader_cost: 0.00011 sec, ips: 45.24987 instance/sec.
[03/04 11:19:35] epoch:[ 18/30 ] train step:540  loss: 0.72721 lr: 0.000100 batch_cost: 0.35394 sec, reader_cost: 0.00010 sec, ips: 45.20522 instance/sec.
[03/04 11:19:38] epoch:[ 18/30 ] train step:550  loss: 0.81384 lr: 0.000100 batch_cost: 0.35495 sec, reader_cost: 0.00255 sec, ips: 45.07647 instance/sec.
[03/04 11:19:42] epoch:[ 18/30 ] train step:560  loss: 0.74701 lr: 0.000100 batch_cost: 0.35658 sec, reader_cost: 0.00015 sec, ips: 44.87095 instance/sec.
[03/04 11:19:45] epoch:[ 18/30 ] train step:570  loss: 0.90364 lr: 0.000100 batch_cost: 0.35254 sec, reader_cost: 0.00015 sec, ips: 45.38437 instance/sec.
[03/04 11:19:49] epoch:[ 18/30 ] train step:580  loss: 0.68768 lr: 0.000100 batch_cost: 0.35972 sec, reader_cost: 0.00246 sec, ips: 44.47904 instance/sec.
[03/04 11:19:52] epoch:[ 18/30 ] train step:590  loss: 0.73442 lr: 0.000100 batch_cost: 0.35578 sec, reader_cost: 0.00245 sec, ips: 44.97205 instance/sec.
[03/04 11:19:56] epoch:[ 18/30 ] train step:600  loss: 0.86796 lr: 0.000100 batch_cost: 0.35668 sec, reader_cost: 0.00252 sec, ips: 44.85872 instance/sec.
[03/04 11:19:59] epoch:[ 18/30 ] train step:610  loss: 0.72142 lr: 0.000100 batch_cost: 0.35422 sec, reader_cost: 0.00014 sec, ips: 45.17023 instance/sec.
[03/04 11:20:03] epoch:[ 18/30 ] train step:620  loss: 0.72686 lr: 0.000100 batch_cost: 0.35513 sec, reader_cost: 0.00262 sec, ips: 45.05417 instance/sec.
[03/04 11:20:07] epoch:[ 18/30 ] train step:630  loss: 0.68009 lr: 0.000100 batch_cost: 0.35350 sec, reader_cost: 0.00237 sec, ips: 45.26177 instance/sec.
[03/04 11:20:10] epoch:[ 18/30 ] train step:640  loss: 0.53760 lr: 0.000100 batch_cost: 0.35789 sec, reader_cost: 0.00275 sec, ips: 44.70631 instance/sec.
[03/04 11:20:14] epoch:[ 18/30 ] train step:650  loss: 0.79453 lr: 0.000100 batch_cost: 0.35511 sec, reader_cost: 0.00232 sec, ips: 45.05665 instance/sec.
[03/04 11:20:17] epoch:[ 18/30 ] train step:660  loss: 0.69238 lr: 0.000100 batch_cost: 0.36078 sec, reader_cost: 0.00243 sec, ips: 44.34809 instance/sec.
[03/04 11:20:21] epoch:[ 18/30 ] train step:670  loss: 0.70088 lr: 0.000100 batch_cost: 0.35504 sec, reader_cost: 0.00246 sec, ips: 45.06482 instance/sec.
[03/04 11:20:24] epoch:[ 18/30 ] train step:680  loss: 1.19563 lr: 0.000100 batch_cost: 0.35349 sec, reader_cost: 0.00017 sec, ips: 45.26348 instance/sec.
[03/04 11:20:28] epoch:[ 18/30 ] train step:690  loss: 0.96420 lr: 0.000100 batch_cost: 0.35492 sec, reader_cost: 0.00013 sec, ips: 45.08111 instance/sec.
[03/04 11:20:31] epoch:[ 18/30 ] train step:700  loss: 0.76642 lr: 0.000100 batch_cost: 0.35425 sec, reader_cost: 0.00255 sec, ips: 45.16545 instance/sec.
[03/04 11:20:35] epoch:[ 18/30 ] train step:710  loss: 0.95683 lr: 0.000100 batch_cost: 0.35868 sec, reader_cost: 0.00267 sec, ips: 44.60792 instance/sec.
[03/04 11:20:38] epoch:[ 18/30 ] train step:720  loss: 0.69551 lr: 0.000100 batch_cost: 0.35395 sec, reader_cost: 0.00264 sec, ips: 45.20430 instance/sec.
[03/04 11:20:42] epoch:[ 18/30 ] train step:730  loss: 0.76765 lr: 0.000100 batch_cost: 0.35559 sec, reader_cost: 0.00011 sec, ips: 44.99521 instance/sec.
[03/04 11:20:46] epoch:[ 18/30 ] train step:740  loss: 0.73922 lr: 0.000100 batch_cost: 0.34980 sec, reader_cost: 0.00023 sec, ips: 45.74038 instance/sec.
[03/04 11:20:49] epoch:[ 18/30 ] train step:750  loss: 0.71793 lr: 0.000100 batch_cost: 0.35668 sec, reader_cost: 0.00251 sec, ips: 44.85761 instance/sec.
[03/04 11:20:53] epoch:[ 18/30 ] train step:760  loss: 0.88486 lr: 0.000100 batch_cost: 0.35332 sec, reader_cost: 0.00273 sec, ips: 45.28483 instance/sec.
[03/04 11:20:56] epoch:[ 18/30 ] train step:770  loss: 0.62695 lr: 0.000100 batch_cost: 0.35783 sec, reader_cost: 0.00016 sec, ips: 44.71453 instance/sec.
[03/04 11:21:00] epoch:[ 18/30 ] train step:780  loss: 0.64699 lr: 0.000100 batch_cost: 0.35298 sec, reader_cost: 0.00006 sec, ips: 45.32787 instance/sec.
[03/04 11:21:02] END epoch:18  train loss_avg: 0.80814  avg_batch_cost: 0.35259 sec, avg_reader_cost: 0.00008 sec, batch_cost_sum: 280.06951 sec, avg_ips: 44.96027 instance/sec.
[03/04 11:21:03] epoch:[ 19/30 ] train step:0    loss: 0.86439 lr: 0.000100 batch_cost: 1.13714 sec, reader_cost: 0.76828 sec, ips: 14.07033 instance/sec.
[03/04 11:21:07] epoch:[ 19/30 ] train step:10   loss: 0.71452 lr: 0.000100 batch_cost: 0.35647 sec, reader_cost: 0.00145 sec, ips: 44.88512 instance/sec.
[03/04 11:21:10] epoch:[ 19/30 ] train step:20   loss: 1.14057 lr: 0.000100 batch_cost: 0.35610 sec, reader_cost: 0.00212 sec, ips: 44.93158 instance/sec.
[03/04 11:21:14] epoch:[ 19/30 ] train step:30   loss: 0.79770 lr: 0.000100 batch_cost: 0.35771 sec, reader_cost: 0.00211 sec, ips: 44.72907 instance/sec.
[03/04 11:21:18] epoch:[ 19/30 ] train step:40   loss: 0.65140 lr: 0.000100 batch_cost: 0.35625 sec, reader_cost: 0.00210 sec, ips: 44.91179 instance/sec.
[03/04 11:21:21] epoch:[ 19/30 ] train step:50   loss: 0.71357 lr: 0.000100 batch_cost: 0.35842 sec, reader_cost: 0.00258 sec, ips: 44.64056 instance/sec.
[03/04 11:21:25] epoch:[ 19/30 ] train step:60   loss: 0.69566 lr: 0.000100 batch_cost: 0.35280 sec, reader_cost: 0.00012 sec, ips: 45.35124 instance/sec.
[03/04 11:21:28] epoch:[ 19/30 ] train step:70   loss: 0.88997 lr: 0.000100 batch_cost: 0.35879 sec, reader_cost: 0.00211 sec, ips: 44.59396 instance/sec.
[03/04 11:21:32] epoch:[ 19/30 ] train step:80   loss: 0.92180 lr: 0.000100 batch_cost: 0.35794 sec, reader_cost: 0.00219 sec, ips: 44.69964 instance/sec.
[03/04 11:21:35] epoch:[ 19/30 ] train step:90   loss: 0.72968 lr: 0.000100 batch_cost: 0.35461 sec, reader_cost: 0.00025 sec, ips: 45.12000 instance/sec.
[03/04 11:21:39] epoch:[ 19/30 ] train step:100  loss: 1.26937 lr: 0.000100 batch_cost: 0.35679 sec, reader_cost: 0.00235 sec, ips: 44.84478 instance/sec.
[03/04 11:21:43] epoch:[ 19/30 ] train step:110  loss: 0.84266 lr: 0.000100 batch_cost: 0.35572 sec, reader_cost: 0.00266 sec, ips: 44.97931 instance/sec.
[03/04 11:21:46] epoch:[ 19/30 ] train step:120  loss: 0.80394 lr: 0.000100 batch_cost: 0.35609 sec, reader_cost: 0.00210 sec, ips: 44.93209 instance/sec.
[03/04 11:21:50] epoch:[ 19/30 ] train step:130  loss: 0.87654 lr: 0.000100 batch_cost: 0.35868 sec, reader_cost: 0.00256 sec, ips: 44.60753 instance/sec.
[03/04 11:21:53] epoch:[ 19/30 ] train step:140  loss: 0.90555 lr: 0.000100 batch_cost: 0.35715 sec, reader_cost: 0.00014 sec, ips: 44.79963 instance/sec.
[03/04 11:21:57] epoch:[ 19/30 ] train step:150  loss: 0.82774 lr: 0.000100 batch_cost: 0.35546 sec, reader_cost: 0.00208 sec, ips: 45.01202 instance/sec.
[03/04 11:22:00] epoch:[ 19/30 ] train step:160  loss: 0.86424 lr: 0.000100 batch_cost: 0.35909 sec, reader_cost: 0.00234 sec, ips: 44.55768 instance/sec.
[03/04 11:22:04] epoch:[ 19/30 ] train step:170  loss: 0.74110 lr: 0.000100 batch_cost: 0.35480 sec, reader_cost: 0.00231 sec, ips: 45.09589 instance/sec.
[03/04 11:22:07] epoch:[ 19/30 ] train step:180  loss: 0.76465 lr: 0.000100 batch_cost: 0.35578 sec, reader_cost: 0.00221 sec, ips: 44.97190 instance/sec.
[03/04 11:22:11] epoch:[ 19/30 ] train step:190  loss: 0.75998 lr: 0.000100 batch_cost: 0.35610 sec, reader_cost: 0.00206 sec, ips: 44.93113 instance/sec.
[03/04 11:22:15] epoch:[ 19/30 ] train step:200  loss: 1.04345 lr: 0.000100 batch_cost: 0.35659 sec, reader_cost: 0.00219 sec, ips: 44.86921 instance/sec.
[03/04 11:22:18] epoch:[ 19/30 ] train step:210  loss: 0.70335 lr: 0.000100 batch_cost: 0.35839 sec, reader_cost: 0.00258 sec, ips: 44.64454 instance/sec.
[03/04 11:22:22] epoch:[ 19/30 ] train step:220  loss: 0.70459 lr: 0.000100 batch_cost: 0.35382 sec, reader_cost: 0.00020 sec, ips: 45.22014 instance/sec.
[03/04 11:22:25] epoch:[ 19/30 ] train step:230  loss: 0.67407 lr: 0.000100 batch_cost: 0.35803 sec, reader_cost: 0.00014 sec, ips: 44.68898 instance/sec.
[03/04 11:22:29] epoch:[ 19/30 ] train step:240  loss: 0.85698 lr: 0.000100 batch_cost: 0.35572 sec, reader_cost: 0.00237 sec, ips: 44.97982 instance/sec.
[03/04 11:22:32] epoch:[ 19/30 ] train step:250  loss: 0.80010 lr: 0.000100 batch_cost: 0.35777 sec, reader_cost: 0.00233 sec, ips: 44.72091 instance/sec.
[03/04 11:22:36] epoch:[ 19/30 ] train step:260  loss: 0.65799 lr: 0.000100 batch_cost: 0.35797 sec, reader_cost: 0.00240 sec, ips: 44.69666 instance/sec.
[03/04 11:22:40] epoch:[ 19/30 ] train step:270  loss: 0.96639 lr: 0.000100 batch_cost: 0.35525 sec, reader_cost: 0.00230 sec, ips: 45.03875 instance/sec.
[03/04 11:22:43] epoch:[ 19/30 ] train step:280  loss: 0.73738 lr: 0.000100 batch_cost: 0.35824 sec, reader_cost: 0.00233 sec, ips: 44.66239 instance/sec.
[03/04 11:22:47] epoch:[ 19/30 ] train step:290  loss: 0.87661 lr: 0.000100 batch_cost: 0.35470 sec, reader_cost: 0.00227 sec, ips: 45.10802 instance/sec.
[03/04 11:22:50] epoch:[ 19/30 ] train step:300  loss: 0.90092 lr: 0.000100 batch_cost: 0.35679 sec, reader_cost: 0.00030 sec, ips: 44.84430 instance/sec.
[03/04 11:22:54] epoch:[ 19/30 ] train step:310  loss: 0.64116 lr: 0.000100 batch_cost: 0.35631 sec, reader_cost: 0.00224 sec, ips: 44.90461 instance/sec.
[03/04 11:22:57] epoch:[ 19/30 ] train step:320  loss: 0.84254 lr: 0.000100 batch_cost: 0.35625 sec, reader_cost: 0.00230 sec, ips: 44.91246 instance/sec.
[03/04 11:23:01] epoch:[ 19/30 ] train step:330  loss: 0.81177 lr: 0.000100 batch_cost: 0.35702 sec, reader_cost: 0.00266 sec, ips: 44.81522 instance/sec.
[03/04 11:23:04] epoch:[ 19/30 ] train step:340  loss: 0.71573 lr: 0.000100 batch_cost: 0.35626 sec, reader_cost: 0.00235 sec, ips: 44.91077 instance/sec.
[03/04 11:23:08] epoch:[ 19/30 ] train step:350  loss: 0.81273 lr: 0.000100 batch_cost: 0.35839 sec, reader_cost: 0.00212 sec, ips: 44.64394 instance/sec.
[03/04 11:23:12] epoch:[ 19/30 ] train step:360  loss: 0.64095 lr: 0.000100 batch_cost: 0.35563 sec, reader_cost: 0.00228 sec, ips: 44.99017 instance/sec.
[03/04 11:23:15] epoch:[ 19/30 ] train step:370  loss: 0.75538 lr: 0.000100 batch_cost: 0.35781 sec, reader_cost: 0.00016 sec, ips: 44.71626 instance/sec.
[03/04 11:23:19] epoch:[ 19/30 ] train step:380  loss: 0.69424 lr: 0.000100 batch_cost: 0.35651 sec, reader_cost: 0.00217 sec, ips: 44.87903 instance/sec.
[03/04 11:23:22] epoch:[ 19/30 ] train step:390  loss: 0.84772 lr: 0.000100 batch_cost: 0.35525 sec, reader_cost: 0.00222 sec, ips: 45.03851 instance/sec.
[03/04 11:23:26] epoch:[ 19/30 ] train step:400  loss: 0.72393 lr: 0.000100 batch_cost: 0.35544 sec, reader_cost: 0.00019 sec, ips: 45.01494 instance/sec.
[03/04 11:23:29] epoch:[ 19/30 ] train step:410  loss: 0.72421 lr: 0.000100 batch_cost: 0.35658 sec, reader_cost: 0.00239 sec, ips: 44.87017 instance/sec.
[03/04 11:23:33] epoch:[ 19/30 ] train step:420  loss: 0.75758 lr: 0.000100 batch_cost: 0.35628 sec, reader_cost: 0.00015 sec, ips: 44.90888 instance/sec.
[03/04 11:23:37] epoch:[ 19/30 ] train step:430  loss: 0.74141 lr: 0.000100 batch_cost: 0.35556 sec, reader_cost: 0.00015 sec, ips: 44.99898 instance/sec.
[03/04 11:23:40] epoch:[ 19/30 ] train step:440  loss: 0.99430 lr: 0.000100 batch_cost: 0.35725 sec, reader_cost: 0.00226 sec, ips: 44.78606 instance/sec.
[03/04 11:23:44] epoch:[ 19/30 ] train step:450  loss: 0.75379 lr: 0.000100 batch_cost: 0.35457 sec, reader_cost: 0.00015 sec, ips: 45.12464 instance/sec.
[03/04 11:23:47] epoch:[ 19/30 ] train step:460  loss: 0.70432 lr: 0.000100 batch_cost: 0.35762 sec, reader_cost: 0.00238 sec, ips: 44.74038 instance/sec.
[03/04 11:23:51] epoch:[ 19/30 ] train step:470  loss: 0.81035 lr: 0.000100 batch_cost: 0.35591 sec, reader_cost: 0.00234 sec, ips: 44.95506 instance/sec.
[03/04 11:23:54] epoch:[ 19/30 ] train step:480  loss: 0.81763 lr: 0.000100 batch_cost: 0.35325 sec, reader_cost: 0.00042 sec, ips: 45.29394 instance/sec.
[03/04 11:23:58] epoch:[ 19/30 ] train step:490  loss: 0.84521 lr: 0.000100 batch_cost: 0.35376 sec, reader_cost: 0.00010 sec, ips: 45.22865 instance/sec.
[03/04 11:24:02] epoch:[ 19/30 ] train step:500  loss: 1.24223 lr: 0.000100 batch_cost: 0.35581 sec, reader_cost: 0.00018 sec, ips: 44.96744 instance/sec.
[03/04 11:24:05] epoch:[ 19/30 ] train step:510  loss: 0.77642 lr: 0.000100 batch_cost: 0.35881 sec, reader_cost: 0.00233 sec, ips: 44.59191 instance/sec.
[03/04 11:24:09] epoch:[ 19/30 ] train step:520  loss: 0.76051 lr: 0.000100 batch_cost: 0.35501 sec, reader_cost: 0.00237 sec, ips: 45.06927 instance/sec.
[03/04 11:24:12] epoch:[ 19/30 ] train step:530  loss: 0.78428 lr: 0.000100 batch_cost: 0.35778 sec, reader_cost: 0.00228 sec, ips: 44.71977 instance/sec.
[03/04 11:24:16] epoch:[ 19/30 ] train step:540  loss: 0.96873 lr: 0.000100 batch_cost: 0.35685 sec, reader_cost: 0.00238 sec, ips: 44.83738 instance/sec.
[03/04 11:24:19] epoch:[ 19/30 ] train step:550  loss: 0.77692 lr: 0.000100 batch_cost: 0.35656 sec, reader_cost: 0.00238 sec, ips: 44.87311 instance/sec.
[03/04 11:24:23] epoch:[ 19/30 ] train step:560  loss: 0.81550 lr: 0.000100 batch_cost: 0.35658 sec, reader_cost: 0.00052 sec, ips: 44.87125 instance/sec.
[03/04 11:24:26] epoch:[ 19/30 ] train step:570  loss: 0.75136 lr: 0.000100 batch_cost: 0.37170 sec, reader_cost: 0.00251 sec, ips: 43.04543 instance/sec.
[03/04 11:24:30] epoch:[ 19/30 ] train step:580  loss: 0.66006 lr: 0.000100 batch_cost: 0.36097 sec, reader_cost: 0.00252 sec, ips: 44.32527 instance/sec.
[03/04 11:24:34] epoch:[ 19/30 ] train step:590  loss: 0.84277 lr: 0.000100 batch_cost: 0.35839 sec, reader_cost: 0.00239 sec, ips: 44.64469 instance/sec.
[03/04 11:24:37] epoch:[ 19/30 ] train step:600  loss: 0.68949 lr: 0.000100 batch_cost: 0.35698 sec, reader_cost: 0.00042 sec, ips: 44.82088 instance/sec.
[03/04 11:24:41] epoch:[ 19/30 ] train step:610  loss: 0.85994 lr: 0.000100 batch_cost: 0.35858 sec, reader_cost: 0.00228 sec, ips: 44.62085 instance/sec.
[03/04 11:24:44] epoch:[ 19/30 ] train step:620  loss: 0.81746 lr: 0.000100 batch_cost: 0.35725 sec, reader_cost: 0.00220 sec, ips: 44.78711 instance/sec.
[03/04 11:24:48] epoch:[ 19/30 ] train step:630  loss: 0.74618 lr: 0.000100 batch_cost: 0.36008 sec, reader_cost: 0.00271 sec, ips: 44.43398 instance/sec.
[03/04 11:24:52] epoch:[ 19/30 ] train step:640  loss: 0.74946 lr: 0.000100 batch_cost: 0.36053 sec, reader_cost: 0.00224 sec, ips: 44.37921 instance/sec.
[03/04 11:24:55] epoch:[ 19/30 ] train step:650  loss: 0.67362 lr: 0.000100 batch_cost: 0.35707 sec, reader_cost: 0.00228 sec, ips: 44.80912 instance/sec.
[03/04 11:24:59] epoch:[ 19/30 ] train step:660  loss: 0.82668 lr: 0.000100 batch_cost: 0.35852 sec, reader_cost: 0.00233 sec, ips: 44.62800 instance/sec.
[03/04 11:25:02] epoch:[ 19/30 ] train step:670  loss: 0.67154 lr: 0.000100 batch_cost: 0.35951 sec, reader_cost: 0.00221 sec, ips: 44.50562 instance/sec.
[03/04 11:25:06] epoch:[ 19/30 ] train step:680  loss: 0.60077 lr: 0.000100 batch_cost: 0.35770 sec, reader_cost: 0.00016 sec, ips: 44.72988 instance/sec.
[03/04 11:25:10] epoch:[ 19/30 ] train step:690  loss: 0.81282 lr: 0.000100 batch_cost: 0.35768 sec, reader_cost: 0.00232 sec, ips: 44.73259 instance/sec.
[03/04 11:25:13] epoch:[ 19/30 ] train step:700  loss: 1.00015 lr: 0.000100 batch_cost: 0.35785 sec, reader_cost: 0.00220 sec, ips: 44.71110 instance/sec.
[03/04 11:25:17] epoch:[ 19/30 ] train step:710  loss: 0.70319 lr: 0.000100 batch_cost: 0.35596 sec, reader_cost: 0.00231 sec, ips: 44.94858 instance/sec.
[03/04 11:25:20] epoch:[ 19/30 ] train step:720  loss: 1.01653 lr: 0.000100 batch_cost: 0.35641 sec, reader_cost: 0.00014 sec, ips: 44.89188 instance/sec.
[03/04 11:25:24] epoch:[ 19/30 ] train step:730  loss: 0.74672 lr: 0.000100 batch_cost: 0.35890 sec, reader_cost: 0.00241 sec, ips: 44.58080 instance/sec.
[03/04 11:25:27] epoch:[ 19/30 ] train step:740  loss: 0.78074 lr: 0.000100 batch_cost: 0.35828 sec, reader_cost: 0.00251 sec, ips: 44.65725 instance/sec.
[03/04 11:25:31] epoch:[ 19/30 ] train step:750  loss: 0.71201 lr: 0.000100 batch_cost: 0.35898 sec, reader_cost: 0.00046 sec, ips: 44.57115 instance/sec.
[03/04 11:25:35] epoch:[ 19/30 ] train step:760  loss: 0.76734 lr: 0.000100 batch_cost: 0.35903 sec, reader_cost: 0.00252 sec, ips: 44.56402 instance/sec.
[03/04 11:25:38] epoch:[ 19/30 ] train step:770  loss: 0.86220 lr: 0.000100 batch_cost: 0.35663 sec, reader_cost: 0.00044 sec, ips: 44.86456 instance/sec.
[03/04 11:25:42] epoch:[ 19/30 ] train step:780  loss: 0.75253 lr: 0.000100 batch_cost: 0.35253 sec, reader_cost: 0.00007 sec, ips: 45.38569 instance/sec.
[03/04 11:25:44] END epoch:19  train loss_avg: 0.80330  avg_batch_cost: 0.35657 sec, avg_reader_cost: 0.00006 sec, batch_cost_sum: 281.73054 sec, avg_ips: 44.69519 instance/sec.
[03/04 11:25:45] epoch:[ 20/30 ] train step:0    loss: 0.69494 lr: 0.000100 batch_cost: 1.12600 sec, reader_cost: 0.75880 sec, ips: 14.20957 instance/sec.
[03/04 11:25:49] epoch:[ 20/30 ] train step:10   loss: 0.69617 lr: 0.000100 batch_cost: 0.35836 sec, reader_cost: 0.00219 sec, ips: 44.64780 instance/sec.
[03/04 11:25:53] epoch:[ 20/30 ] train step:20   loss: 0.54668 lr: 0.000100 batch_cost: 0.35757 sec, reader_cost: 0.00014 sec, ips: 44.74634 instance/sec.
[03/04 11:25:56] epoch:[ 20/30 ] train step:30   loss: 0.88134 lr: 0.000100 batch_cost: 0.36108 sec, reader_cost: 0.00225 sec, ips: 44.31134 instance/sec.
[03/04 11:26:00] epoch:[ 20/30 ] train step:40   loss: 0.90179 lr: 0.000100 batch_cost: 0.35851 sec, reader_cost: 0.00211 sec, ips: 44.62937 instance/sec.
[03/04 11:26:03] epoch:[ 20/30 ] train step:50   loss: 0.80818 lr: 0.000100 batch_cost: 0.35908 sec, reader_cost: 0.00213 sec, ips: 44.55825 instance/sec.
[03/04 11:26:07] epoch:[ 20/30 ] train step:60   loss: 0.78901 lr: 0.000100 batch_cost: 0.35933 sec, reader_cost: 0.00230 sec, ips: 44.52685 instance/sec.
[03/04 11:26:10] epoch:[ 20/30 ] train step:70   loss: 1.10393 lr: 0.000100 batch_cost: 0.35820 sec, reader_cost: 0.00275 sec, ips: 44.66718 instance/sec.
[03/04 11:26:14] epoch:[ 20/30 ] train step:80   loss: 0.75072 lr: 0.000100 batch_cost: 0.36059 sec, reader_cost: 0.00227 sec, ips: 44.37120 instance/sec.
[03/04 11:26:18] epoch:[ 20/30 ] train step:90   loss: 0.76789 lr: 0.000100 batch_cost: 0.35927 sec, reader_cost: 0.00223 sec, ips: 44.53515 instance/sec.
[03/04 11:26:21] epoch:[ 20/30 ] train step:100  loss: 0.72311 lr: 0.000100 batch_cost: 0.35879 sec, reader_cost: 0.00239 sec, ips: 44.59372 instance/sec.
[03/04 11:26:25] epoch:[ 20/30 ] train step:110  loss: 0.87527 lr: 0.000100 batch_cost: 0.35727 sec, reader_cost: 0.00218 sec, ips: 44.78358 instance/sec.
[03/04 11:26:28] epoch:[ 20/30 ] train step:120  loss: 0.93608 lr: 0.000100 batch_cost: 0.35855 sec, reader_cost: 0.00229 sec, ips: 44.62420 instance/sec.
[03/04 11:26:32] epoch:[ 20/30 ] train step:130  loss: 0.78356 lr: 0.000100 batch_cost: 0.35947 sec, reader_cost: 0.00271 sec, ips: 44.50981 instance/sec.
[03/04 11:26:36] epoch:[ 20/30 ] train step:140  loss: 0.72025 lr: 0.000100 batch_cost: 0.36040 sec, reader_cost: 0.00216 sec, ips: 44.39474 instance/sec.
[03/04 11:26:39] epoch:[ 20/30 ] train step:150  loss: 0.99083 lr: 0.000100 batch_cost: 0.35993 sec, reader_cost: 0.00223 sec, ips: 44.45335 instance/sec.
[03/04 11:26:43] epoch:[ 20/30 ] train step:160  loss: 0.74268 lr: 0.000100 batch_cost: 0.36034 sec, reader_cost: 0.00222 sec, ips: 44.40264 instance/sec.
[03/04 11:26:46] epoch:[ 20/30 ] train step:170  loss: 0.77129 lr: 0.000100 batch_cost: 0.35713 sec, reader_cost: 0.00044 sec, ips: 44.80185 instance/sec.
[03/04 11:26:50] epoch:[ 20/30 ] train step:180  loss: 0.65764 lr: 0.000100 batch_cost: 0.35858 sec, reader_cost: 0.00246 sec, ips: 44.62085 instance/sec.
[03/04 11:26:53] epoch:[ 20/30 ] train step:190  loss: 0.85858 lr: 0.000100 batch_cost: 0.35867 sec, reader_cost: 0.00225 sec, ips: 44.60928 instance/sec.
[03/04 11:26:57] epoch:[ 20/30 ] train step:200  loss: 1.02511 lr: 0.000100 batch_cost: 0.35969 sec, reader_cost: 0.00228 sec, ips: 44.48276 instance/sec.
[03/04 11:27:01] epoch:[ 20/30 ] train step:210  loss: 0.91270 lr: 0.000100 batch_cost: 0.35669 sec, reader_cost: 0.00229 sec, ips: 44.85698 instance/sec.
[03/04 11:27:04] epoch:[ 20/30 ] train step:220  loss: 0.70008 lr: 0.000100 batch_cost: 0.35817 sec, reader_cost: 0.00241 sec, ips: 44.67146 instance/sec.
[03/04 11:27:08] epoch:[ 20/30 ] train step:230  loss: 0.87117 lr: 0.000100 batch_cost: 0.35929 sec, reader_cost: 0.00246 sec, ips: 44.53181 instance/sec.
[03/04 11:27:11] epoch:[ 20/30 ] train step:240  loss: 0.77783 lr: 0.000100 batch_cost: 0.35970 sec, reader_cost: 0.00225 sec, ips: 44.48099 instance/sec.
[03/04 11:27:15] epoch:[ 20/30 ] train step:250  loss: 0.65833 lr: 0.000100 batch_cost: 0.36087 sec, reader_cost: 0.00217 sec, ips: 44.33696 instance/sec.
[03/04 11:27:19] epoch:[ 20/30 ] train step:260  loss: 0.94971 lr: 0.000100 batch_cost: 0.35842 sec, reader_cost: 0.00235 sec, ips: 44.64032 instance/sec.
[03/04 11:27:22] epoch:[ 20/30 ] train step:270  loss: 0.78313 lr: 0.000100 batch_cost: 0.35929 sec, reader_cost: 0.00230 sec, ips: 44.53270 instance/sec.
[03/04 11:27:26] epoch:[ 20/30 ] train step:280  loss: 0.81205 lr: 0.000100 batch_cost: 0.36094 sec, reader_cost: 0.00227 sec, ips: 44.32896 instance/sec.
[03/04 11:27:29] epoch:[ 20/30 ] train step:290  loss: 0.83053 lr: 0.000100 batch_cost: 0.35724 sec, reader_cost: 0.00221 sec, ips: 44.78755 instance/sec.
[03/04 11:27:33] epoch:[ 20/30 ] train step:300  loss: 0.69863 lr: 0.000100 batch_cost: 0.35898 sec, reader_cost: 0.00236 sec, ips: 44.57020 instance/sec.
[03/04 11:27:37] epoch:[ 20/30 ] train step:310  loss: 0.68615 lr: 0.000100 batch_cost: 0.36001 sec, reader_cost: 0.00224 sec, ips: 44.44322 instance/sec.
[03/04 11:27:40] epoch:[ 20/30 ] train step:320  loss: 0.77545 lr: 0.000100 batch_cost: 0.35750 sec, reader_cost: 0.00217 sec, ips: 44.75491 instance/sec.
[03/04 11:27:44] epoch:[ 20/30 ] train step:330  loss: 0.75963 lr: 0.000100 batch_cost: 0.35569 sec, reader_cost: 0.00012 sec, ips: 44.98266 instance/sec.
[03/04 11:27:47] epoch:[ 20/30 ] train step:340  loss: 0.69224 lr: 0.000100 batch_cost: 0.35923 sec, reader_cost: 0.00218 sec, ips: 44.53923 instance/sec.
[03/04 11:27:51] epoch:[ 20/30 ] train step:350  loss: 0.71941 lr: 0.000100 batch_cost: 0.35811 sec, reader_cost: 0.00056 sec, ips: 44.67842 instance/sec.
[03/04 11:27:54] epoch:[ 20/30 ] train step:360  loss: 0.74671 lr: 0.000100 batch_cost: 0.36092 sec, reader_cost: 0.00239 sec, ips: 44.33075 instance/sec.
[03/04 11:27:58] epoch:[ 20/30 ] train step:370  loss: 0.98910 lr: 0.000100 batch_cost: 0.35844 sec, reader_cost: 0.00229 sec, ips: 44.63753 instance/sec.
[03/04 11:28:02] epoch:[ 20/30 ] train step:380  loss: 0.82415 lr: 0.000100 batch_cost: 0.35865 sec, reader_cost: 0.00234 sec, ips: 44.61136 instance/sec.
[03/04 11:28:05] epoch:[ 20/30 ] train step:390  loss: 0.75879 lr: 0.000100 batch_cost: 0.35902 sec, reader_cost: 0.00016 sec, ips: 44.56627 instance/sec.
[03/04 11:28:09] epoch:[ 20/30 ] train step:400  loss: 0.76829 lr: 0.000100 batch_cost: 0.35779 sec, reader_cost: 0.00235 sec, ips: 44.71852 instance/sec.
[03/04 11:28:12] epoch:[ 20/30 ] train step:410  loss: 1.01573 lr: 0.000100 batch_cost: 0.35813 sec, reader_cost: 0.00223 sec, ips: 44.67625 instance/sec.
[03/04 11:28:16] epoch:[ 20/30 ] train step:420  loss: 0.62785 lr: 0.000100 batch_cost: 0.35938 sec, reader_cost: 0.00234 sec, ips: 44.52153 instance/sec.
[03/04 11:28:20] epoch:[ 20/30 ] train step:430  loss: 0.88061 lr: 0.000100 batch_cost: 0.35652 sec, reader_cost: 0.00044 sec, ips: 44.87825 instance/sec.
[03/04 11:28:23] epoch:[ 20/30 ] train step:440  loss: 0.87763 lr: 0.000100 batch_cost: 0.35812 sec, reader_cost: 0.00229 sec, ips: 44.67783 instance/sec.
[03/04 11:28:27] epoch:[ 20/30 ] train step:450  loss: 0.67388 lr: 0.000100 batch_cost: 0.36045 sec, reader_cost: 0.00230 sec, ips: 44.38869 instance/sec.
[03/04 11:28:30] epoch:[ 20/30 ] train step:460  loss: 0.66090 lr: 0.000100 batch_cost: 0.35892 sec, reader_cost: 0.00219 sec, ips: 44.57831 instance/sec.
[03/04 11:28:34] epoch:[ 20/30 ] train step:470  loss: 0.79457 lr: 0.000100 batch_cost: 0.35704 sec, reader_cost: 0.00232 sec, ips: 44.81303 instance/sec.
[03/04 11:28:38] epoch:[ 20/30 ] train step:480  loss: 0.84558 lr: 0.000100 batch_cost: 0.35593 sec, reader_cost: 0.00232 sec, ips: 44.95220 instance/sec.
[03/04 11:28:41] epoch:[ 20/30 ] train step:490  loss: 0.85735 lr: 0.000100 batch_cost: 0.35743 sec, reader_cost: 0.00219 sec, ips: 44.76458 instance/sec.
[03/04 11:28:45] epoch:[ 20/30 ] train step:500  loss: 0.64562 lr: 0.000100 batch_cost: 0.35671 sec, reader_cost: 0.00014 sec, ips: 44.85380 instance/sec.
[03/04 11:28:48] epoch:[ 20/30 ] train step:510  loss: 0.65404 lr: 0.000100 batch_cost: 0.35694 sec, reader_cost: 0.00240 sec, ips: 44.82507 instance/sec.
[03/04 11:28:52] epoch:[ 20/30 ] train step:520  loss: 0.71372 lr: 0.000100 batch_cost: 0.35764 sec, reader_cost: 0.00264 sec, ips: 44.73790 instance/sec.
[03/04 11:28:55] epoch:[ 20/30 ] train step:530  loss: 0.75359 lr: 0.000100 batch_cost: 0.35781 sec, reader_cost: 0.00230 sec, ips: 44.71662 instance/sec.
[03/04 11:28:59] epoch:[ 20/30 ] train step:540  loss: 0.90597 lr: 0.000100 batch_cost: 0.36322 sec, reader_cost: 0.00256 sec, ips: 44.05087 instance/sec.
[03/04 11:29:03] epoch:[ 20/30 ] train step:550  loss: 0.71451 lr: 0.000100 batch_cost: 0.35906 sec, reader_cost: 0.00249 sec, ips: 44.56126 instance/sec.
[03/04 11:29:06] epoch:[ 20/30 ] train step:560  loss: 0.75372 lr: 0.000100 batch_cost: 0.35961 sec, reader_cost: 0.00232 sec, ips: 44.49296 instance/sec.
[03/04 11:29:10] epoch:[ 20/30 ] train step:570  loss: 0.91362 lr: 0.000100 batch_cost: 0.35683 sec, reader_cost: 0.00016 sec, ips: 44.83929 instance/sec.
[03/04 11:29:13] epoch:[ 20/30 ] train step:580  loss: 0.88391 lr: 0.000100 batch_cost: 0.35890 sec, reader_cost: 0.00236 sec, ips: 44.58071 instance/sec.
[03/04 11:29:17] epoch:[ 20/30 ] train step:590  loss: 0.93097 lr: 0.000100 batch_cost: 0.36015 sec, reader_cost: 0.00209 sec, ips: 44.42636 instance/sec.
[03/04 11:29:20] epoch:[ 20/30 ] train step:600  loss: 0.79048 lr: 0.000100 batch_cost: 0.35959 sec, reader_cost: 0.00242 sec, ips: 44.49476 instance/sec.
[03/04 11:29:24] epoch:[ 20/30 ] train step:610  loss: 1.00306 lr: 0.000100 batch_cost: 0.35491 sec, reader_cost: 0.00022 sec, ips: 45.08171 instance/sec.
[03/04 11:29:28] epoch:[ 20/30 ] train step:620  loss: 0.74496 lr: 0.000100 batch_cost: 0.35277 sec, reader_cost: 0.00014 sec, ips: 45.35569 instance/sec.
[03/04 11:29:31] epoch:[ 20/30 ] train step:630  loss: 0.72922 lr: 0.000100 batch_cost: 0.35488 sec, reader_cost: 0.00232 sec, ips: 45.08541 instance/sec.
[03/04 11:29:35] epoch:[ 20/30 ] train step:640  loss: 0.86047 lr: 0.000100 batch_cost: 0.35813 sec, reader_cost: 0.00225 sec, ips: 44.67631 instance/sec.
[03/04 11:29:38] epoch:[ 20/30 ] train step:650  loss: 0.60341 lr: 0.000100 batch_cost: 0.35597 sec, reader_cost: 0.00010 sec, ips: 44.94771 instance/sec.
[03/04 11:29:42] epoch:[ 20/30 ] train step:660  loss: 1.11418 lr: 0.000100 batch_cost: 0.35588 sec, reader_cost: 0.00239 sec, ips: 44.95849 instance/sec.
[03/04 11:29:45] epoch:[ 20/30 ] train step:670  loss: 0.82755 lr: 0.000100 batch_cost: 0.35764 sec, reader_cost: 0.00043 sec, ips: 44.73733 instance/sec.
[03/04 11:29:49] epoch:[ 20/30 ] train step:680  loss: 0.95931 lr: 0.000100 batch_cost: 0.35422 sec, reader_cost: 0.00017 sec, ips: 45.16995 instance/sec.
[03/04 11:29:53] epoch:[ 20/30 ] train step:690  loss: 1.09347 lr: 0.000100 batch_cost: 0.35405 sec, reader_cost: 0.00248 sec, ips: 45.19164 instance/sec.
[03/04 11:29:56] epoch:[ 20/30 ] train step:700  loss: 0.78841 lr: 0.000100 batch_cost: 0.35782 sec, reader_cost: 0.00236 sec, ips: 44.71495 instance/sec.
[03/04 11:30:00] epoch:[ 20/30 ] train step:710  loss: 0.73394 lr: 0.000100 batch_cost: 0.35548 sec, reader_cost: 0.00042 sec, ips: 45.00954 instance/sec.
[03/04 11:30:03] epoch:[ 20/30 ] train step:720  loss: 0.72917 lr: 0.000100 batch_cost: 0.35657 sec, reader_cost: 0.00243 sec, ips: 44.87242 instance/sec.
[03/04 11:30:07] epoch:[ 20/30 ] train step:730  loss: 0.69984 lr: 0.000100 batch_cost: 0.35629 sec, reader_cost: 0.00230 sec, ips: 44.90717 instance/sec.
[03/04 11:30:10] epoch:[ 20/30 ] train step:740  loss: 0.71171 lr: 0.000100 batch_cost: 0.35750 sec, reader_cost: 0.00240 sec, ips: 44.75544 instance/sec.
[03/04 11:30:14] epoch:[ 20/30 ] train step:750  loss: 0.76572 lr: 0.000100 batch_cost: 0.35546 sec, reader_cost: 0.00231 sec, ips: 45.01241 instance/sec.
[03/04 11:30:18] epoch:[ 20/30 ] train step:760  loss: 0.73699 lr: 0.000100 batch_cost: 0.35621 sec, reader_cost: 0.00231 sec, ips: 44.91793 instance/sec.
[03/04 11:30:21] epoch:[ 20/30 ] train step:770  loss: 0.89387 lr: 0.000100 batch_cost: 0.35620 sec, reader_cost: 0.00221 sec, ips: 44.91805 instance/sec.
[03/04 11:30:25] epoch:[ 20/30 ] train step:780  loss: 0.66310 lr: 0.000100 batch_cost: 0.35090 sec, reader_cost: 0.00006 sec, ips: 45.59658 instance/sec.
[03/04 11:30:27] END epoch:20  train loss_avg: 0.79690  avg_batch_cost: 0.35279 sec, avg_reader_cost: 0.00005 sec, batch_cost_sum: 282.50349 sec, avg_ips: 44.57290 instance/sec.
[03/04 11:30:28] epoch:[ 21/30 ] train step:0    loss: 0.69944 lr: 0.000100 batch_cost: 1.11165 sec, reader_cost: 0.74623 sec, ips: 14.39297 instance/sec.
[03/04 11:30:32] epoch:[ 21/30 ] train step:10   loss: 0.70617 lr: 0.000100 batch_cost: 0.35601 sec, reader_cost: 0.00022 sec, ips: 44.94202 instance/sec.
[03/04 11:30:35] epoch:[ 21/30 ] train step:20   loss: 0.76133 lr: 0.000100 batch_cost: 0.35601 sec, reader_cost: 0.00216 sec, ips: 44.94301 instance/sec.
[03/04 11:30:39] epoch:[ 21/30 ] train step:30   loss: 1.01268 lr: 0.000100 batch_cost: 0.35482 sec, reader_cost: 0.00015 sec, ips: 45.09283 instance/sec.
[03/04 11:30:42] epoch:[ 21/30 ] train step:40   loss: 0.66581 lr: 0.000100 batch_cost: 0.35613 sec, reader_cost: 0.00199 sec, ips: 44.92719 instance/sec.
[03/04 11:30:46] epoch:[ 21/30 ] train step:50   loss: 0.64109 lr: 0.000100 batch_cost: 0.35387 sec, reader_cost: 0.00042 sec, ips: 45.21420 instance/sec.
[03/04 11:30:49] epoch:[ 21/30 ] train step:60   loss: 0.71176 lr: 0.000100 batch_cost: 0.35537 sec, reader_cost: 0.00230 sec, ips: 45.02413 instance/sec.
[03/04 11:30:53] epoch:[ 21/30 ] train step:70   loss: 0.73429 lr: 0.000100 batch_cost: 0.35326 sec, reader_cost: 0.00016 sec, ips: 45.29244 instance/sec.
[03/04 11:30:57] epoch:[ 21/30 ] train step:80   loss: 0.75418 lr: 0.000100 batch_cost: 0.35754 sec, reader_cost: 0.00200 sec, ips: 44.75031 instance/sec.
[03/04 11:31:00] epoch:[ 21/30 ] train step:90   loss: 0.90696 lr: 0.000100 batch_cost: 0.35397 sec, reader_cost: 0.00248 sec, ips: 45.20114 instance/sec.
[03/04 11:31:04] epoch:[ 21/30 ] train step:100  loss: 0.95667 lr: 0.000100 batch_cost: 0.36239 sec, reader_cost: 0.00028 sec, ips: 44.15141 instance/sec.
[03/04 11:31:07] epoch:[ 21/30 ] train step:110  loss: 0.80990 lr: 0.000100 batch_cost: 0.35555 sec, reader_cost: 0.00016 sec, ips: 45.00082 instance/sec.
[03/04 11:31:11] epoch:[ 21/30 ] train step:120  loss: 0.73985 lr: 0.000100 batch_cost: 0.35543 sec, reader_cost: 0.00214 sec, ips: 45.01591 instance/sec.
[03/04 11:31:14] epoch:[ 21/30 ] train step:130  loss: 0.72327 lr: 0.000100 batch_cost: 0.35538 sec, reader_cost: 0.00231 sec, ips: 45.02262 instance/sec.
[03/04 11:31:18] epoch:[ 21/30 ] train step:140  loss: 0.70923 lr: 0.000100 batch_cost: 0.35719 sec, reader_cost: 0.00225 sec, ips: 44.79422 instance/sec.
[03/04 11:31:21] epoch:[ 21/30 ] train step:150  loss: 0.75624 lr: 0.000100 batch_cost: 0.35523 sec, reader_cost: 0.00016 sec, ips: 45.04093 instance/sec.
[03/04 11:31:25] epoch:[ 21/30 ] train step:160  loss: 0.58136 lr: 0.000100 batch_cost: 0.35789 sec, reader_cost: 0.00225 sec, ips: 44.70613 instance/sec.
[03/04 11:31:29] epoch:[ 21/30 ] train step:170  loss: 0.83684 lr: 0.000100 batch_cost: 0.35735 sec, reader_cost: 0.00206 sec, ips: 44.77363 instance/sec.
[03/04 11:31:32] epoch:[ 21/30 ] train step:180  loss: 0.70150 lr: 0.000100 batch_cost: 0.35321 sec, reader_cost: 0.00230 sec, ips: 45.29920 instance/sec.
[03/04 11:31:36] epoch:[ 21/30 ] train step:190  loss: 1.12323 lr: 0.000100 batch_cost: 0.35872 sec, reader_cost: 0.00226 sec, ips: 44.60303 instance/sec.
[03/04 11:31:39] epoch:[ 21/30 ] train step:200  loss: 0.65164 lr: 0.000100 batch_cost: 0.35527 sec, reader_cost: 0.00231 sec, ips: 45.03588 instance/sec.
[03/04 11:31:43] epoch:[ 21/30 ] train step:210  loss: 0.92987 lr: 0.000100 batch_cost: 0.35666 sec, reader_cost: 0.00215 sec, ips: 44.86091 instance/sec.
[03/04 11:31:46] epoch:[ 21/30 ] train step:220  loss: 0.81847 lr: 0.000100 batch_cost: 0.35666 sec, reader_cost: 0.00015 sec, ips: 44.86100 instance/sec.
[03/04 11:31:50] epoch:[ 21/30 ] train step:230  loss: 0.70760 lr: 0.000100 batch_cost: 0.35498 sec, reader_cost: 0.00041 sec, ips: 45.07305 instance/sec.
[03/04 11:31:54] epoch:[ 21/30 ] train step:240  loss: 0.61920 lr: 0.000100 batch_cost: 0.35724 sec, reader_cost: 0.00213 sec, ips: 44.78809 instance/sec.
[03/04 11:31:57] epoch:[ 21/30 ] train step:250  loss: 1.02477 lr: 0.000100 batch_cost: 0.35454 sec, reader_cost: 0.00016 sec, ips: 45.12876 instance/sec.
[03/04 11:32:01] epoch:[ 21/30 ] train step:260  loss: 0.71588 lr: 0.000100 batch_cost: 0.35867 sec, reader_cost: 0.00208 sec, ips: 44.60984 instance/sec.
[03/04 11:32:04] epoch:[ 21/30 ] train step:270  loss: 0.81898 lr: 0.000100 batch_cost: 0.35658 sec, reader_cost: 0.00223 sec, ips: 44.87089 instance/sec.
[03/04 11:32:08] epoch:[ 21/30 ] train step:280  loss: 0.79185 lr: 0.000100 batch_cost: 0.35611 sec, reader_cost: 0.00216 sec, ips: 44.93014 instance/sec.
[03/04 11:32:11] epoch:[ 21/30 ] train step:290  loss: 0.71080 lr: 0.000100 batch_cost: 0.35595 sec, reader_cost: 0.00209 sec, ips: 44.95030 instance/sec.
[03/04 11:32:15] epoch:[ 21/30 ] train step:300  loss: 0.80849 lr: 0.000100 batch_cost: 0.35718 sec, reader_cost: 0.00229 sec, ips: 44.79530 instance/sec.
[03/04 11:32:18] epoch:[ 21/30 ] train step:310  loss: 0.80062 lr: 0.000100 batch_cost: 0.35657 sec, reader_cost: 0.00015 sec, ips: 44.87236 instance/sec.
[03/04 11:32:22] epoch:[ 21/30 ] train step:320  loss: 0.76344 lr: 0.000100 batch_cost: 0.35570 sec, reader_cost: 0.00208 sec, ips: 44.98227 instance/sec.
[03/04 11:32:26] epoch:[ 21/30 ] train step:330  loss: 0.68785 lr: 0.000100 batch_cost: 0.35554 sec, reader_cost: 0.00013 sec, ips: 45.00248 instance/sec.
[03/04 11:32:29] epoch:[ 21/30 ] train step:340  loss: 0.65343 lr: 0.000100 batch_cost: 0.35646 sec, reader_cost: 0.00211 sec, ips: 44.88551 instance/sec.
[03/04 11:32:33] epoch:[ 21/30 ] train step:350  loss: 0.89636 lr: 0.000100 batch_cost: 0.35771 sec, reader_cost: 0.00027 sec, ips: 44.72854 instance/sec.
[03/04 11:32:36] epoch:[ 21/30 ] train step:360  loss: 0.65367 lr: 0.000100 batch_cost: 0.35579 sec, reader_cost: 0.00227 sec, ips: 44.96985 instance/sec.
[03/04 11:32:40] epoch:[ 21/30 ] train step:370  loss: 0.66637 lr: 0.000100 batch_cost: 0.35434 sec, reader_cost: 0.00010 sec, ips: 45.15488 instance/sec.
[03/04 11:32:43] epoch:[ 21/30 ] train step:380  loss: 0.97896 lr: 0.000100 batch_cost: 0.35673 sec, reader_cost: 0.00232 sec, ips: 44.85125 instance/sec.
[03/04 11:32:47] epoch:[ 21/30 ] train step:390  loss: 0.66856 lr: 0.000100 batch_cost: 0.35391 sec, reader_cost: 0.00015 sec, ips: 45.20887 instance/sec.
[03/04 11:32:51] epoch:[ 21/30 ] train step:400  loss: 0.83391 lr: 0.000100 batch_cost: 0.35519 sec, reader_cost: 0.00015 sec, ips: 45.04598 instance/sec.
[03/04 11:32:54] epoch:[ 21/30 ] train step:410  loss: 0.85275 lr: 0.000100 batch_cost: 0.35700 sec, reader_cost: 0.00235 sec, ips: 44.81731 instance/sec.
[03/04 11:32:58] epoch:[ 21/30 ] train step:420  loss: 1.03105 lr: 0.000100 batch_cost: 0.35758 sec, reader_cost: 0.00014 sec, ips: 44.74482 instance/sec.
[03/04 11:33:01] epoch:[ 21/30 ] train step:430  loss: 0.80543 lr: 0.000100 batch_cost: 0.35385 sec, reader_cost: 0.00229 sec, ips: 45.21676 instance/sec.
[03/04 11:33:05] epoch:[ 21/30 ] train step:440  loss: 0.73796 lr: 0.000100 batch_cost: 0.35825 sec, reader_cost: 0.00218 sec, ips: 44.66120 instance/sec.
[03/04 11:33:08] epoch:[ 21/30 ] train step:450  loss: 0.70956 lr: 0.000100 batch_cost: 0.35498 sec, reader_cost: 0.00014 sec, ips: 45.07311 instance/sec.
[03/04 11:33:12] epoch:[ 21/30 ] train step:460  loss: 1.03797 lr: 0.000100 batch_cost: 0.35586 sec, reader_cost: 0.00221 sec, ips: 44.96165 instance/sec.
[03/04 11:33:15] epoch:[ 21/30 ] train step:470  loss: 0.74018 lr: 0.000100 batch_cost: 0.35615 sec, reader_cost: 0.00221 sec, ips: 44.92496 instance/sec.
[03/04 11:33:19] epoch:[ 21/30 ] train step:480  loss: 0.66798 lr: 0.000100 batch_cost: 0.35527 sec, reader_cost: 0.00222 sec, ips: 45.03648 instance/sec.
[03/04 11:33:23] epoch:[ 21/30 ] train step:490  loss: 0.89115 lr: 0.000100 batch_cost: 0.35594 sec, reader_cost: 0.00236 sec, ips: 44.95138 instance/sec.
[03/04 11:33:26] epoch:[ 21/30 ] train step:500  loss: 0.80069 lr: 0.000100 batch_cost: 0.35791 sec, reader_cost: 0.00223 sec, ips: 44.70455 instance/sec.
[03/04 11:33:30] epoch:[ 21/30 ] train step:510  loss: 0.66119 lr: 0.000100 batch_cost: 0.35692 sec, reader_cost: 0.00015 sec, ips: 44.82758 instance/sec.
[03/04 11:33:33] epoch:[ 21/30 ] train step:520  loss: 0.71204 lr: 0.000100 batch_cost: 0.35552 sec, reader_cost: 0.00219 sec, ips: 45.00411 instance/sec.
[03/04 11:33:37] epoch:[ 21/30 ] train step:530  loss: 1.01138 lr: 0.000100 batch_cost: 0.35670 sec, reader_cost: 0.00219 sec, ips: 44.85506 instance/sec.
[03/04 11:33:40] epoch:[ 21/30 ] train step:540  loss: 0.64288 lr: 0.000100 batch_cost: 0.35589 sec, reader_cost: 0.00016 sec, ips: 44.95831 instance/sec.
[03/04 11:33:44] epoch:[ 21/30 ] train step:550  loss: 0.88660 lr: 0.000100 batch_cost: 0.35589 sec, reader_cost: 0.00219 sec, ips: 44.95726 instance/sec.
[03/04 11:33:48] epoch:[ 21/30 ] train step:560  loss: 0.73415 lr: 0.000100 batch_cost: 0.35721 sec, reader_cost: 0.00217 sec, ips: 44.79168 instance/sec.
[03/04 11:33:51] epoch:[ 21/30 ] train step:570  loss: 0.75814 lr: 0.000100 batch_cost: 0.35681 sec, reader_cost: 0.00225 sec, ips: 44.84202 instance/sec.
[03/04 11:33:55] epoch:[ 21/30 ] train step:580  loss: 0.76822 lr: 0.000100 batch_cost: 0.35873 sec, reader_cost: 0.00230 sec, ips: 44.60151 instance/sec.
[03/04 11:33:58] epoch:[ 21/30 ] train step:590  loss: 0.80289 lr: 0.000100 batch_cost: 0.35571 sec, reader_cost: 0.00227 sec, ips: 44.98079 instance/sec.
[03/04 11:34:02] epoch:[ 21/30 ] train step:600  loss: 0.70459 lr: 0.000100 batch_cost: 0.35594 sec, reader_cost: 0.00218 sec, ips: 44.95108 instance/sec.
[03/04 11:34:05] epoch:[ 21/30 ] train step:610  loss: 0.81582 lr: 0.000100 batch_cost: 0.35521 sec, reader_cost: 0.00042 sec, ips: 45.04344 instance/sec.
[03/04 11:34:09] epoch:[ 21/30 ] train step:620  loss: 0.86135 lr: 0.000100 batch_cost: 0.35574 sec, reader_cost: 0.00212 sec, ips: 44.97687 instance/sec.
[03/04 11:34:12] epoch:[ 21/30 ] train step:630  loss: 0.97084 lr: 0.000100 batch_cost: 0.35629 sec, reader_cost: 0.00232 sec, ips: 44.90780 instance/sec.
[03/04 11:34:16] epoch:[ 21/30 ] train step:640  loss: 0.82850 lr: 0.000100 batch_cost: 0.35754 sec, reader_cost: 0.00217 sec, ips: 44.75046 instance/sec.
[03/04 11:34:20] epoch:[ 21/30 ] train step:650  loss: 0.98023 lr: 0.000100 batch_cost: 0.35748 sec, reader_cost: 0.00013 sec, ips: 44.75834 instance/sec.
[03/04 11:34:23] epoch:[ 21/30 ] train step:660  loss: 0.75812 lr: 0.000100 batch_cost: 0.35724 sec, reader_cost: 0.00225 sec, ips: 44.78827 instance/sec.
[03/04 11:34:27] epoch:[ 21/30 ] train step:670  loss: 0.77837 lr: 0.000100 batch_cost: 0.35653 sec, reader_cost: 0.00231 sec, ips: 44.87759 instance/sec.
[03/04 11:34:30] epoch:[ 21/30 ] train step:680  loss: 0.84541 lr: 0.000100 batch_cost: 0.35617 sec, reader_cost: 0.00226 sec, ips: 44.92220 instance/sec.
[03/04 11:34:34] epoch:[ 21/30 ] train step:690  loss: 0.76537 lr: 0.000100 batch_cost: 0.35641 sec, reader_cost: 0.00211 sec, ips: 44.89212 instance/sec.
[03/04 11:34:37] epoch:[ 21/30 ] train step:700  loss: 0.80066 lr: 0.000100 batch_cost: 0.35821 sec, reader_cost: 0.00228 sec, ips: 44.66670 instance/sec.
[03/04 11:34:41] epoch:[ 21/30 ] train step:710  loss: 0.75724 lr: 0.000100 batch_cost: 0.35520 sec, reader_cost: 0.00016 sec, ips: 45.04525 instance/sec.
[03/04 11:34:45] epoch:[ 21/30 ] train step:720  loss: 0.77055 lr: 0.000100 batch_cost: 0.35745 sec, reader_cost: 0.00229 sec, ips: 44.76183 instance/sec.
[03/04 11:34:48] epoch:[ 21/30 ] train step:730  loss: 0.63468 lr: 0.000100 batch_cost: 0.35549 sec, reader_cost: 0.00235 sec, ips: 45.00776 instance/sec.
[03/04 11:34:52] epoch:[ 21/30 ] train step:740  loss: 0.83687 lr: 0.000100 batch_cost: 0.35652 sec, reader_cost: 0.00013 sec, ips: 44.87819 instance/sec.
[03/04 11:34:55] epoch:[ 21/30 ] train step:750  loss: 0.74671 lr: 0.000100 batch_cost: 0.35489 sec, reader_cost: 0.00029 sec, ips: 45.08480 instance/sec.
[03/04 11:34:59] epoch:[ 21/30 ] train step:760  loss: 1.12931 lr: 0.000100 batch_cost: 0.35440 sec, reader_cost: 0.00213 sec, ips: 45.14643 instance/sec.
[03/04 11:35:02] epoch:[ 21/30 ] train step:770  loss: 0.92502 lr: 0.000100 batch_cost: 0.35645 sec, reader_cost: 0.00224 sec, ips: 44.88716 instance/sec.
[03/04 11:35:06] epoch:[ 21/30 ] train step:780  loss: 0.78229 lr: 0.000100 batch_cost: 0.35151 sec, reader_cost: 0.00006 sec, ips: 45.51790 instance/sec.
[03/04 11:35:08] END epoch:21  train loss_avg: 0.79285  avg_batch_cost: 0.35100 sec, avg_reader_cost: 0.00005 sec, batch_cost_sum: 281.03939 sec, avg_ips: 44.80511 instance/sec.
[03/04 11:35:09] epoch:[ 22/30 ] train step:0    loss: 0.73932 lr: 0.000100 batch_cost: 1.02774 sec, reader_cost: 0.66591 sec, ips: 15.56813 instance/sec.
[03/04 11:35:13] epoch:[ 22/30 ] train step:10   loss: 0.83482 lr: 0.000100 batch_cost: 0.35426 sec, reader_cost: 0.00015 sec, ips: 45.16515 instance/sec.
[03/04 11:35:16] epoch:[ 22/30 ] train step:20   loss: 1.16268 lr: 0.000100 batch_cost: 0.35601 sec, reader_cost: 0.00211 sec, ips: 44.94295 instance/sec.
[03/04 11:35:20] epoch:[ 22/30 ] train step:30   loss: 0.75132 lr: 0.000100 batch_cost: 0.35893 sec, reader_cost: 0.00219 sec, ips: 44.57716 instance/sec.
[03/04 11:35:24] epoch:[ 22/30 ] train step:40   loss: 0.74186 lr: 0.000100 batch_cost: 0.35494 sec, reader_cost: 0.00205 sec, ips: 45.07835 instance/sec.
[03/04 11:35:27] epoch:[ 22/30 ] train step:50   loss: 0.80147 lr: 0.000100 batch_cost: 0.35878 sec, reader_cost: 0.00013 sec, ips: 44.59523 instance/sec.
[03/04 11:35:31] epoch:[ 22/30 ] train step:60   loss: 0.80017 lr: 0.000100 batch_cost: 0.35444 sec, reader_cost: 0.00015 sec, ips: 45.14179 instance/sec.
[03/04 11:35:34] epoch:[ 22/30 ] train step:70   loss: 1.14463 lr: 0.000100 batch_cost: 0.35931 sec, reader_cost: 0.00226 sec, ips: 44.53040 instance/sec.
[03/04 11:35:38] epoch:[ 22/30 ] train step:80   loss: 0.77510 lr: 0.000100 batch_cost: 0.35656 sec, reader_cost: 0.00230 sec, ips: 44.87380 instance/sec.
[03/04 11:35:41] epoch:[ 22/30 ] train step:90   loss: 0.74627 lr: 0.000100 batch_cost: 0.35536 sec, reader_cost: 0.00225 sec, ips: 45.02476 instance/sec.
[03/04 11:35:45] epoch:[ 22/30 ] train step:100  loss: 0.67654 lr: 0.000100 batch_cost: 0.35614 sec, reader_cost: 0.00218 sec, ips: 44.92674 instance/sec.
[03/04 11:35:48] epoch:[ 22/30 ] train step:110  loss: 1.09360 lr: 0.000100 batch_cost: 0.35435 sec, reader_cost: 0.00015 sec, ips: 45.15369 instance/sec.
[03/04 11:35:52] epoch:[ 22/30 ] train step:120  loss: 0.85757 lr: 0.000100 batch_cost: 0.35608 sec, reader_cost: 0.00224 sec, ips: 44.93341 instance/sec.
[03/04 11:35:56] epoch:[ 22/30 ] train step:130  loss: 0.80385 lr: 0.000100 batch_cost: 0.35421 sec, reader_cost: 0.00210 sec, ips: 45.17044 instance/sec.
[03/04 11:35:59] epoch:[ 22/30 ] train step:140  loss: 0.69308 lr: 0.000100 batch_cost: 0.36037 sec, reader_cost: 0.00216 sec, ips: 44.39876 instance/sec.
[03/04 11:36:03] epoch:[ 22/30 ] train step:150  loss: 0.59590 lr: 0.000100 batch_cost: 0.35560 sec, reader_cost: 0.00227 sec, ips: 44.99379 instance/sec.
[03/04 11:36:06] epoch:[ 22/30 ] train step:160  loss: 0.76384 lr: 0.000100 batch_cost: 0.35541 sec, reader_cost: 0.00228 sec, ips: 45.01839 instance/sec.
[03/04 11:36:10] epoch:[ 22/30 ] train step:170  loss: 0.62896 lr: 0.000100 batch_cost: 0.35639 sec, reader_cost: 0.00210 sec, ips: 44.89407 instance/sec.
[03/04 11:36:13] epoch:[ 22/30 ] train step:180  loss: 0.87946 lr: 0.000100 batch_cost: 0.35697 sec, reader_cost: 0.00211 sec, ips: 44.82225 instance/sec.
[03/04 11:36:17] epoch:[ 22/30 ] train step:190  loss: 0.82207 lr: 0.000100 batch_cost: 0.35618 sec, reader_cost: 0.00223 sec, ips: 44.92063 instance/sec.
[03/04 11:36:21] epoch:[ 22/30 ] train step:200  loss: 0.70085 lr: 0.000100 batch_cost: 0.35553 sec, reader_cost: 0.00016 sec, ips: 45.00377 instance/sec.
[03/04 11:36:24] epoch:[ 22/30 ] train step:210  loss: 0.73401 lr: 0.000100 batch_cost: 0.35820 sec, reader_cost: 0.00230 sec, ips: 44.66730 instance/sec.
[03/04 11:36:28] epoch:[ 22/30 ] train step:220  loss: 1.07412 lr: 0.000100 batch_cost: 0.35470 sec, reader_cost: 0.00015 sec, ips: 45.10829 instance/sec.
[03/04 11:36:31] epoch:[ 22/30 ] train step:230  loss: 0.81893 lr: 0.000100 batch_cost: 0.35575 sec, reader_cost: 0.00014 sec, ips: 44.97551 instance/sec.
[03/04 11:36:35] epoch:[ 22/30 ] train step:240  loss: 0.89061 lr: 0.000100 batch_cost: 0.35626 sec, reader_cost: 0.00232 sec, ips: 44.91053 instance/sec.
[03/04 11:36:38] epoch:[ 22/30 ] train step:250  loss: 0.91524 lr: 0.000100 batch_cost: 0.35694 sec, reader_cost: 0.00222 sec, ips: 44.82540 instance/sec.
[03/04 11:36:42] epoch:[ 22/30 ] train step:260  loss: 0.84471 lr: 0.000100 batch_cost: 0.35651 sec, reader_cost: 0.00020 sec, ips: 44.87984 instance/sec.
[03/04 11:36:45] epoch:[ 22/30 ] train step:270  loss: 0.66400 lr: 0.000100 batch_cost: 0.35576 sec, reader_cost: 0.00220 sec, ips: 44.97362 instance/sec.
[03/04 11:36:49] epoch:[ 22/30 ] train step:280  loss: 0.71871 lr: 0.000100 batch_cost: 0.35755 sec, reader_cost: 0.00018 sec, ips: 44.74930 instance/sec.
[03/04 11:36:53] epoch:[ 22/30 ] train step:290  loss: 0.77131 lr: 0.000100 batch_cost: 0.35595 sec, reader_cost: 0.00230 sec, ips: 44.95057 instance/sec.
[03/04 11:36:56] epoch:[ 22/30 ] train step:300  loss: 0.73069 lr: 0.000100 batch_cost: 0.35728 sec, reader_cost: 0.00222 sec, ips: 44.78265 instance/sec.
[03/04 11:37:00] epoch:[ 22/30 ] train step:310  loss: 0.77222 lr: 0.000100 batch_cost: 0.35562 sec, reader_cost: 0.00220 sec, ips: 44.99131 instance/sec.
[03/04 11:37:03] epoch:[ 22/30 ] train step:320  loss: 0.79113 lr: 0.000100 batch_cost: 0.35644 sec, reader_cost: 0.00233 sec, ips: 44.88827 instance/sec.
[03/04 11:37:07] epoch:[ 22/30 ] train step:330  loss: 0.81460 lr: 0.000100 batch_cost: 0.35834 sec, reader_cost: 0.00264 sec, ips: 44.64973 instance/sec.
[03/04 11:37:10] epoch:[ 22/30 ] train step:340  loss: 0.94229 lr: 0.000100 batch_cost: 0.35478 sec, reader_cost: 0.00013 sec, ips: 45.09804 instance/sec.
[03/04 11:37:14] epoch:[ 22/30 ] train step:350  loss: 0.87639 lr: 0.000100 batch_cost: 0.35736 sec, reader_cost: 0.00233 sec, ips: 44.77234 instance/sec.
[03/04 11:37:18] epoch:[ 22/30 ] train step:360  loss: 0.78192 lr: 0.000100 batch_cost: 0.35593 sec, reader_cost: 0.00232 sec, ips: 44.95286 instance/sec.
[03/04 11:37:21] epoch:[ 22/30 ] train step:370  loss: 0.75013 lr: 0.000100 batch_cost: 0.35797 sec, reader_cost: 0.00251 sec, ips: 44.69666 instance/sec.
[03/04 11:37:25] epoch:[ 22/30 ] train step:380  loss: 1.18595 lr: 0.000100 batch_cost: 0.35443 sec, reader_cost: 0.00236 sec, ips: 45.14255 instance/sec.
[03/04 11:37:28] epoch:[ 22/30 ] train step:390  loss: 0.84146 lr: 0.000100 batch_cost: 0.35866 sec, reader_cost: 0.00230 sec, ips: 44.61011 instance/sec.
[03/04 11:37:32] epoch:[ 22/30 ] train step:400  loss: 0.67735 lr: 0.000100 batch_cost: 0.35657 sec, reader_cost: 0.00267 sec, ips: 44.87167 instance/sec.
[03/04 11:37:35] epoch:[ 22/30 ] train step:410  loss: 0.71008 lr: 0.000100 batch_cost: 0.35711 sec, reader_cost: 0.00229 sec, ips: 44.80475 instance/sec.
[03/04 11:37:39] epoch:[ 22/30 ] train step:420  loss: 0.72662 lr: 0.000100 batch_cost: 0.35703 sec, reader_cost: 0.00015 sec, ips: 44.81429 instance/sec.
[03/04 11:37:42] epoch:[ 22/30 ] train step:430  loss: 0.63645 lr: 0.000100 batch_cost: 0.35637 sec, reader_cost: 0.00239 sec, ips: 44.89695 instance/sec.
[03/04 11:37:46] epoch:[ 22/30 ] train step:440  loss: 0.65332 lr: 0.000100 batch_cost: 0.35650 sec, reader_cost: 0.00221 sec, ips: 44.88092 instance/sec.
[03/04 11:37:50] epoch:[ 22/30 ] train step:450  loss: 0.89622 lr: 0.000100 batch_cost: 0.35573 sec, reader_cost: 0.00231 sec, ips: 44.97753 instance/sec.
[03/04 11:37:53] epoch:[ 22/30 ] train step:460  loss: 0.74242 lr: 0.000100 batch_cost: 0.35797 sec, reader_cost: 0.00014 sec, ips: 44.69633 instance/sec.
[03/04 11:37:57] epoch:[ 22/30 ] train step:470  loss: 0.90628 lr: 0.000100 batch_cost: 0.35593 sec, reader_cost: 0.00221 sec, ips: 44.95205 instance/sec.
[03/04 11:38:00] epoch:[ 22/30 ] train step:480  loss: 0.69852 lr: 0.000100 batch_cost: 0.35687 sec, reader_cost: 0.00232 sec, ips: 44.83417 instance/sec.
[03/04 11:38:04] epoch:[ 22/30 ] train step:490  loss: 0.83941 lr: 0.000100 batch_cost: 0.35526 sec, reader_cost: 0.00013 sec, ips: 45.03802 instance/sec.
[03/04 11:38:07] epoch:[ 22/30 ] train step:500  loss: 0.66263 lr: 0.000100 batch_cost: 0.35548 sec, reader_cost: 0.00226 sec, ips: 45.01008 instance/sec.
[03/04 11:38:11] epoch:[ 22/30 ] train step:510  loss: 0.82098 lr: 0.000100 batch_cost: 0.35774 sec, reader_cost: 0.00221 sec, ips: 44.72517 instance/sec.
[03/04 11:38:15] epoch:[ 22/30 ] train step:520  loss: 0.84256 lr: 0.000100 batch_cost: 0.35607 sec, reader_cost: 0.00270 sec, ips: 44.93456 instance/sec.
[03/04 11:38:18] epoch:[ 22/30 ] train step:530  loss: 0.84721 lr: 0.000100 batch_cost: 0.35744 sec, reader_cost: 0.00015 sec, ips: 44.76303 instance/sec.
[03/04 11:38:22] epoch:[ 22/30 ] train step:540  loss: 1.07135 lr: 0.000100 batch_cost: 0.35594 sec, reader_cost: 0.00279 sec, ips: 44.95081 instance/sec.
[03/04 11:38:25] epoch:[ 22/30 ] train step:550  loss: 0.85227 lr: 0.000100 batch_cost: 0.35537 sec, reader_cost: 0.00011 sec, ips: 45.02406 instance/sec.
[03/04 11:38:29] epoch:[ 22/30 ] train step:560  loss: 0.83801 lr: 0.000100 batch_cost: 0.35625 sec, reader_cost: 0.00233 sec, ips: 44.91179 instance/sec.
[03/04 11:38:32] epoch:[ 22/30 ] train step:570  loss: 0.81001 lr: 0.000100 batch_cost: 0.35437 sec, reader_cost: 0.00018 sec, ips: 45.15002 instance/sec.
[03/04 11:38:36] epoch:[ 22/30 ] train step:580  loss: 0.87373 lr: 0.000100 batch_cost: 0.35538 sec, reader_cost: 0.00017 sec, ips: 45.02210 instance/sec.
[03/04 11:38:39] epoch:[ 22/30 ] train step:590  loss: 0.71646 lr: 0.000100 batch_cost: 0.35587 sec, reader_cost: 0.00237 sec, ips: 44.96024 instance/sec.
[03/04 11:38:43] epoch:[ 22/30 ] train step:600  loss: 0.72731 lr: 0.000100 batch_cost: 0.35594 sec, reader_cost: 0.00233 sec, ips: 44.95102 instance/sec.
[03/04 11:38:47] epoch:[ 22/30 ] train step:610  loss: 0.84024 lr: 0.000100 batch_cost: 0.35730 sec, reader_cost: 0.00249 sec, ips: 44.78068 instance/sec.
[03/04 11:38:50] epoch:[ 22/30 ] train step:620  loss: 0.78197 lr: 0.000100 batch_cost: 0.35599 sec, reader_cost: 0.00016 sec, ips: 44.94560 instance/sec.
[03/04 11:38:54] epoch:[ 22/30 ] train step:630  loss: 0.83589 lr: 0.000100 batch_cost: 0.35498 sec, reader_cost: 0.00015 sec, ips: 45.07260 instance/sec.
[03/04 11:38:57] epoch:[ 22/30 ] train step:640  loss: 0.84167 lr: 0.000100 batch_cost: 0.35842 sec, reader_cost: 0.00222 sec, ips: 44.63984 instance/sec.
[03/04 11:39:01] epoch:[ 22/30 ] train step:650  loss: 0.79437 lr: 0.000100 batch_cost: 0.35595 sec, reader_cost: 0.00015 sec, ips: 44.94994 instance/sec.
[03/04 11:39:04] epoch:[ 22/30 ] train step:660  loss: 0.68548 lr: 0.000100 batch_cost: 0.35476 sec, reader_cost: 0.00253 sec, ips: 45.10089 instance/sec.
[03/04 11:39:08] epoch:[ 22/30 ] train step:670  loss: 0.76486 lr: 0.000100 batch_cost: 0.35615 sec, reader_cost: 0.00030 sec, ips: 44.92493 instance/sec.
[03/04 11:39:11] epoch:[ 22/30 ] train step:680  loss: 0.87296 lr: 0.000100 batch_cost: 0.35620 sec, reader_cost: 0.00225 sec, ips: 44.91907 instance/sec.
[03/04 11:39:15] epoch:[ 22/30 ] train step:690  loss: 0.72465 lr: 0.000100 batch_cost: 0.35666 sec, reader_cost: 0.00243 sec, ips: 44.86121 instance/sec.
[03/04 11:39:19] epoch:[ 22/30 ] train step:700  loss: 0.87221 lr: 0.000100 batch_cost: 0.35787 sec, reader_cost: 0.00235 sec, ips: 44.70908 instance/sec.
[03/04 11:39:22] epoch:[ 22/30 ] train step:710  loss: 0.72810 lr: 0.000100 batch_cost: 0.35727 sec, reader_cost: 0.00228 sec, ips: 44.78391 instance/sec.
[03/04 11:39:26] epoch:[ 22/30 ] train step:720  loss: 0.81975 lr: 0.000100 batch_cost: 0.35278 sec, reader_cost: 0.00042 sec, ips: 45.35391 instance/sec.
[03/04 11:39:29] epoch:[ 22/30 ] train step:730  loss: 0.76621 lr: 0.000100 batch_cost: 0.35839 sec, reader_cost: 0.00258 sec, ips: 44.64373 instance/sec.
[03/04 11:39:33] epoch:[ 22/30 ] train step:740  loss: 0.81539 lr: 0.000100 batch_cost: 0.35587 sec, reader_cost: 0.00224 sec, ips: 44.96048 instance/sec.
[03/04 11:39:36] epoch:[ 22/30 ] train step:750  loss: 0.65170 lr: 0.000100 batch_cost: 0.35513 sec, reader_cost: 0.00015 sec, ips: 45.05432 instance/sec.
[03/04 11:39:40] epoch:[ 22/30 ] train step:760  loss: 1.17151 lr: 0.000100 batch_cost: 0.35748 sec, reader_cost: 0.00228 sec, ips: 44.75741 instance/sec.
[03/04 11:39:44] epoch:[ 22/30 ] train step:770  loss: 0.64601 lr: 0.000100 batch_cost: 0.35623 sec, reader_cost: 0.00017 sec, ips: 44.91516 instance/sec.
[03/04 11:39:47] epoch:[ 22/30 ] train step:780  loss: 0.73742 lr: 0.000100 batch_cost: 0.35314 sec, reader_cost: 0.00005 sec, ips: 45.30841 instance/sec.
[03/04 11:39:49] END epoch:22  train loss_avg: 0.78685  avg_batch_cost: 0.35408 sec, avg_reader_cost: 0.00006 sec, batch_cost_sum: 280.91194 sec, avg_ips: 44.82544 instance/sec.
[03/04 11:39:51] epoch:[ 23/30 ] train step:0    loss: 0.67181 lr: 0.000100 batch_cost: 1.13742 sec, reader_cost: 0.76859 sec, ips: 14.06690 instance/sec.
[03/04 11:39:54] epoch:[ 23/30 ] train step:10   loss: 0.75326 lr: 0.000100 batch_cost: 0.35736 sec, reader_cost: 0.00015 sec, ips: 44.77288 instance/sec.
[03/04 11:39:58] epoch:[ 23/30 ] train step:20   loss: 0.77024 lr: 0.000100 batch_cost: 0.35512 sec, reader_cost: 0.00013 sec, ips: 45.05469 instance/sec.
[03/04 11:40:01] epoch:[ 23/30 ] train step:30   loss: 0.67124 lr: 0.000100 batch_cost: 0.35836 sec, reader_cost: 0.00224 sec, ips: 44.64760 instance/sec.
[03/04 11:40:05] epoch:[ 23/30 ] train step:40   loss: 0.57228 lr: 0.000100 batch_cost: 0.35442 sec, reader_cost: 0.00208 sec, ips: 45.14452 instance/sec.
[03/04 11:40:08] epoch:[ 23/30 ] train step:50   loss: 0.82606 lr: 0.000100 batch_cost: 0.35715 sec, reader_cost: 0.00223 sec, ips: 44.79951 instance/sec.
[03/04 11:40:12] epoch:[ 23/30 ] train step:60   loss: 0.75231 lr: 0.000100 batch_cost: 0.35388 sec, reader_cost: 0.00013 sec, ips: 45.21253 instance/sec.
[03/04 11:40:16] epoch:[ 23/30 ] train step:70   loss: 0.72572 lr: 0.000100 batch_cost: 0.35492 sec, reader_cost: 0.00211 sec, ips: 45.08099 instance/sec.
[03/04 11:40:19] epoch:[ 23/30 ] train step:80   loss: 0.65892 lr: 0.000100 batch_cost: 0.35639 sec, reader_cost: 0.00209 sec, ips: 44.89518 instance/sec.
[03/04 11:40:23] epoch:[ 23/30 ] train step:90   loss: 0.76663 lr: 0.000100 batch_cost: 0.35453 sec, reader_cost: 0.00012 sec, ips: 45.12995 instance/sec.
[03/04 11:40:26] epoch:[ 23/30 ] train step:100  loss: 0.90444 lr: 0.000100 batch_cost: 0.35598 sec, reader_cost: 0.00205 sec, ips: 44.94587 instance/sec.
[03/04 11:40:30] epoch:[ 23/30 ] train step:110  loss: 0.81018 lr: 0.000100 batch_cost: 0.35530 sec, reader_cost: 0.00219 sec, ips: 45.03231 instance/sec.
[03/04 11:40:33] epoch:[ 23/30 ] train step:120  loss: 0.95336 lr: 0.000100 batch_cost: 0.35804 sec, reader_cost: 0.00221 sec, ips: 44.68714 instance/sec.
[03/04 11:40:37] epoch:[ 23/30 ] train step:130  loss: 0.82836 lr: 0.000100 batch_cost: 0.35525 sec, reader_cost: 0.00238 sec, ips: 45.03842 instance/sec.
[03/04 11:40:40] epoch:[ 23/30 ] train step:140  loss: 0.76972 lr: 0.000100 batch_cost: 0.35657 sec, reader_cost: 0.00221 sec, ips: 44.87194 instance/sec.
[03/04 11:40:44] epoch:[ 23/30 ] train step:150  loss: 0.83796 lr: 0.000100 batch_cost: 0.35507 sec, reader_cost: 0.00218 sec, ips: 45.06110 instance/sec.
[03/04 11:40:48] epoch:[ 23/30 ] train step:160  loss: 0.95179 lr: 0.000100 batch_cost: 0.35599 sec, reader_cost: 0.00228 sec, ips: 44.94518 instance/sec.
[03/04 11:40:51] epoch:[ 23/30 ] train step:170  loss: 0.72109 lr: 0.000100 batch_cost: 0.35537 sec, reader_cost: 0.00051 sec, ips: 45.02349 instance/sec.
[03/04 11:40:55] epoch:[ 23/30 ] train step:180  loss: 0.85390 lr: 0.000100 batch_cost: 0.35650 sec, reader_cost: 0.00230 sec, ips: 44.88116 instance/sec.
[03/04 11:40:58] epoch:[ 23/30 ] train step:190  loss: 0.71958 lr: 0.000100 batch_cost: 0.35705 sec, reader_cost: 0.00014 sec, ips: 44.81220 instance/sec.
[03/04 11:41:02] epoch:[ 23/30 ] train step:200  loss: 0.80406 lr: 0.000100 batch_cost: 0.35569 sec, reader_cost: 0.00241 sec, ips: 44.98311 instance/sec.
[03/04 11:41:05] epoch:[ 23/30 ] train step:210  loss: 0.78763 lr: 0.000100 batch_cost: 0.35659 sec, reader_cost: 0.00230 sec, ips: 44.86933 instance/sec.
[03/04 11:41:09] epoch:[ 23/30 ] train step:220  loss: 0.74873 lr: 0.000100 batch_cost: 0.35682 sec, reader_cost: 0.00218 sec, ips: 44.84031 instance/sec.
[03/04 11:41:13] epoch:[ 23/30 ] train step:230  loss: 0.91265 lr: 0.000100 batch_cost: 0.35499 sec, reader_cost: 0.00226 sec, ips: 45.07142 instance/sec.
[03/04 11:41:16] epoch:[ 23/30 ] train step:240  loss: 0.64620 lr: 0.000100 batch_cost: 0.35566 sec, reader_cost: 0.00224 sec, ips: 44.98691 instance/sec.
[03/04 11:41:20] epoch:[ 23/30 ] train step:250  loss: 0.82596 lr: 0.000100 batch_cost: 0.35484 sec, reader_cost: 0.00231 sec, ips: 45.09101 instance/sec.
[03/04 11:41:23] epoch:[ 23/30 ] train step:260  loss: 0.90344 lr: 0.000100 batch_cost: 0.35863 sec, reader_cost: 0.00229 sec, ips: 44.61465 instance/sec.
[03/04 11:41:27] epoch:[ 23/30 ] train step:270  loss: 0.80298 lr: 0.000100 batch_cost: 0.35630 sec, reader_cost: 0.00264 sec, ips: 44.90596 instance/sec.
[03/04 11:41:30] epoch:[ 23/30 ] train step:280  loss: 0.61023 lr: 0.000100 batch_cost: 0.35976 sec, reader_cost: 0.00225 sec, ips: 44.47400 instance/sec.
[03/04 11:41:34] epoch:[ 23/30 ] train step:290  loss: 0.81445 lr: 0.000100 batch_cost: 0.35642 sec, reader_cost: 0.00216 sec, ips: 44.89046 instance/sec.
[03/04 11:41:37] epoch:[ 23/30 ] train step:300  loss: 0.70048 lr: 0.000100 batch_cost: 0.35467 sec, reader_cost: 0.00213 sec, ips: 45.11256 instance/sec.
[03/04 11:41:41] epoch:[ 23/30 ] train step:310  loss: 0.83653 lr: 0.000100 batch_cost: 0.35632 sec, reader_cost: 0.00216 sec, ips: 44.90293 instance/sec.
[03/04 11:41:45] epoch:[ 23/30 ] train step:320  loss: 0.75610 lr: 0.000100 batch_cost: 0.35726 sec, reader_cost: 0.00233 sec, ips: 44.78495 instance/sec.
[03/04 11:41:48] epoch:[ 23/30 ] train step:330  loss: 0.83550 lr: 0.000100 batch_cost: 0.36060 sec, reader_cost: 0.00049 sec, ips: 44.37088 instance/sec.
[03/04 11:41:52] epoch:[ 23/30 ] train step:340  loss: 0.76597 lr: 0.000100 batch_cost: 0.35807 sec, reader_cost: 0.00221 sec, ips: 44.68351 instance/sec.
[03/04 11:41:55] epoch:[ 23/30 ] train step:350  loss: 0.83696 lr: 0.000100 batch_cost: 0.35816 sec, reader_cost: 0.00260 sec, ips: 44.67322 instance/sec.
[03/04 11:41:59] epoch:[ 23/30 ] train step:360  loss: 0.70260 lr: 0.000100 batch_cost: 0.35796 sec, reader_cost: 0.00218 sec, ips: 44.69714 instance/sec.
[03/04 11:42:03] epoch:[ 23/30 ] train step:370  loss: 0.97203 lr: 0.000100 batch_cost: 0.35953 sec, reader_cost: 0.00029 sec, ips: 44.50202 instance/sec.
[03/04 11:42:06] epoch:[ 23/30 ] train step:380  loss: 0.70709 lr: 0.000100 batch_cost: 0.35865 sec, reader_cost: 0.00219 sec, ips: 44.61156 instance/sec.
[03/04 11:42:10] epoch:[ 23/30 ] train step:390  loss: 0.74019 lr: 0.000100 batch_cost: 0.35783 sec, reader_cost: 0.00012 sec, ips: 44.71358 instance/sec.
[03/04 11:42:13] epoch:[ 23/30 ] train step:400  loss: 0.85148 lr: 0.000100 batch_cost: 0.35924 sec, reader_cost: 0.00232 sec, ips: 44.53843 instance/sec.
[03/04 11:42:17] epoch:[ 23/30 ] train step:410  loss: 0.74471 lr: 0.000100 batch_cost: 0.36049 sec, reader_cost: 0.00237 sec, ips: 44.38414 instance/sec.
[03/04 11:42:21] epoch:[ 23/30 ] train step:420  loss: 0.84778 lr: 0.000100 batch_cost: 0.35856 sec, reader_cost: 0.00227 sec, ips: 44.62236 instance/sec.
[03/04 11:42:24] epoch:[ 23/30 ] train step:430  loss: 0.94081 lr: 0.000100 batch_cost: 0.35818 sec, reader_cost: 0.00231 sec, ips: 44.67033 instance/sec.
[03/04 11:42:28] epoch:[ 23/30 ] train step:440  loss: 0.69421 lr: 0.000100 batch_cost: 0.35904 sec, reader_cost: 0.00222 sec, ips: 44.56310 instance/sec.
[03/04 11:42:31] epoch:[ 23/30 ] train step:450  loss: 0.86644 lr: 0.000100 batch_cost: 0.35969 sec, reader_cost: 0.00238 sec, ips: 44.48264 instance/sec.
[03/04 11:42:35] epoch:[ 23/30 ] train step:460  loss: 0.55139 lr: 0.000100 batch_cost: 0.35829 sec, reader_cost: 0.00238 sec, ips: 44.65704 instance/sec.
[03/04 11:42:38] epoch:[ 23/30 ] train step:470  loss: 0.68445 lr: 0.000100 batch_cost: 0.36010 sec, reader_cost: 0.00222 sec, ips: 44.43186 instance/sec.
[03/04 11:42:42] epoch:[ 23/30 ] train step:480  loss: 0.83581 lr: 0.000100 batch_cost: 0.35962 sec, reader_cost: 0.00234 sec, ips: 44.49137 instance/sec.
[03/04 11:42:46] epoch:[ 23/30 ] train step:490  loss: 0.68594 lr: 0.000100 batch_cost: 0.35781 sec, reader_cost: 0.00238 sec, ips: 44.71700 instance/sec.
[03/04 11:42:49] epoch:[ 23/30 ] train step:500  loss: 0.71887 lr: 0.000100 batch_cost: 0.36085 sec, reader_cost: 0.00242 sec, ips: 44.33983 instance/sec.
[03/04 11:42:53] epoch:[ 23/30 ] train step:510  loss: 0.64066 lr: 0.000100 batch_cost: 0.35922 sec, reader_cost: 0.00231 sec, ips: 44.54157 instance/sec.
[03/04 11:42:56] epoch:[ 23/30 ] train step:520  loss: 0.53537 lr: 0.000100 batch_cost: 0.35869 sec, reader_cost: 0.00220 sec, ips: 44.60652 instance/sec.
[03/04 11:43:00] epoch:[ 23/30 ] train step:530  loss: 0.70656 lr: 0.000100 batch_cost: 0.36032 sec, reader_cost: 0.00236 sec, ips: 44.40514 instance/sec.
[03/04 11:43:04] epoch:[ 23/30 ] train step:540  loss: 0.67688 lr: 0.000100 batch_cost: 0.35715 sec, reader_cost: 0.00229 sec, ips: 44.79921 instance/sec.
[03/04 11:43:07] epoch:[ 23/30 ] train step:550  loss: 0.78148 lr: 0.000100 batch_cost: 0.36063 sec, reader_cost: 0.00235 sec, ips: 44.36703 instance/sec.
[03/04 11:43:11] epoch:[ 23/30 ] train step:560  loss: 0.82709 lr: 0.000100 batch_cost: 0.35895 sec, reader_cost: 0.00239 sec, ips: 44.57399 instance/sec.
[03/04 11:43:14] epoch:[ 23/30 ] train step:570  loss: 0.87417 lr: 0.000100 batch_cost: 0.35945 sec, reader_cost: 0.00211 sec, ips: 44.51261 instance/sec.
[03/04 11:43:18] epoch:[ 23/30 ] train step:580  loss: 0.82688 lr: 0.000100 batch_cost: 0.35956 sec, reader_cost: 0.00231 sec, ips: 44.49871 instance/sec.
[03/04 11:43:22] epoch:[ 23/30 ] train step:590  loss: 0.66530 lr: 0.000100 batch_cost: 0.35797 sec, reader_cost: 0.00230 sec, ips: 44.69639 instance/sec.
[03/04 11:43:25] epoch:[ 23/30 ] train step:600  loss: 0.82014 lr: 0.000100 batch_cost: 0.35936 sec, reader_cost: 0.00256 sec, ips: 44.52369 instance/sec.
[03/04 11:43:29] epoch:[ 23/30 ] train step:610  loss: 0.79945 lr: 0.000100 batch_cost: 0.35828 sec, reader_cost: 0.00244 sec, ips: 44.65814 instance/sec.
[03/04 11:43:32] epoch:[ 23/30 ] train step:620  loss: 0.83174 lr: 0.000100 batch_cost: 0.35934 sec, reader_cost: 0.00220 sec, ips: 44.52608 instance/sec.
[03/04 11:43:36] epoch:[ 23/30 ] train step:630  loss: 0.91847 lr: 0.000100 batch_cost: 0.35871 sec, reader_cost: 0.00221 sec, ips: 44.60386 instance/sec.
[03/04 11:43:39] epoch:[ 23/30 ] train step:640  loss: 0.70387 lr: 0.000100 batch_cost: 0.35919 sec, reader_cost: 0.00232 sec, ips: 44.54411 instance/sec.
[03/04 11:43:43] epoch:[ 23/30 ] train step:650  loss: 0.70453 lr: 0.000100 batch_cost: 0.35942 sec, reader_cost: 0.00224 sec, ips: 44.51577 instance/sec.
[03/04 11:43:47] epoch:[ 23/30 ] train step:660  loss: 0.69114 lr: 0.000100 batch_cost: 0.35979 sec, reader_cost: 0.00245 sec, ips: 44.47046 instance/sec.
[03/04 11:43:50] epoch:[ 23/30 ] train step:670  loss: 0.64360 lr: 0.000100 batch_cost: 0.36099 sec, reader_cost: 0.00233 sec, ips: 44.32255 instance/sec.
[03/04 11:43:54] epoch:[ 23/30 ] train step:680  loss: 1.13853 lr: 0.000100 batch_cost: 0.35867 sec, reader_cost: 0.00240 sec, ips: 44.60946 instance/sec.
[03/04 11:43:57] epoch:[ 23/30 ] train step:690  loss: 0.75747 lr: 0.000100 batch_cost: 0.35953 sec, reader_cost: 0.00224 sec, ips: 44.50311 instance/sec.
[03/04 11:44:01] epoch:[ 23/30 ] train step:700  loss: 0.80272 lr: 0.000100 batch_cost: 0.35829 sec, reader_cost: 0.00233 sec, ips: 44.65654 instance/sec.
[03/04 11:44:05] epoch:[ 23/30 ] train step:710  loss: 0.86030 lr: 0.000100 batch_cost: 0.35743 sec, reader_cost: 0.00014 sec, ips: 44.76339 instance/sec.
[03/04 11:44:08] epoch:[ 23/30 ] train step:720  loss: 0.72118 lr: 0.000100 batch_cost: 0.36025 sec, reader_cost: 0.00223 sec, ips: 44.41369 instance/sec.
[03/04 11:44:12] epoch:[ 23/30 ] train step:730  loss: 0.72888 lr: 0.000100 batch_cost: 0.36049 sec, reader_cost: 0.00234 sec, ips: 44.38344 instance/sec.
[03/04 11:44:15] epoch:[ 23/30 ] train step:740  loss: 0.68388 lr: 0.000100 batch_cost: 0.35942 sec, reader_cost: 0.00223 sec, ips: 44.51645 instance/sec.
[03/04 11:44:19] epoch:[ 23/30 ] train step:750  loss: 0.84207 lr: 0.000100 batch_cost: 0.36100 sec, reader_cost: 0.00273 sec, ips: 44.32100 instance/sec.
[03/04 11:44:23] epoch:[ 23/30 ] train step:760  loss: 0.72161 lr: 0.000100 batch_cost: 0.35912 sec, reader_cost: 0.00229 sec, ips: 44.55274 instance/sec.
[03/04 11:44:26] epoch:[ 23/30 ] train step:770  loss: 0.68675 lr: 0.000100 batch_cost: 0.35880 sec, reader_cost: 0.00226 sec, ips: 44.59357 instance/sec.
[03/04 11:44:30] epoch:[ 23/30 ] train step:780  loss: 0.79952 lr: 0.000100 batch_cost: 0.35346 sec, reader_cost: 0.00008 sec, ips: 45.26675 instance/sec.
[03/04 11:44:32] END epoch:23  train loss_avg: 0.78272  avg_batch_cost: 0.35422 sec, avg_reader_cost: 0.00006 sec, batch_cost_sum: 282.38228 sec, avg_ips: 44.59203 instance/sec.
[03/04 11:44:33] epoch:[ 24/30 ] train step:0    loss: 0.73829 lr: 0.000100 batch_cost: 1.13175 sec, reader_cost: 0.76096 sec, ips: 14.13744 instance/sec.
[03/04 11:44:37] epoch:[ 24/30 ] train step:10   loss: 0.65540 lr: 0.000100 batch_cost: 0.36080 sec, reader_cost: 0.00232 sec, ips: 44.34581 instance/sec.
[03/04 11:44:40] epoch:[ 24/30 ] train step:20   loss: 0.69714 lr: 0.000100 batch_cost: 0.36024 sec, reader_cost: 0.00212 sec, ips: 44.41451 instance/sec.
[03/04 11:44:44] epoch:[ 24/30 ] train step:30   loss: 0.75395 lr: 0.000100 batch_cost: 0.35835 sec, reader_cost: 0.00225 sec, ips: 44.64908 instance/sec.
[03/04 11:44:48] epoch:[ 24/30 ] train step:40   loss: 0.63772 lr: 0.000100 batch_cost: 0.35893 sec, reader_cost: 0.00227 sec, ips: 44.57737 instance/sec.
[03/04 11:44:51] epoch:[ 24/30 ] train step:50   loss: 0.88154 lr: 0.000100 batch_cost: 0.35604 sec, reader_cost: 0.00010 sec, ips: 44.93868 instance/sec.
[03/04 11:44:55] epoch:[ 24/30 ] train step:60   loss: 0.82386 lr: 0.000100 batch_cost: 0.36099 sec, reader_cost: 0.00220 sec, ips: 44.32293 instance/sec.
[03/04 11:44:58] epoch:[ 24/30 ] train step:70   loss: 0.86463 lr: 0.000100 batch_cost: 0.35808 sec, reader_cost: 0.00212 sec, ips: 44.68267 instance/sec.
[03/04 11:45:02] epoch:[ 24/30 ] train step:80   loss: 0.65253 lr: 0.000100 batch_cost: 0.35849 sec, reader_cost: 0.00206 sec, ips: 44.63150 instance/sec.
[03/04 11:45:05] epoch:[ 24/30 ] train step:90   loss: 0.82288 lr: 0.000100 batch_cost: 0.35716 sec, reader_cost: 0.00013 sec, ips: 44.79757 instance/sec.
[03/04 11:45:09] epoch:[ 24/30 ] train step:100  loss: 0.77846 lr: 0.000100 batch_cost: 0.35701 sec, reader_cost: 0.00217 sec, ips: 44.81624 instance/sec.
[03/04 11:45:13] epoch:[ 24/30 ] train step:110  loss: 0.73156 lr: 0.000100 batch_cost: 0.35694 sec, reader_cost: 0.00221 sec, ips: 44.82492 instance/sec.
[03/04 11:45:16] epoch:[ 24/30 ] train step:120  loss: 0.87045 lr: 0.000100 batch_cost: 0.35991 sec, reader_cost: 0.00224 sec, ips: 44.45503 instance/sec.
[03/04 11:45:20] epoch:[ 24/30 ] train step:130  loss: 0.80686 lr: 0.000100 batch_cost: 0.35709 sec, reader_cost: 0.00013 sec, ips: 44.80687 instance/sec.
[03/04 11:45:23] epoch:[ 24/30 ] train step:140  loss: 0.65213 lr: 0.000100 batch_cost: 0.36108 sec, reader_cost: 0.00212 sec, ips: 44.31090 instance/sec.
[03/04 11:45:27] epoch:[ 24/30 ] train step:150  loss: 1.14354 lr: 0.000100 batch_cost: 0.35867 sec, reader_cost: 0.00211 sec, ips: 44.60895 instance/sec.
[03/04 11:45:31] epoch:[ 24/30 ] train step:160  loss: 0.71171 lr: 0.000100 batch_cost: 0.35843 sec, reader_cost: 0.00215 sec, ips: 44.63875 instance/sec.
[03/04 11:45:34] epoch:[ 24/30 ] train step:170  loss: 0.80781 lr: 0.000100 batch_cost: 0.35841 sec, reader_cost: 0.00012 sec, ips: 44.64130 instance/sec.
[03/04 11:45:38] epoch:[ 24/30 ] train step:180  loss: 0.72341 lr: 0.000100 batch_cost: 0.35783 sec, reader_cost: 0.00229 sec, ips: 44.71402 instance/sec.
[03/04 11:45:41] epoch:[ 24/30 ] train step:190  loss: 0.98468 lr: 0.000100 batch_cost: 0.35799 sec, reader_cost: 0.00227 sec, ips: 44.69342 instance/sec.
[03/04 11:45:45] epoch:[ 24/30 ] train step:200  loss: 0.79853 lr: 0.000100 batch_cost: 0.35928 sec, reader_cost: 0.00213 sec, ips: 44.53341 instance/sec.
[03/04 11:45:49] epoch:[ 24/30 ] train step:210  loss: 0.80331 lr: 0.000100 batch_cost: 0.35674 sec, reader_cost: 0.00014 sec, ips: 44.85086 instance/sec.
[03/04 11:45:52] epoch:[ 24/30 ] train step:220  loss: 0.76478 lr: 0.000100 batch_cost: 0.35771 sec, reader_cost: 0.00016 sec, ips: 44.72896 instance/sec.
[03/04 11:45:56] epoch:[ 24/30 ] train step:230  loss: 0.62408 lr: 0.000100 batch_cost: 0.35815 sec, reader_cost: 0.00222 sec, ips: 44.67432 instance/sec.
[03/04 11:45:59] epoch:[ 24/30 ] train step:240  loss: 0.74350 lr: 0.000100 batch_cost: 0.35877 sec, reader_cost: 0.00217 sec, ips: 44.59704 instance/sec.
[03/04 11:46:03] epoch:[ 24/30 ] train step:250  loss: 0.98811 lr: 0.000100 batch_cost: 0.35942 sec, reader_cost: 0.00013 sec, ips: 44.51654 instance/sec.
[03/04 11:46:06] epoch:[ 24/30 ] train step:260  loss: 0.53106 lr: 0.000100 batch_cost: 0.35714 sec, reader_cost: 0.00230 sec, ips: 44.80095 instance/sec.
[03/04 11:46:10] epoch:[ 24/30 ] train step:270  loss: 0.81806 lr: 0.000100 batch_cost: 0.36445 sec, reader_cost: 0.00229 sec, ips: 43.90200 instance/sec.
[03/04 11:46:14] epoch:[ 24/30 ] train step:280  loss: 1.08631 lr: 0.000100 batch_cost: 0.35971 sec, reader_cost: 0.00033 sec, ips: 44.47984 instance/sec.
[03/04 11:46:17] epoch:[ 24/30 ] train step:290  loss: 0.75865 lr: 0.000100 batch_cost: 0.35497 sec, reader_cost: 0.00012 sec, ips: 45.07472 instance/sec.
[03/04 11:46:21] epoch:[ 24/30 ] train step:300  loss: 0.71521 lr: 0.000100 batch_cost: 0.35929 sec, reader_cost: 0.00220 sec, ips: 44.53187 instance/sec.
[03/04 11:46:24] epoch:[ 24/30 ] train step:310  loss: 0.77796 lr: 0.000100 batch_cost: 0.35771 sec, reader_cost: 0.00219 sec, ips: 44.72937 instance/sec.
[03/04 11:46:28] epoch:[ 24/30 ] train step:320  loss: 0.67803 lr: 0.000100 batch_cost: 0.35940 sec, reader_cost: 0.00232 sec, ips: 44.51926 instance/sec.
[03/04 11:46:32] epoch:[ 24/30 ] train step:330  loss: 0.79168 lr: 0.000100 batch_cost: 0.35917 sec, reader_cost: 0.00014 sec, ips: 44.54742 instance/sec.
[03/04 11:46:35] epoch:[ 24/30 ] train step:340  loss: 0.68749 lr: 0.000100 batch_cost: 0.35816 sec, reader_cost: 0.00231 sec, ips: 44.67322 instance/sec.
[03/04 11:46:39] epoch:[ 24/30 ] train step:350  loss: 0.74065 lr: 0.000100 batch_cost: 0.36043 sec, reader_cost: 0.00231 sec, ips: 44.39171 instance/sec.
[03/04 11:46:42] epoch:[ 24/30 ] train step:360  loss: 0.89575 lr: 0.000100 batch_cost: 0.35945 sec, reader_cost: 0.00253 sec, ips: 44.51241 instance/sec.
[03/04 11:46:46] epoch:[ 24/30 ] train step:370  loss: 0.71391 lr: 0.000100 batch_cost: 0.35512 sec, reader_cost: 0.00015 sec, ips: 45.05535 instance/sec.
[03/04 11:46:49] epoch:[ 24/30 ] train step:380  loss: 0.73338 lr: 0.000100 batch_cost: 0.35768 sec, reader_cost: 0.00220 sec, ips: 44.73217 instance/sec.
[03/04 11:46:53] epoch:[ 24/30 ] train step:390  loss: 0.71140 lr: 0.000100 batch_cost: 0.35767 sec, reader_cost: 0.00031 sec, ips: 44.73402 instance/sec.
[03/04 11:46:57] epoch:[ 24/30 ] train step:400  loss: 0.92799 lr: 0.000100 batch_cost: 0.35931 sec, reader_cost: 0.00240 sec, ips: 44.52942 instance/sec.
[03/04 11:47:00] epoch:[ 24/30 ] train step:410  loss: 0.78618 lr: 0.000100 batch_cost: 0.36108 sec, reader_cost: 0.00240 sec, ips: 44.31114 instance/sec.
[03/04 11:47:04] epoch:[ 24/30 ] train step:420  loss: 0.77738 lr: 0.000100 batch_cost: 0.35915 sec, reader_cost: 0.00229 sec, ips: 44.54985 instance/sec.
[03/04 11:47:07] epoch:[ 24/30 ] train step:430  loss: 0.83145 lr: 0.000100 batch_cost: 0.35765 sec, reader_cost: 0.00042 sec, ips: 44.73635 instance/sec.
[03/04 11:47:11] epoch:[ 24/30 ] train step:440  loss: 0.67996 lr: 0.000100 batch_cost: 0.36116 sec, reader_cost: 0.00234 sec, ips: 44.30148 instance/sec.
[03/04 11:47:15] epoch:[ 24/30 ] train step:450  loss: 0.70565 lr: 0.000100 batch_cost: 0.35600 sec, reader_cost: 0.00011 sec, ips: 44.94335 instance/sec.
[03/04 11:47:18] epoch:[ 24/30 ] train step:460  loss: 0.94315 lr: 0.000100 batch_cost: 0.35886 sec, reader_cost: 0.00216 sec, ips: 44.58522 instance/sec.
[03/04 11:47:22] epoch:[ 24/30 ] train step:470  loss: 0.81744 lr: 0.000100 batch_cost: 0.36086 sec, reader_cost: 0.00230 sec, ips: 44.33880 instance/sec.
[03/04 11:47:25] epoch:[ 24/30 ] train step:480  loss: 0.79389 lr: 0.000100 batch_cost: 0.35777 sec, reader_cost: 0.00231 sec, ips: 44.72100 instance/sec.
[03/04 11:47:29] epoch:[ 24/30 ] train step:490  loss: 0.69887 lr: 0.000100 batch_cost: 0.35759 sec, reader_cost: 0.00223 sec, ips: 44.74431 instance/sec.
[03/04 11:47:33] epoch:[ 24/30 ] train step:500  loss: 0.91747 lr: 0.000100 batch_cost: 0.35904 sec, reader_cost: 0.00241 sec, ips: 44.56390 instance/sec.
[03/04 11:47:36] epoch:[ 24/30 ] train step:510  loss: 0.82149 lr: 0.000100 batch_cost: 0.35897 sec, reader_cost: 0.00230 sec, ips: 44.57142 instance/sec.
[03/04 11:47:40] epoch:[ 24/30 ] train step:520  loss: 0.77786 lr: 0.000100 batch_cost: 0.35912 sec, reader_cost: 0.00230 sec, ips: 44.55331 instance/sec.
[03/04 11:47:43] epoch:[ 24/30 ] train step:530  loss: 0.81305 lr: 0.000100 batch_cost: 0.35752 sec, reader_cost: 0.00239 sec, ips: 44.75276 instance/sec.
[03/04 11:47:47] epoch:[ 24/30 ] train step:540  loss: 0.75916 lr: 0.000100 batch_cost: 0.35889 sec, reader_cost: 0.00220 sec, ips: 44.58196 instance/sec.
[03/04 11:47:51] epoch:[ 24/30 ] train step:550  loss: 0.84261 lr: 0.000100 batch_cost: 0.35837 sec, reader_cost: 0.00231 sec, ips: 44.64691 instance/sec.
[03/04 11:47:54] epoch:[ 24/30 ] train step:560  loss: 0.68111 lr: 0.000100 batch_cost: 0.35895 sec, reader_cost: 0.00231 sec, ips: 44.57390 instance/sec.
[03/04 11:47:58] epoch:[ 24/30 ] train step:570  loss: 0.82926 lr: 0.000100 batch_cost: 0.35845 sec, reader_cost: 0.00012 sec, ips: 44.63670 instance/sec.
[03/04 11:48:01] epoch:[ 24/30 ] train step:580  loss: 0.79668 lr: 0.000100 batch_cost: 0.35910 sec, reader_cost: 0.00219 sec, ips: 44.55579 instance/sec.
[03/04 11:48:05] epoch:[ 24/30 ] train step:590  loss: 0.72431 lr: 0.000100 batch_cost: 0.35798 sec, reader_cost: 0.00251 sec, ips: 44.69529 instance/sec.
[03/04 11:48:08] epoch:[ 24/30 ] train step:600  loss: 0.75902 lr: 0.000100 batch_cost: 0.35907 sec, reader_cost: 0.00230 sec, ips: 44.55911 instance/sec.
[03/04 11:48:12] epoch:[ 24/30 ] train step:610  loss: 0.60984 lr: 0.000100 batch_cost: 0.35780 sec, reader_cost: 0.00023 sec, ips: 44.71772 instance/sec.
[03/04 11:48:16] epoch:[ 24/30 ] train step:620  loss: 0.73979 lr: 0.000100 batch_cost: 0.36462 sec, reader_cost: 0.00227 sec, ips: 43.88168 instance/sec.
[03/04 11:48:19] epoch:[ 24/30 ] train step:630  loss: 0.70481 lr: 0.000100 batch_cost: 0.35939 sec, reader_cost: 0.00233 sec, ips: 44.51952 instance/sec.
[03/04 11:48:23] epoch:[ 24/30 ] train step:640  loss: 0.75284 lr: 0.000100 batch_cost: 0.35885 sec, reader_cost: 0.00229 sec, ips: 44.58741 instance/sec.
[03/04 11:48:26] epoch:[ 24/30 ] train step:650  loss: 0.78498 lr: 0.000100 batch_cost: 0.35819 sec, reader_cost: 0.00012 sec, ips: 44.66855 instance/sec.
[03/04 11:48:30] epoch:[ 24/30 ] train step:660  loss: 0.55851 lr: 0.000100 batch_cost: 0.35807 sec, reader_cost: 0.00231 sec, ips: 44.68428 instance/sec.
[03/04 11:48:34] epoch:[ 24/30 ] train step:670  loss: 0.85041 lr: 0.000100 batch_cost: 0.35851 sec, reader_cost: 0.00218 sec, ips: 44.62916 instance/sec.
[03/04 11:48:37] epoch:[ 24/30 ] train step:680  loss: 0.76362 lr: 0.000100 batch_cost: 0.35994 sec, reader_cost: 0.00016 sec, ips: 44.45146 instance/sec.
[03/04 11:48:41] epoch:[ 24/30 ] train step:690  loss: 0.68202 lr: 0.000100 batch_cost: 0.35929 sec, reader_cost: 0.00236 sec, ips: 44.53273 instance/sec.
[03/04 11:48:44] epoch:[ 24/30 ] train step:700  loss: 0.87033 lr: 0.000100 batch_cost: 0.35771 sec, reader_cost: 0.00240 sec, ips: 44.72887 instance/sec.
[03/04 11:48:48] epoch:[ 24/30 ] train step:710  loss: 0.54614 lr: 0.000100 batch_cost: 0.35767 sec, reader_cost: 0.00012 sec, ips: 44.73393 instance/sec.
[03/04 11:48:51] epoch:[ 24/30 ] train step:720  loss: 0.87669 lr: 0.000100 batch_cost: 0.35949 sec, reader_cost: 0.00235 sec, ips: 44.50780 instance/sec.
[03/04 11:48:55] epoch:[ 24/30 ] train step:730  loss: 0.71157 lr: 0.000100 batch_cost: 0.35932 sec, reader_cost: 0.00230 sec, ips: 44.52912 instance/sec.
[03/04 11:48:59] epoch:[ 24/30 ] train step:740  loss: 1.29058 lr: 0.000100 batch_cost: 0.35728 sec, reader_cost: 0.00228 sec, ips: 44.78325 instance/sec.
[03/04 11:49:02] epoch:[ 24/30 ] train step:750  loss: 0.70709 lr: 0.000100 batch_cost: 0.35885 sec, reader_cost: 0.00253 sec, ips: 44.58676 instance/sec.
[03/04 11:49:06] epoch:[ 24/30 ] train step:760  loss: 0.87605 lr: 0.000100 batch_cost: 0.35921 sec, reader_cost: 0.00226 sec, ips: 44.54275 instance/sec.
[03/04 11:49:09] epoch:[ 24/30 ] train step:770  loss: 0.77770 lr: 0.000100 batch_cost: 0.35860 sec, reader_cost: 0.00012 sec, ips: 44.61770 instance/sec.
[03/04 11:49:13] epoch:[ 24/30 ] train step:780  loss: 0.72606 lr: 0.000100 batch_cost: 0.35616 sec, reader_cost: 0.00007 sec, ips: 44.92415 instance/sec.
[03/04 11:49:15] END epoch:24  train loss_avg: 0.77985  avg_batch_cost: 0.35546 sec, avg_reader_cost: 0.00006 sec, batch_cost_sum: 283.00153 sec, avg_ips: 44.49446 instance/sec.
[03/04 11:49:17] epoch:[ 25/30 ] train step:0    loss: 0.80689 lr: 0.000100 batch_cost: 1.11360 sec, reader_cost: 0.74752 sec, ips: 14.36777 instance/sec.
[03/04 11:49:20] epoch:[ 25/30 ] train step:10   loss: 0.88135 lr: 0.000100 batch_cost: 0.35766 sec, reader_cost: 0.00024 sec, ips: 44.73569 instance/sec.
[03/04 11:49:24] epoch:[ 25/30 ] train step:20   loss: 0.70753 lr: 0.000100 batch_cost: 0.35834 sec, reader_cost: 0.00012 sec, ips: 44.64985 instance/sec.
[03/04 11:49:27] epoch:[ 25/30 ] train step:30   loss: 0.85048 lr: 0.000100 batch_cost: 0.36120 sec, reader_cost: 0.00206 sec, ips: 44.29666 instance/sec.
[03/04 11:49:31] epoch:[ 25/30 ] train step:40   loss: 0.63166 lr: 0.000100 batch_cost: 0.35831 sec, reader_cost: 0.00231 sec, ips: 44.65392 instance/sec.
[03/04 11:49:34] epoch:[ 25/30 ] train step:50   loss: 0.86471 lr: 0.000100 batch_cost: 0.35804 sec, reader_cost: 0.00211 sec, ips: 44.68738 instance/sec.
[03/04 11:49:38] epoch:[ 25/30 ] train step:60   loss: 0.76122 lr: 0.000100 batch_cost: 0.35754 sec, reader_cost: 0.00012 sec, ips: 44.75025 instance/sec.
[03/04 11:49:42] epoch:[ 25/30 ] train step:70   loss: 0.79200 lr: 0.000100 batch_cost: 0.35759 sec, reader_cost: 0.00199 sec, ips: 44.74360 instance/sec.
[03/04 11:49:45] epoch:[ 25/30 ] train step:80   loss: 0.68830 lr: 0.000100 batch_cost: 0.35777 sec, reader_cost: 0.00224 sec, ips: 44.72156 instance/sec.
[03/04 11:49:49] epoch:[ 25/30 ] train step:90   loss: 0.81321 lr: 0.000100 batch_cost: 0.35752 sec, reader_cost: 0.00218 sec, ips: 44.75279 instance/sec.
[03/04 11:49:52] epoch:[ 25/30 ] train step:100  loss: 0.84158 lr: 0.000100 batch_cost: 0.35705 sec, reader_cost: 0.00238 sec, ips: 44.81154 instance/sec.
[03/04 11:49:56] epoch:[ 25/30 ] train step:110  loss: 0.78348 lr: 0.000100 batch_cost: 0.35926 sec, reader_cost: 0.00228 sec, ips: 44.53598 instance/sec.
[03/04 11:50:00] epoch:[ 25/30 ] train step:120  loss: 0.77651 lr: 0.000100 batch_cost: 0.35850 sec, reader_cost: 0.00257 sec, ips: 44.63058 instance/sec.
[03/04 11:50:03] epoch:[ 25/30 ] train step:130  loss: 0.76230 lr: 0.000100 batch_cost: 0.35996 sec, reader_cost: 0.00222 sec, ips: 44.44937 instance/sec.
[03/04 11:50:07] epoch:[ 25/30 ] train step:140  loss: 0.81876 lr: 0.000100 batch_cost: 0.36106 sec, reader_cost: 0.00232 sec, ips: 44.31442 instance/sec.
[03/04 11:50:10] epoch:[ 25/30 ] train step:150  loss: 0.72525 lr: 0.000100 batch_cost: 0.35749 sec, reader_cost: 0.00199 sec, ips: 44.75655 instance/sec.
[03/04 11:50:14] epoch:[ 25/30 ] train step:160  loss: 0.81044 lr: 0.000100 batch_cost: 0.36027 sec, reader_cost: 0.00215 sec, ips: 44.41099 instance/sec.
[03/04 11:50:18] epoch:[ 25/30 ] train step:170  loss: 0.79936 lr: 0.000100 batch_cost: 0.35929 sec, reader_cost: 0.00225 sec, ips: 44.53255 instance/sec.
[03/04 11:50:21] epoch:[ 25/30 ] train step:180  loss: 0.73631 lr: 0.000100 batch_cost: 0.35309 sec, reader_cost: 0.00025 sec, ips: 45.31465 instance/sec.
[03/04 11:50:25] epoch:[ 25/30 ] train step:190  loss: 0.70005 lr: 0.000100 batch_cost: 0.36033 sec, reader_cost: 0.00256 sec, ips: 44.40326 instance/sec.
[03/04 11:50:28] epoch:[ 25/30 ] train step:200  loss: 0.58644 lr: 0.000100 batch_cost: 0.35990 sec, reader_cost: 0.00224 sec, ips: 44.45647 instance/sec.
[03/04 11:50:32] epoch:[ 25/30 ] train step:210  loss: 0.69783 lr: 0.000100 batch_cost: 0.35749 sec, reader_cost: 0.00235 sec, ips: 44.75658 instance/sec.
[03/04 11:50:35] epoch:[ 25/30 ] train step:220  loss: 0.78819 lr: 0.000100 batch_cost: 0.35957 sec, reader_cost: 0.00244 sec, ips: 44.49806 instance/sec.
[03/04 11:50:39] epoch:[ 25/30 ] train step:230  loss: 0.73922 lr: 0.000100 batch_cost: 0.35912 sec, reader_cost: 0.00032 sec, ips: 44.55322 instance/sec.
[03/04 11:50:43] epoch:[ 25/30 ] train step:240  loss: 0.87627 lr: 0.000100 batch_cost: 0.35937 sec, reader_cost: 0.00238 sec, ips: 44.52257 instance/sec.
[03/04 11:50:46] epoch:[ 25/30 ] train step:250  loss: 0.92335 lr: 0.000100 batch_cost: 0.35936 sec, reader_cost: 0.00232 sec, ips: 44.52366 instance/sec.
[03/04 11:50:50] epoch:[ 25/30 ] train step:260  loss: 0.61917 lr: 0.000100 batch_cost: 0.35687 sec, reader_cost: 0.00242 sec, ips: 44.83399 instance/sec.
[03/04 11:50:53] epoch:[ 25/30 ] train step:270  loss: 0.63439 lr: 0.000100 batch_cost: 0.35924 sec, reader_cost: 0.00209 sec, ips: 44.53805 instance/sec.
[03/04 11:50:57] epoch:[ 25/30 ] train step:280  loss: 0.99502 lr: 0.000100 batch_cost: 0.36123 sec, reader_cost: 0.00218 sec, ips: 44.29263 instance/sec.
[03/04 11:51:01] epoch:[ 25/30 ] train step:290  loss: 0.68808 lr: 0.000100 batch_cost: 0.35739 sec, reader_cost: 0.00223 sec, ips: 44.76879 instance/sec.
[03/04 11:51:04] epoch:[ 25/30 ] train step:300  loss: 0.74152 lr: 0.000100 batch_cost: 0.35910 sec, reader_cost: 0.00233 sec, ips: 44.55538 instance/sec.
[03/04 11:51:08] epoch:[ 25/30 ] train step:310  loss: 0.75778 lr: 0.000100 batch_cost: 0.35939 sec, reader_cost: 0.00250 sec, ips: 44.51964 instance/sec.
[03/04 11:51:11] epoch:[ 25/30 ] train step:320  loss: 0.98827 lr: 0.000100 batch_cost: 0.35557 sec, reader_cost: 0.00227 sec, ips: 44.99789 instance/sec.
[03/04 11:51:15] epoch:[ 25/30 ] train step:330  loss: 0.79475 lr: 0.000100 batch_cost: 0.36038 sec, reader_cost: 0.00215 sec, ips: 44.39774 instance/sec.
[03/04 11:51:18] epoch:[ 25/30 ] train step:340  loss: 0.79842 lr: 0.000100 batch_cost: 0.35616 sec, reader_cost: 0.00233 sec, ips: 44.92349 instance/sec.
[03/04 11:51:22] epoch:[ 25/30 ] train step:350  loss: 0.88494 lr: 0.000100 batch_cost: 0.35565 sec, reader_cost: 0.00230 sec, ips: 44.98863 instance/sec.
[03/04 11:51:26] epoch:[ 25/30 ] train step:360  loss: 0.75504 lr: 0.000100 batch_cost: 0.35777 sec, reader_cost: 0.00264 sec, ips: 44.72121 instance/sec.
[03/04 11:51:29] epoch:[ 25/30 ] train step:370  loss: 0.78563 lr: 0.000100 batch_cost: 0.35505 sec, reader_cost: 0.00220 sec, ips: 45.06376 instance/sec.
[03/04 11:51:33] epoch:[ 25/30 ] train step:380  loss: 0.75367 lr: 0.000100 batch_cost: 0.35531 sec, reader_cost: 0.00241 sec, ips: 45.03150 instance/sec.
[03/04 11:51:36] epoch:[ 25/30 ] train step:390  loss: 0.76843 lr: 0.000100 batch_cost: 0.35660 sec, reader_cost: 0.00228 sec, ips: 44.86876 instance/sec.
[03/04 11:51:40] epoch:[ 25/30 ] train step:400  loss: 0.85183 lr: 0.000100 batch_cost: 0.35821 sec, reader_cost: 0.00015 sec, ips: 44.66632 instance/sec.
[03/04 11:51:43] epoch:[ 25/30 ] train step:410  loss: 0.87246 lr: 0.000100 batch_cost: 0.35550 sec, reader_cost: 0.00230 sec, ips: 45.00661 instance/sec.
[03/04 11:51:47] epoch:[ 25/30 ] train step:420  loss: 0.99862 lr: 0.000100 batch_cost: 0.35523 sec, reader_cost: 0.00244 sec, ips: 45.04165 instance/sec.
[03/04 11:51:51] epoch:[ 25/30 ] train step:430  loss: 0.71755 lr: 0.000100 batch_cost: 0.35709 sec, reader_cost: 0.00230 sec, ips: 44.80705 instance/sec.
[03/04 11:51:54] epoch:[ 25/30 ] train step:440  loss: 0.72655 lr: 0.000100 batch_cost: 0.35635 sec, reader_cost: 0.00214 sec, ips: 44.89947 instance/sec.
[03/04 11:51:58] epoch:[ 25/30 ] train step:450  loss: 0.66468 lr: 0.000100 batch_cost: 0.35825 sec, reader_cost: 0.00219 sec, ips: 44.66135 instance/sec.
[03/04 11:52:01] epoch:[ 25/30 ] train step:460  loss: 1.02462 lr: 0.000100 batch_cost: 0.35514 sec, reader_cost: 0.00014 sec, ips: 45.05260 instance/sec.
[03/04 11:52:05] epoch:[ 25/30 ] train step:470  loss: 0.67723 lr: 0.000100 batch_cost: 0.35624 sec, reader_cost: 0.00042 sec, ips: 44.91324 instance/sec.
[03/04 11:52:08] epoch:[ 25/30 ] train step:480  loss: 0.74764 lr: 0.000100 batch_cost: 0.35599 sec, reader_cost: 0.00234 sec, ips: 44.94452 instance/sec.
[03/04 11:52:12] epoch:[ 25/30 ] train step:490  loss: 0.92965 lr: 0.000100 batch_cost: 0.35641 sec, reader_cost: 0.00219 sec, ips: 44.89212 instance/sec.
[03/04 11:52:16] epoch:[ 25/30 ] train step:500  loss: 0.77901 lr: 0.000100 batch_cost: 0.35674 sec, reader_cost: 0.00226 sec, ips: 44.85035 instance/sec.
[03/04 11:52:19] epoch:[ 25/30 ] train step:510  loss: 0.83349 lr: 0.000100 batch_cost: 0.35710 sec, reader_cost: 0.00237 sec, ips: 44.80561 instance/sec.
[03/04 11:52:23] epoch:[ 25/30 ] train step:520  loss: 0.74425 lr: 0.000100 batch_cost: 0.35811 sec, reader_cost: 0.00231 sec, ips: 44.67919 instance/sec.
[03/04 11:52:26] epoch:[ 25/30 ] train step:530  loss: 0.80898 lr: 0.000100 batch_cost: 0.35661 sec, reader_cost: 0.00220 sec, ips: 44.86717 instance/sec.
[03/04 11:52:30] epoch:[ 25/30 ] train step:540  loss: 0.98198 lr: 0.000100 batch_cost: 0.35614 sec, reader_cost: 0.00268 sec, ips: 44.92565 instance/sec.
[03/04 11:52:33] epoch:[ 25/30 ] train step:550  loss: 0.76330 lr: 0.000100 batch_cost: 0.35464 sec, reader_cost: 0.00233 sec, ips: 45.11675 instance/sec.
[03/04 11:52:37] epoch:[ 25/30 ] train step:560  loss: 0.81066 lr: 0.000100 batch_cost: 0.35931 sec, reader_cost: 0.00223 sec, ips: 44.52980 instance/sec.
[03/04 11:52:40] epoch:[ 25/30 ] train step:570  loss: 0.71154 lr: 0.000100 batch_cost: 0.35642 sec, reader_cost: 0.00016 sec, ips: 44.89145 instance/sec.
[03/04 11:52:44] epoch:[ 25/30 ] train step:580  loss: 0.70630 lr: 0.000100 batch_cost: 0.35375 sec, reader_cost: 0.00230 sec, ips: 45.22910 instance/sec.
[03/04 11:52:48] epoch:[ 25/30 ] train step:590  loss: 0.83129 lr: 0.000100 batch_cost: 0.35340 sec, reader_cost: 0.00040 sec, ips: 45.27472 instance/sec.
[03/04 11:52:51] epoch:[ 25/30 ] train step:600  loss: 0.90017 lr: 0.000100 batch_cost: 0.35622 sec, reader_cost: 0.00013 sec, ips: 44.91573 instance/sec.
[03/04 11:52:55] epoch:[ 25/30 ] train step:610  loss: 0.76768 lr: 0.000100 batch_cost: 0.35659 sec, reader_cost: 0.00219 sec, ips: 44.86915 instance/sec.
[03/04 11:52:58] epoch:[ 25/30 ] train step:620  loss: 0.71920 lr: 0.000100 batch_cost: 0.35638 sec, reader_cost: 0.00232 sec, ips: 44.89569 instance/sec.
[03/04 11:53:02] epoch:[ 25/30 ] train step:630  loss: 0.75672 lr: 0.000100 batch_cost: 0.35715 sec, reader_cost: 0.00211 sec, ips: 44.79886 instance/sec.
[03/04 11:53:05] epoch:[ 25/30 ] train step:640  loss: 0.80871 lr: 0.000100 batch_cost: 0.35701 sec, reader_cost: 0.00235 sec, ips: 44.81639 instance/sec.
[03/04 11:53:09] epoch:[ 25/30 ] train step:650  loss: 0.82220 lr: 0.000100 batch_cost: 0.35573 sec, reader_cost: 0.00018 sec, ips: 44.97784 instance/sec.
[03/04 11:53:12] epoch:[ 25/30 ] train step:660  loss: 0.77918 lr: 0.000100 batch_cost: 0.35455 sec, reader_cost: 0.00012 sec, ips: 45.12737 instance/sec.
[03/04 11:53:16] epoch:[ 25/30 ] train step:670  loss: 0.63467 lr: 0.000100 batch_cost: 0.35579 sec, reader_cost: 0.00228 sec, ips: 44.97054 instance/sec.
[03/04 11:53:20] epoch:[ 25/30 ] train step:680  loss: 0.75641 lr: 0.000100 batch_cost: 0.35512 sec, reader_cost: 0.00012 sec, ips: 45.05484 instance/sec.
[03/04 11:53:23] epoch:[ 25/30 ] train step:690  loss: 0.69439 lr: 0.000100 batch_cost: 0.35896 sec, reader_cost: 0.00221 sec, ips: 44.57304 instance/sec.
[03/04 11:53:27] epoch:[ 25/30 ] train step:700  loss: 0.87357 lr: 0.000100 batch_cost: 0.35837 sec, reader_cost: 0.00237 sec, ips: 44.64682 instance/sec.
[03/04 11:53:30] epoch:[ 25/30 ] train step:710  loss: 0.66792 lr: 0.000100 batch_cost: 0.35474 sec, reader_cost: 0.00016 sec, ips: 45.10307 instance/sec.
[03/04 11:53:34] epoch:[ 25/30 ] train step:720  loss: 0.58377 lr: 0.000100 batch_cost: 0.35814 sec, reader_cost: 0.00234 sec, ips: 44.67557 instance/sec.
[03/04 11:53:37] epoch:[ 25/30 ] train step:730  loss: 0.62096 lr: 0.000100 batch_cost: 0.35702 sec, reader_cost: 0.00232 sec, ips: 44.81510 instance/sec.
[03/04 11:53:41] epoch:[ 25/30 ] train step:740  loss: 0.89040 lr: 0.000100 batch_cost: 0.35423 sec, reader_cost: 0.00232 sec, ips: 45.16874 instance/sec.
[03/04 11:53:45] epoch:[ 25/30 ] train step:750  loss: 1.15460 lr: 0.000100 batch_cost: 0.35685 sec, reader_cost: 0.00243 sec, ips: 44.83633 instance/sec.
[03/04 11:53:48] epoch:[ 25/30 ] train step:760  loss: 0.79748 lr: 0.000100 batch_cost: 0.35595 sec, reader_cost: 0.00235 sec, ips: 44.94973 instance/sec.
[03/04 11:53:52] epoch:[ 25/30 ] train step:770  loss: 0.86025 lr: 0.000100 batch_cost: 0.35693 sec, reader_cost: 0.00016 sec, ips: 44.82642 instance/sec.
[03/04 11:53:55] epoch:[ 25/30 ] train step:780  loss: 0.70831 lr: 0.000100 batch_cost: 0.35101 sec, reader_cost: 0.00006 sec, ips: 45.58311 instance/sec.
[03/04 11:53:57] END epoch:25  train loss_avg: 0.77512  avg_batch_cost: 0.35137 sec, avg_reader_cost: 0.00007 sec, batch_cost_sum: 281.89491 sec, avg_ips: 44.66913 instance/sec.
[03/04 11:53:59] epoch:[ 26/30 ] train step:0    loss: 0.71285 lr: 0.000100 batch_cost: 1.14342 sec, reader_cost: 0.77096 sec, ips: 13.99315 instance/sec.
[03/04 11:54:02] epoch:[ 26/30 ] train step:10   loss: 0.65542 lr: 0.000100 batch_cost: 0.35268 sec, reader_cost: 0.00012 sec, ips: 45.36642 instance/sec.
[03/04 11:54:06] epoch:[ 26/30 ] train step:20   loss: 0.65820 lr: 0.000100 batch_cost: 0.36039 sec, reader_cost: 0.00209 sec, ips: 44.39630 instance/sec.
[03/04 11:54:09] epoch:[ 26/30 ] train step:30   loss: 0.76579 lr: 0.000100 batch_cost: 0.35652 sec, reader_cost: 0.00217 sec, ips: 44.87768 instance/sec.
[03/04 11:54:13] epoch:[ 26/30 ] train step:40   loss: 1.02500 lr: 0.000100 batch_cost: 0.35389 sec, reader_cost: 0.00206 sec, ips: 45.21174 instance/sec.
[03/04 11:54:17] epoch:[ 26/30 ] train step:50   loss: 0.85706 lr: 0.000100 batch_cost: 0.35630 sec, reader_cost: 0.00215 sec, ips: 44.90584 instance/sec.
[03/04 11:54:20] epoch:[ 26/30 ] train step:60   loss: 0.73855 lr: 0.000100 batch_cost: 0.35629 sec, reader_cost: 0.00223 sec, ips: 44.90717 instance/sec.
[03/04 11:54:24] epoch:[ 26/30 ] train step:70   loss: 0.88297 lr: 0.000100 batch_cost: 0.36339 sec, reader_cost: 0.00235 sec, ips: 44.02937 instance/sec.
[03/04 11:54:27] epoch:[ 26/30 ] train step:80   loss: 0.77470 lr: 0.000100 batch_cost: 0.36085 sec, reader_cost: 0.00250 sec, ips: 44.33921 instance/sec.
[03/04 11:54:31] epoch:[ 26/30 ] train step:90   loss: 0.78358 lr: 0.000100 batch_cost: 0.35493 sec, reader_cost: 0.00222 sec, ips: 45.07926 instance/sec.
[03/04 11:54:34] epoch:[ 26/30 ] train step:100  loss: 0.85785 lr: 0.000100 batch_cost: 0.35720 sec, reader_cost: 0.00223 sec, ips: 44.79323 instance/sec.
[03/04 11:54:38] epoch:[ 26/30 ] train step:110  loss: 0.70635 lr: 0.000100 batch_cost: 0.35618 sec, reader_cost: 0.00018 sec, ips: 44.92165 instance/sec.
[03/04 11:54:42] epoch:[ 26/30 ] train step:120  loss: 0.74863 lr: 0.000100 batch_cost: 0.35920 sec, reader_cost: 0.00018 sec, ips: 44.54352 instance/sec.
[03/04 11:54:45] epoch:[ 26/30 ] train step:130  loss: 0.89464 lr: 0.000100 batch_cost: 0.35393 sec, reader_cost: 0.00013 sec, ips: 45.20634 instance/sec.
[03/04 11:54:49] epoch:[ 26/30 ] train step:140  loss: 0.72666 lr: 0.000100 batch_cost: 0.35480 sec, reader_cost: 0.00220 sec, ips: 45.09644 instance/sec.
[03/04 11:54:52] epoch:[ 26/30 ] train step:150  loss: 0.72659 lr: 0.000100 batch_cost: 0.35759 sec, reader_cost: 0.00224 sec, ips: 44.74458 instance/sec.
[03/04 11:54:56] epoch:[ 26/30 ] train step:160  loss: 0.90599 lr: 0.000100 batch_cost: 0.35437 sec, reader_cost: 0.00213 sec, ips: 45.15066 instance/sec.
[03/04 11:54:59] epoch:[ 26/30 ] train step:170  loss: 0.79923 lr: 0.000100 batch_cost: 0.35497 sec, reader_cost: 0.00223 sec, ips: 45.07423 instance/sec.
[03/04 11:55:03] epoch:[ 26/30 ] train step:180  loss: 0.63503 lr: 0.000100 batch_cost: 0.35643 sec, reader_cost: 0.00016 sec, ips: 44.88899 instance/sec.
[03/04 11:55:07] epoch:[ 26/30 ] train step:190  loss: 0.78072 lr: 0.000100 batch_cost: 0.35458 sec, reader_cost: 0.00226 sec, ips: 45.12397 instance/sec.
[03/04 11:55:10] epoch:[ 26/30 ] train step:200  loss: 0.64177 lr: 0.000100 batch_cost: 0.35479 sec, reader_cost: 0.00213 sec, ips: 45.09659 instance/sec.
[03/04 11:55:14] epoch:[ 26/30 ] train step:210  loss: 0.73403 lr: 0.000100 batch_cost: 0.35314 sec, reader_cost: 0.00022 sec, ips: 45.30761 instance/sec.
[03/04 11:55:17] epoch:[ 26/30 ] train step:220  loss: 0.64429 lr: 0.000100 batch_cost: 0.35563 sec, reader_cost: 0.00235 sec, ips: 44.99068 instance/sec.
[03/04 11:55:21] epoch:[ 26/30 ] train step:230  loss: 0.78263 lr: 0.000100 batch_cost: 0.35568 sec, reader_cost: 0.00230 sec, ips: 44.98368 instance/sec.
[03/04 11:55:24] epoch:[ 26/30 ] train step:240  loss: 0.79806 lr: 0.000100 batch_cost: 0.35540 sec, reader_cost: 0.00237 sec, ips: 45.01926 instance/sec.
[03/04 11:55:28] epoch:[ 26/30 ] train step:250  loss: 0.87372 lr: 0.000100 batch_cost: 0.35615 sec, reader_cost: 0.00219 sec, ips: 44.92481 instance/sec.
[03/04 11:55:31] epoch:[ 26/30 ] train step:260  loss: 0.66613 lr: 0.000100 batch_cost: 0.35487 sec, reader_cost: 0.00011 sec, ips: 45.08744 instance/sec.
[03/04 11:55:35] epoch:[ 26/30 ] train step:270  loss: 0.59019 lr: 0.000100 batch_cost: 0.35740 sec, reader_cost: 0.00224 sec, ips: 44.76748 instance/sec.
[03/04 11:55:38] epoch:[ 26/30 ] train step:280  loss: 0.67561 lr: 0.000100 batch_cost: 0.35454 sec, reader_cost: 0.00246 sec, ips: 45.12946 instance/sec.
[03/04 11:55:42] epoch:[ 26/30 ] train step:290  loss: 0.70069 lr: 0.000100 batch_cost: 0.35889 sec, reader_cost: 0.00239 sec, ips: 44.58178 instance/sec.
[03/04 11:55:46] epoch:[ 26/30 ] train step:300  loss: 0.76832 lr: 0.000100 batch_cost: 0.35340 sec, reader_cost: 0.00252 sec, ips: 45.27402 instance/sec.
[03/04 11:55:49] epoch:[ 26/30 ] train step:310  loss: 0.66837 lr: 0.000100 batch_cost: 0.35403 sec, reader_cost: 0.00240 sec, ips: 45.19417 instance/sec.
[03/04 11:55:53] epoch:[ 26/30 ] train step:320  loss: 0.67577 lr: 0.000100 batch_cost: 0.36265 sec, reader_cost: 0.00025 sec, ips: 44.11919 instance/sec.
[03/04 11:55:56] epoch:[ 26/30 ] train step:330  loss: 0.95880 lr: 0.000100 batch_cost: 0.35661 sec, reader_cost: 0.00129 sec, ips: 44.86711 instance/sec.
[03/04 11:56:00] epoch:[ 26/30 ] train step:340  loss: 0.77365 lr: 0.000100 batch_cost: 0.35993 sec, reader_cost: 0.00123 sec, ips: 44.45335 instance/sec.
[03/04 11:56:03] epoch:[ 26/30 ] train step:350  loss: 0.61784 lr: 0.000100 batch_cost: 0.35856 sec, reader_cost: 0.00136 sec, ips: 44.62239 instance/sec.
[03/04 11:56:07] epoch:[ 26/30 ] train step:360  loss: 0.64797 lr: 0.000100 batch_cost: 0.35638 sec, reader_cost: 0.00140 sec, ips: 44.89605 instance/sec.
[03/04 11:56:11] epoch:[ 26/30 ] train step:370  loss: 0.81402 lr: 0.000100 batch_cost: 0.35647 sec, reader_cost: 0.00024 sec, ips: 44.88479 instance/sec.
[03/04 11:56:14] epoch:[ 26/30 ] train step:380  loss: 0.76315 lr: 0.000100 batch_cost: 0.36183 sec, reader_cost: 0.00025 sec, ips: 44.21960 instance/sec.
[03/04 11:56:18] epoch:[ 26/30 ] train step:390  loss: 0.72358 lr: 0.000100 batch_cost: 0.35986 sec, reader_cost: 0.00015 sec, ips: 44.46165 instance/sec.
[03/04 11:56:21] epoch:[ 26/30 ] train step:400  loss: 0.67494 lr: 0.000100 batch_cost: 0.35605 sec, reader_cost: 0.00156 sec, ips: 44.93745 instance/sec.
[03/04 11:56:25] epoch:[ 26/30 ] train step:410  loss: 0.86066 lr: 0.000100 batch_cost: 0.35791 sec, reader_cost: 0.00144 sec, ips: 44.70396 instance/sec.
[03/04 11:56:29] epoch:[ 26/30 ] train step:420  loss: 0.62417 lr: 0.000100 batch_cost: 0.35955 sec, reader_cost: 0.00127 sec, ips: 44.50060 instance/sec.
[03/04 11:56:32] epoch:[ 26/30 ] train step:430  loss: 0.79034 lr: 0.000100 batch_cost: 0.35661 sec, reader_cost: 0.00130 sec, ips: 44.86690 instance/sec.
[03/04 11:56:36] epoch:[ 26/30 ] train step:440  loss: 0.80827 lr: 0.000100 batch_cost: 0.35867 sec, reader_cost: 0.00131 sec, ips: 44.60934 instance/sec.
[03/04 11:56:39] epoch:[ 26/30 ] train step:450  loss: 0.75075 lr: 0.000100 batch_cost: 0.35855 sec, reader_cost: 0.00180 sec, ips: 44.62438 instance/sec.
[03/04 11:56:43] epoch:[ 26/30 ] train step:460  loss: 0.65580 lr: 0.000100 batch_cost: 0.35741 sec, reader_cost: 0.00132 sec, ips: 44.76595 instance/sec.
[03/04 11:56:46] epoch:[ 26/30 ] train step:470  loss: 1.06994 lr: 0.000100 batch_cost: 0.35667 sec, reader_cost: 0.00151 sec, ips: 44.85953 instance/sec.
[03/04 11:56:50] epoch:[ 26/30 ] train step:480  loss: 0.87511 lr: 0.000100 batch_cost: 0.35788 sec, reader_cost: 0.00129 sec, ips: 44.70741 instance/sec.
[03/04 11:56:54] epoch:[ 26/30 ] train step:490  loss: 0.86441 lr: 0.000100 batch_cost: 0.35790 sec, reader_cost: 0.00153 sec, ips: 44.70515 instance/sec.
[03/04 11:56:57] epoch:[ 26/30 ] train step:500  loss: 0.80230 lr: 0.000100 batch_cost: 0.35781 sec, reader_cost: 0.00141 sec, ips: 44.71617 instance/sec.
[03/04 11:57:01] epoch:[ 26/30 ] train step:510  loss: 0.85656 lr: 0.000100 batch_cost: 0.35944 sec, reader_cost: 0.00158 sec, ips: 44.51382 instance/sec.
[03/04 11:57:04] epoch:[ 26/30 ] train step:520  loss: 0.69063 lr: 0.000100 batch_cost: 0.35982 sec, reader_cost: 0.00025 sec, ips: 44.46696 instance/sec.
[03/04 11:57:08] epoch:[ 26/30 ] train step:530  loss: 0.76201 lr: 0.000100 batch_cost: 0.35746 sec, reader_cost: 0.00156 sec, ips: 44.75968 instance/sec.
[03/04 11:57:11] epoch:[ 26/30 ] train step:540  loss: 0.95342 lr: 0.000100 batch_cost: 0.35823 sec, reader_cost: 0.00137 sec, ips: 44.66355 instance/sec.
[03/04 11:57:15] epoch:[ 26/30 ] train step:550  loss: 0.86024 lr: 0.000100 batch_cost: 0.35860 sec, reader_cost: 0.00186 sec, ips: 44.61833 instance/sec.
[03/04 11:57:19] epoch:[ 26/30 ] train step:560  loss: 0.76069 lr: 0.000100 batch_cost: 0.35530 sec, reader_cost: 0.00124 sec, ips: 45.03231 instance/sec.
[03/04 11:57:22] epoch:[ 26/30 ] train step:570  loss: 0.77580 lr: 0.000100 batch_cost: 0.36033 sec, reader_cost: 0.00156 sec, ips: 44.40340 instance/sec.
[03/04 11:57:26] epoch:[ 26/30 ] train step:580  loss: 0.66626 lr: 0.000100 batch_cost: 0.36046 sec, reader_cost: 0.00018 sec, ips: 44.38796 instance/sec.
[03/04 11:57:29] epoch:[ 26/30 ] train step:590  loss: 0.62211 lr: 0.000100 batch_cost: 0.35769 sec, reader_cost: 0.00160 sec, ips: 44.73095 instance/sec.
[03/04 11:57:33] epoch:[ 26/30 ] train step:600  loss: 0.93611 lr: 0.000100 batch_cost: 0.35982 sec, reader_cost: 0.00149 sec, ips: 44.46663 instance/sec.
[03/04 11:57:37] epoch:[ 26/30 ] train step:610  loss: 0.82567 lr: 0.000100 batch_cost: 0.35735 sec, reader_cost: 0.00157 sec, ips: 44.77420 instance/sec.
[03/04 11:57:40] epoch:[ 26/30 ] train step:620  loss: 0.72161 lr: 0.000100 batch_cost: 0.35809 sec, reader_cost: 0.00126 sec, ips: 44.68169 instance/sec.
[03/04 11:57:44] epoch:[ 26/30 ] train step:630  loss: 0.79342 lr: 0.000100 batch_cost: 0.35886 sec, reader_cost: 0.00152 sec, ips: 44.58527 instance/sec.
[03/04 11:57:47] epoch:[ 26/30 ] train step:640  loss: 0.74592 lr: 0.000100 batch_cost: 0.36008 sec, reader_cost: 0.00142 sec, ips: 44.43425 instance/sec.
[03/04 11:57:51] epoch:[ 26/30 ] train step:650  loss: 0.84583 lr: 0.000100 batch_cost: 0.36085 sec, reader_cost: 0.00159 sec, ips: 44.33933 instance/sec.
[03/04 11:57:54] epoch:[ 26/30 ] train step:660  loss: 0.62300 lr: 0.000100 batch_cost: 0.35729 sec, reader_cost: 0.00153 sec, ips: 44.78217 instance/sec.
[03/04 11:57:58] epoch:[ 26/30 ] train step:670  loss: 0.65423 lr: 0.000100 batch_cost: 0.35745 sec, reader_cost: 0.00143 sec, ips: 44.76141 instance/sec.
[03/04 11:58:02] epoch:[ 26/30 ] train step:680  loss: 0.98615 lr: 0.000100 batch_cost: 0.35801 sec, reader_cost: 0.00146 sec, ips: 44.69178 instance/sec.
[03/04 11:58:05] epoch:[ 26/30 ] train step:690  loss: 0.72211 lr: 0.000100 batch_cost: 0.35365 sec, reader_cost: 0.00260 sec, ips: 45.24206 instance/sec.
[03/04 11:58:09] epoch:[ 26/30 ] train step:700  loss: 0.75142 lr: 0.000100 batch_cost: 0.36148 sec, reader_cost: 0.00249 sec, ips: 44.26268 instance/sec.
[03/04 11:58:12] epoch:[ 26/30 ] train step:710  loss: 0.84327 lr: 0.000100 batch_cost: 0.35531 sec, reader_cost: 0.00251 sec, ips: 45.03053 instance/sec.
[03/04 11:58:16] epoch:[ 26/30 ] train step:720  loss: 0.97820 lr: 0.000100 batch_cost: 0.35411 sec, reader_cost: 0.00247 sec, ips: 45.18416 instance/sec.
[03/04 11:58:19] epoch:[ 26/30 ] train step:730  loss: 0.76388 lr: 0.000100 batch_cost: 0.35462 sec, reader_cost: 0.00232 sec, ips: 45.11854 instance/sec.
[03/04 11:58:23] epoch:[ 26/30 ] train step:740  loss: 0.70692 lr: 0.000100 batch_cost: 0.35320 sec, reader_cost: 0.00238 sec, ips: 45.30055 instance/sec.
[03/04 11:58:27] epoch:[ 26/30 ] train step:750  loss: 0.60259 lr: 0.000100 batch_cost: 0.35468 sec, reader_cost: 0.00014 sec, ips: 45.11093 instance/sec.
[03/04 11:58:30] epoch:[ 26/30 ] train step:760  loss: 0.82901 lr: 0.000100 batch_cost: 0.35855 sec, reader_cost: 0.00255 sec, ips: 44.62367 instance/sec.
[03/04 11:58:34] epoch:[ 26/30 ] train step:770  loss: 0.75637 lr: 0.000100 batch_cost: 0.35365 sec, reader_cost: 0.00014 sec, ips: 45.24298 instance/sec.
[03/04 11:58:37] epoch:[ 26/30 ] train step:780  loss: 0.66771 lr: 0.000100 batch_cost: 0.35172 sec, reader_cost: 0.00008 sec, ips: 45.49035 instance/sec.
[03/04 11:58:39] END epoch:26  train loss_avg: 0.77187  avg_batch_cost: 0.35168 sec, avg_reader_cost: 0.00010 sec, batch_cost_sum: 281.65764 sec, avg_ips: 44.70676 instance/sec.
[03/04 11:58:41] epoch:[ 27/30 ] train step:0    loss: 0.87624 lr: 0.000100 batch_cost: 1.34452 sec, reader_cost: 0.97411 sec, ips: 11.90015 instance/sec.
[03/04 11:58:44] epoch:[ 27/30 ] train step:10   loss: 0.92579 lr: 0.000100 batch_cost: 0.35632 sec, reader_cost: 0.00220 sec, ips: 44.90296 instance/sec.
[03/04 11:58:48] epoch:[ 27/30 ] train step:20   loss: 0.70236 lr: 0.000100 batch_cost: 0.35485 sec, reader_cost: 0.00222 sec, ips: 45.08938 instance/sec.
[03/04 11:58:52] epoch:[ 27/30 ] train step:30   loss: 0.97328 lr: 0.000100 batch_cost: 0.35230 sec, reader_cost: 0.00013 sec, ips: 45.41548 instance/sec.
[03/04 11:58:55] epoch:[ 27/30 ] train step:40   loss: 0.70946 lr: 0.000100 batch_cost: 0.35745 sec, reader_cost: 0.00260 sec, ips: 44.76189 instance/sec.
[03/04 11:58:59] epoch:[ 27/30 ] train step:50   loss: 0.74272 lr: 0.000100 batch_cost: 0.35570 sec, reader_cost: 0.00016 sec, ips: 44.98148 instance/sec.
[03/04 11:59:02] epoch:[ 27/30 ] train step:60   loss: 0.66414 lr: 0.000100 batch_cost: 0.35509 sec, reader_cost: 0.00244 sec, ips: 45.05925 instance/sec.
[03/04 11:59:06] epoch:[ 27/30 ] train step:70   loss: 0.83665 lr: 0.000100 batch_cost: 0.35222 sec, reader_cost: 0.00011 sec, ips: 45.42621 instance/sec.
[03/04 11:59:09] epoch:[ 27/30 ] train step:80   loss: 0.89313 lr: 0.000100 batch_cost: 0.35443 sec, reader_cost: 0.00013 sec, ips: 45.14303 instance/sec.
[03/04 11:59:13] epoch:[ 27/30 ] train step:90   loss: 0.74650 lr: 0.000100 batch_cost: 0.35568 sec, reader_cost: 0.00226 sec, ips: 44.98459 instance/sec.
[03/04 11:59:16] epoch:[ 27/30 ] train step:100  loss: 0.93965 lr: 0.000100 batch_cost: 0.35881 sec, reader_cost: 0.00243 sec, ips: 44.59156 instance/sec.
[03/04 11:59:20] epoch:[ 27/30 ] train step:110  loss: 0.78565 lr: 0.000100 batch_cost: 0.35542 sec, reader_cost: 0.00014 sec, ips: 45.01712 instance/sec.
[03/04 11:59:24] epoch:[ 27/30 ] train step:120  loss: 0.76629 lr: 0.000100 batch_cost: 0.35534 sec, reader_cost: 0.00012 sec, ips: 45.02763 instance/sec.
[03/04 11:59:27] epoch:[ 27/30 ] train step:130  loss: 0.99214 lr: 0.000100 batch_cost: 0.35471 sec, reader_cost: 0.00016 sec, ips: 45.10717 instance/sec.
[03/04 11:59:31] epoch:[ 27/30 ] train step:140  loss: 0.76202 lr: 0.000100 batch_cost: 0.35728 sec, reader_cost: 0.00013 sec, ips: 44.78268 instance/sec.
[03/04 11:59:34] epoch:[ 27/30 ] train step:150  loss: 0.66397 lr: 0.000100 batch_cost: 0.35349 sec, reader_cost: 0.00011 sec, ips: 45.26358 instance/sec.
[03/04 11:59:38] epoch:[ 27/30 ] train step:160  loss: 0.80549 lr: 0.000100 batch_cost: 0.35671 sec, reader_cost: 0.00014 sec, ips: 44.85449 instance/sec.
[03/04 11:59:41] epoch:[ 27/30 ] train step:170  loss: 0.64123 lr: 0.000100 batch_cost: 0.36136 sec, reader_cost: 0.00019 sec, ips: 44.27766 instance/sec.
[03/04 11:59:45] epoch:[ 27/30 ] train step:180  loss: 0.55012 lr: 0.000100 batch_cost: 0.35789 sec, reader_cost: 0.00248 sec, ips: 44.70628 instance/sec.
[03/04 11:59:49] epoch:[ 27/30 ] train step:190  loss: 0.76124 lr: 0.000100 batch_cost: 0.35525 sec, reader_cost: 0.00012 sec, ips: 45.03857 instance/sec.
[03/04 11:59:52] epoch:[ 27/30 ] train step:200  loss: 0.64712 lr: 0.000100 batch_cost: 0.35489 sec, reader_cost: 0.00241 sec, ips: 45.08444 instance/sec.
[03/04 11:59:56] epoch:[ 27/30 ] train step:210  loss: 0.77585 lr: 0.000100 batch_cost: 0.35870 sec, reader_cost: 0.00216 sec, ips: 44.60516 instance/sec.
[03/04 11:59:59] epoch:[ 27/30 ] train step:220  loss: 0.66386 lr: 0.000100 batch_cost: 0.35578 sec, reader_cost: 0.00252 sec, ips: 44.97126 instance/sec.
[03/04 12:00:03] epoch:[ 27/30 ] train step:230  loss: 0.75700 lr: 0.000100 batch_cost: 0.35837 sec, reader_cost: 0.00226 sec, ips: 44.64635 instance/sec.
[03/04 12:00:06] epoch:[ 27/30 ] train step:240  loss: 0.70782 lr: 0.000100 batch_cost: 0.35558 sec, reader_cost: 0.00239 sec, ips: 44.99738 instance/sec.
[03/04 12:00:10] epoch:[ 27/30 ] train step:250  loss: 0.81657 lr: 0.000100 batch_cost: 0.35712 sec, reader_cost: 0.00212 sec, ips: 44.80307 instance/sec.
[03/04 12:00:13] epoch:[ 27/30 ] train step:260  loss: 0.93345 lr: 0.000100 batch_cost: 0.35584 sec, reader_cost: 0.00244 sec, ips: 44.96464 instance/sec.
[03/04 12:00:17] epoch:[ 27/30 ] train step:270  loss: 0.78268 lr: 0.000100 batch_cost: 0.35449 sec, reader_cost: 0.00011 sec, ips: 45.13538 instance/sec.
[03/04 12:00:21] epoch:[ 27/30 ] train step:280  loss: 0.81118 lr: 0.000100 batch_cost: 0.35667 sec, reader_cost: 0.00220 sec, ips: 44.85926 instance/sec.
[03/04 12:00:24] epoch:[ 27/30 ] train step:290  loss: 0.85673 lr: 0.000100 batch_cost: 0.35631 sec, reader_cost: 0.00146 sec, ips: 44.90434 instance/sec.
[03/04 12:00:28] epoch:[ 27/30 ] train step:300  loss: 0.81792 lr: 0.000100 batch_cost: 0.35583 sec, reader_cost: 0.00026 sec, ips: 44.96470 instance/sec.
[03/04 12:00:31] epoch:[ 27/30 ] train step:310  loss: 0.78728 lr: 0.000100 batch_cost: 0.35444 sec, reader_cost: 0.00013 sec, ips: 45.14197 instance/sec.
[03/04 12:00:35] epoch:[ 27/30 ] train step:320  loss: 0.76382 lr: 0.000100 batch_cost: 0.35684 sec, reader_cost: 0.00221 sec, ips: 44.83756 instance/sec.
[03/04 12:00:38] epoch:[ 27/30 ] train step:330  loss: 0.86290 lr: 0.000100 batch_cost: 0.35359 sec, reader_cost: 0.00044 sec, ips: 45.25012 instance/sec.
[03/04 12:00:42] epoch:[ 27/30 ] train step:340  loss: 0.53920 lr: 0.000100 batch_cost: 0.35681 sec, reader_cost: 0.00012 sec, ips: 44.84157 instance/sec.
[03/04 12:00:45] epoch:[ 27/30 ] train step:350  loss: 0.84449 lr: 0.000100 batch_cost: 0.35538 sec, reader_cost: 0.00250 sec, ips: 45.02255 instance/sec.
[03/04 12:00:49] epoch:[ 27/30 ] train step:360  loss: 0.80327 lr: 0.000100 batch_cost: 0.35360 sec, reader_cost: 0.00240 sec, ips: 45.24871 instance/sec.
[03/04 12:00:53] epoch:[ 27/30 ] train step:370  loss: 0.77348 lr: 0.000100 batch_cost: 0.35687 sec, reader_cost: 0.00205 sec, ips: 44.83435 instance/sec.
[03/04 12:00:56] epoch:[ 27/30 ] train step:380  loss: 0.77354 lr: 0.000100 batch_cost: 0.35554 sec, reader_cost: 0.00012 sec, ips: 45.00242 instance/sec.
[03/04 12:01:00] epoch:[ 27/30 ] train step:390  loss: 0.71520 lr: 0.000100 batch_cost: 0.35669 sec, reader_cost: 0.00262 sec, ips: 44.85734 instance/sec.
[03/04 12:01:03] epoch:[ 27/30 ] train step:400  loss: 0.82055 lr: 0.000100 batch_cost: 0.35477 sec, reader_cost: 0.00234 sec, ips: 45.09971 instance/sec.
[03/04 12:01:07] epoch:[ 27/30 ] train step:410  loss: 0.75196 lr: 0.000100 batch_cost: 0.35826 sec, reader_cost: 0.00251 sec, ips: 44.66043 instance/sec.
[03/04 12:01:10] epoch:[ 27/30 ] train step:420  loss: 0.91439 lr: 0.000100 batch_cost: 0.35516 sec, reader_cost: 0.00250 sec, ips: 45.04985 instance/sec.
[03/04 12:01:14] epoch:[ 27/30 ] train step:430  loss: 0.68832 lr: 0.000100 batch_cost: 0.35602 sec, reader_cost: 0.00263 sec, ips: 44.94094 instance/sec.
[03/04 12:01:17] epoch:[ 27/30 ] train step:440  loss: 0.68314 lr: 0.000100 batch_cost: 0.35377 sec, reader_cost: 0.00237 sec, ips: 45.22685 instance/sec.
[03/04 12:01:21] epoch:[ 27/30 ] train step:450  loss: 0.67978 lr: 0.000100 batch_cost: 0.35711 sec, reader_cost: 0.00015 sec, ips: 44.80457 instance/sec.
[03/04 12:01:25] epoch:[ 27/30 ] train step:460  loss: 0.68334 lr: 0.000100 batch_cost: 0.35772 sec, reader_cost: 0.00245 sec, ips: 44.72782 instance/sec.
[03/04 12:01:28] epoch:[ 27/30 ] train step:470  loss: 0.82151 lr: 0.000100 batch_cost: 0.35510 sec, reader_cost: 0.00269 sec, ips: 45.05741 instance/sec.
[03/04 12:01:32] epoch:[ 27/30 ] train step:480  loss: 0.75680 lr: 0.000100 batch_cost: 0.35533 sec, reader_cost: 0.00251 sec, ips: 45.02826 instance/sec.
[03/04 12:01:35] epoch:[ 27/30 ] train step:490  loss: 0.87749 lr: 0.000100 batch_cost: 0.35763 sec, reader_cost: 0.00234 sec, ips: 44.73954 instance/sec.
[03/04 12:01:39] epoch:[ 27/30 ] train step:500  loss: 0.81348 lr: 0.000100 batch_cost: 0.35771 sec, reader_cost: 0.00246 sec, ips: 44.72881 instance/sec.
[03/04 12:01:42] epoch:[ 27/30 ] train step:510  loss: 0.84226 lr: 0.000100 batch_cost: 0.35612 sec, reader_cost: 0.00265 sec, ips: 44.92833 instance/sec.
[03/04 12:01:46] epoch:[ 27/30 ] train step:520  loss: 0.67783 lr: 0.000100 batch_cost: 0.35688 sec, reader_cost: 0.00248 sec, ips: 44.83273 instance/sec.
[03/04 12:01:49] epoch:[ 27/30 ] train step:530  loss: 0.61713 lr: 0.000100 batch_cost: 0.35408 sec, reader_cost: 0.00013 sec, ips: 45.18738 instance/sec.
[03/04 12:01:53] epoch:[ 27/30 ] train step:540  loss: 0.90641 lr: 0.000100 batch_cost: 0.35750 sec, reader_cost: 0.00250 sec, ips: 44.75559 instance/sec.
[03/04 12:01:57] epoch:[ 27/30 ] train step:550  loss: 0.74923 lr: 0.000100 batch_cost: 0.35529 sec, reader_cost: 0.00245 sec, ips: 45.03313 instance/sec.
[03/04 12:02:00] epoch:[ 27/30 ] train step:560  loss: 0.82457 lr: 0.000100 batch_cost: 0.35580 sec, reader_cost: 0.00230 sec, ips: 44.96928 instance/sec.
[03/04 12:02:04] epoch:[ 27/30 ] train step:570  loss: 0.73079 lr: 0.000100 batch_cost: 0.35697 sec, reader_cost: 0.00258 sec, ips: 44.82228 instance/sec.
[03/04 12:02:07] epoch:[ 27/30 ] train step:580  loss: 0.77810 lr: 0.000100 batch_cost: 0.35675 sec, reader_cost: 0.00244 sec, ips: 44.84984 instance/sec.
[03/04 12:02:11] epoch:[ 27/30 ] train step:590  loss: 0.66878 lr: 0.000100 batch_cost: 0.35785 sec, reader_cost: 0.00263 sec, ips: 44.71122 instance/sec.
[03/04 12:02:14] epoch:[ 27/30 ] train step:600  loss: 0.72241 lr: 0.000100 batch_cost: 0.35641 sec, reader_cost: 0.00018 sec, ips: 44.89178 instance/sec.
[03/04 12:02:18] epoch:[ 27/30 ] train step:610  loss: 0.76893 lr: 0.000100 batch_cost: 0.35663 sec, reader_cost: 0.00016 sec, ips: 44.86387 instance/sec.
[03/04 12:02:22] epoch:[ 27/30 ] train step:620  loss: 0.80751 lr: 0.000100 batch_cost: 0.35620 sec, reader_cost: 0.00247 sec, ips: 44.91895 instance/sec.
[03/04 12:02:25] epoch:[ 27/30 ] train step:630  loss: 0.87975 lr: 0.000100 batch_cost: 0.35449 sec, reader_cost: 0.00254 sec, ips: 45.13584 instance/sec.
[03/04 12:02:29] epoch:[ 27/30 ] train step:640  loss: 0.91425 lr: 0.000100 batch_cost: 0.35339 sec, reader_cost: 0.00022 sec, ips: 45.27527 instance/sec.
[03/04 12:02:32] epoch:[ 27/30 ] train step:650  loss: 0.84853 lr: 0.000100 batch_cost: 0.35647 sec, reader_cost: 0.00254 sec, ips: 44.88491 instance/sec.
[03/04 12:02:36] epoch:[ 27/30 ] train step:660  loss: 0.71223 lr: 0.000100 batch_cost: 0.35462 sec, reader_cost: 0.00245 sec, ips: 45.11884 instance/sec.
[03/04 12:02:39] epoch:[ 27/30 ] train step:670  loss: 0.80414 lr: 0.000100 batch_cost: 0.35402 sec, reader_cost: 0.00267 sec, ips: 45.19578 instance/sec.
[03/04 12:02:43] epoch:[ 27/30 ] train step:680  loss: 0.75541 lr: 0.000100 batch_cost: 0.35852 sec, reader_cost: 0.00258 sec, ips: 44.62845 instance/sec.
[03/04 12:02:46] epoch:[ 27/30 ] train step:690  loss: 0.92672 lr: 0.000100 batch_cost: 0.35560 sec, reader_cost: 0.00249 sec, ips: 44.99403 instance/sec.
[03/04 12:02:50] epoch:[ 27/30 ] train step:700  loss: 0.73763 lr: 0.000100 batch_cost: 0.35762 sec, reader_cost: 0.00235 sec, ips: 44.74067 instance/sec.
[03/04 12:02:54] epoch:[ 27/30 ] train step:710  loss: 0.83483 lr: 0.000100 batch_cost: 0.35385 sec, reader_cost: 0.00257 sec, ips: 45.21749 instance/sec.
[03/04 12:02:57] epoch:[ 27/30 ] train step:720  loss: 0.81153 lr: 0.000100 batch_cost: 0.35564 sec, reader_cost: 0.00260 sec, ips: 44.98878 instance/sec.
[03/04 12:03:01] epoch:[ 27/30 ] train step:730  loss: 0.75902 lr: 0.000100 batch_cost: 0.35481 sec, reader_cost: 0.00018 sec, ips: 45.09516 instance/sec.
[03/04 12:03:04] epoch:[ 27/30 ] train step:740  loss: 0.76332 lr: 0.000100 batch_cost: 0.35622 sec, reader_cost: 0.00236 sec, ips: 44.91591 instance/sec.
[03/04 12:03:08] epoch:[ 27/30 ] train step:750  loss: 0.62998 lr: 0.000100 batch_cost: 0.35778 sec, reader_cost: 0.00260 sec, ips: 44.72007 instance/sec.
[03/04 12:03:11] epoch:[ 27/30 ] train step:760  loss: 0.84970 lr: 0.000100 batch_cost: 0.35662 sec, reader_cost: 0.00253 sec, ips: 44.86600 instance/sec.
[03/04 12:03:15] epoch:[ 27/30 ] train step:770  loss: 0.68616 lr: 0.000100 batch_cost: 0.35917 sec, reader_cost: 0.00265 sec, ips: 44.54710 instance/sec.
[03/04 12:03:19] epoch:[ 27/30 ] train step:780  loss: 0.69300 lr: 0.000100 batch_cost: 0.35229 sec, reader_cost: 0.00008 sec, ips: 45.41702 instance/sec.
[03/04 12:03:21] END epoch:27  train loss_avg: 0.76656  avg_batch_cost: 0.35180 sec, avg_reader_cost: 0.00005 sec, batch_cost_sum: 281.05020 sec, avg_ips: 44.80338 instance/sec.
[03/04 12:03:22] epoch:[ 28/30 ] train step:0    loss: 0.70948 lr: 0.000100 batch_cost: 1.29393 sec, reader_cost: 0.92486 sec, ips: 12.36544 instance/sec.
[03/04 12:03:26] epoch:[ 28/30 ] train step:10   loss: 0.84055 lr: 0.000100 batch_cost: 0.35943 sec, reader_cost: 0.00226 sec, ips: 44.51527 instance/sec.
[03/04 12:03:29] epoch:[ 28/30 ] train step:20   loss: 0.78079 lr: 0.000100 batch_cost: 0.35726 sec, reader_cost: 0.00236 sec, ips: 44.78504 instance/sec.
[03/04 12:03:33] epoch:[ 28/30 ] train step:30   loss: 0.86282 lr: 0.000100 batch_cost: 0.35604 sec, reader_cost: 0.00022 sec, ips: 44.93910 instance/sec.
[03/04 12:03:37] epoch:[ 28/30 ] train step:40   loss: 0.80706 lr: 0.000100 batch_cost: 0.35946 sec, reader_cost: 0.00231 sec, ips: 44.51087 instance/sec.
[03/04 12:03:40] epoch:[ 28/30 ] train step:50   loss: 0.59552 lr: 0.000100 batch_cost: 0.35649 sec, reader_cost: 0.00015 sec, ips: 44.88170 instance/sec.
[03/04 12:03:44] epoch:[ 28/30 ] train step:60   loss: 0.87557 lr: 0.000100 batch_cost: 0.35766 sec, reader_cost: 0.00014 sec, ips: 44.73566 instance/sec.
[03/04 12:03:47] epoch:[ 28/30 ] train step:70   loss: 0.69638 lr: 0.000100 batch_cost: 0.35754 sec, reader_cost: 0.00238 sec, ips: 44.74971 instance/sec.
[03/04 12:03:51] epoch:[ 28/30 ] train step:80   loss: 0.75388 lr: 0.000100 batch_cost: 0.35719 sec, reader_cost: 0.00258 sec, ips: 44.79434 instance/sec.
[03/04 12:03:54] epoch:[ 28/30 ] train step:90   loss: 0.72388 lr: 0.000100 batch_cost: 0.35707 sec, reader_cost: 0.00232 sec, ips: 44.80938 instance/sec.
[03/04 12:03:58] epoch:[ 28/30 ] train step:100  loss: 0.77232 lr: 0.000100 batch_cost: 0.35730 sec, reader_cost: 0.00221 sec, ips: 44.77990 instance/sec.
[03/04 12:04:02] epoch:[ 28/30 ] train step:110  loss: 0.79913 lr: 0.000100 batch_cost: 0.36030 sec, reader_cost: 0.00231 sec, ips: 44.40705 instance/sec.
[03/04 12:04:05] epoch:[ 28/30 ] train step:120  loss: 0.81785 lr: 0.000100 batch_cost: 0.35375 sec, reader_cost: 0.00028 sec, ips: 45.22965 instance/sec.
[03/04 12:04:09] epoch:[ 28/30 ] train step:130  loss: 0.77438 lr: 0.000100 batch_cost: 0.35939 sec, reader_cost: 0.00230 sec, ips: 44.51970 instance/sec.
[03/04 12:04:12] epoch:[ 28/30 ] train step:140  loss: 0.76542 lr: 0.000100 batch_cost: 0.35753 sec, reader_cost: 0.00219 sec, ips: 44.75127 instance/sec.
[03/04 12:04:16] epoch:[ 28/30 ] train step:150  loss: 0.73556 lr: 0.000100 batch_cost: 0.35651 sec, reader_cost: 0.00230 sec, ips: 44.87891 instance/sec.
[03/04 12:04:19] epoch:[ 28/30 ] train step:160  loss: 0.82273 lr: 0.000100 batch_cost: 0.35704 sec, reader_cost: 0.00227 sec, ips: 44.81235 instance/sec.
[03/04 12:04:23] epoch:[ 28/30 ] train step:170  loss: 0.70299 lr: 0.000100 batch_cost: 0.35485 sec, reader_cost: 0.00013 sec, ips: 45.08980 instance/sec.
[03/04 12:04:26] epoch:[ 28/30 ] train step:180  loss: 0.75486 lr: 0.000100 batch_cost: 0.35959 sec, reader_cost: 0.00227 sec, ips: 44.49505 instance/sec.
[03/04 12:04:30] epoch:[ 28/30 ] train step:190  loss: 0.81302 lr: 0.000100 batch_cost: 0.35723 sec, reader_cost: 0.00241 sec, ips: 44.78875 instance/sec.
[03/04 12:04:34] epoch:[ 28/30 ] train step:200  loss: 0.82976 lr: 0.000100 batch_cost: 0.35649 sec, reader_cost: 0.00012 sec, ips: 44.88164 instance/sec.
[03/04 12:04:37] epoch:[ 28/30 ] train step:210  loss: 0.78430 lr: 0.000100 batch_cost: 0.35809 sec, reader_cost: 0.00232 sec, ips: 44.68122 instance/sec.
[03/04 12:04:41] epoch:[ 28/30 ] train step:220  loss: 0.75103 lr: 0.000100 batch_cost: 0.35622 sec, reader_cost: 0.00236 sec, ips: 44.91609 instance/sec.
[03/04 12:04:44] epoch:[ 28/30 ] train step:230  loss: 0.65345 lr: 0.000100 batch_cost: 0.35847 sec, reader_cost: 0.00019 sec, ips: 44.63400 instance/sec.
[03/04 12:04:48] epoch:[ 28/30 ] train step:240  loss: 0.72035 lr: 0.000100 batch_cost: 0.35664 sec, reader_cost: 0.00238 sec, ips: 44.86267 instance/sec.
[03/04 12:04:52] epoch:[ 28/30 ] train step:250  loss: 1.01396 lr: 0.000100 batch_cost: 0.35667 sec, reader_cost: 0.00016 sec, ips: 44.85992 instance/sec.
[03/04 12:04:55] epoch:[ 28/30 ] train step:260  loss: 0.73850 lr: 0.000100 batch_cost: 0.35833 sec, reader_cost: 0.00226 sec, ips: 44.65217 instance/sec.
[03/04 12:04:59] epoch:[ 28/30 ] train step:270  loss: 0.84491 lr: 0.000100 batch_cost: 0.35714 sec, reader_cost: 0.00247 sec, ips: 44.80005 instance/sec.
[03/04 12:05:02] epoch:[ 28/30 ] train step:280  loss: 0.78780 lr: 0.000100 batch_cost: 0.35990 sec, reader_cost: 0.00241 sec, ips: 44.45662 instance/sec.
[03/04 12:05:06] epoch:[ 28/30 ] train step:290  loss: 0.65294 lr: 0.000100 batch_cost: 0.35674 sec, reader_cost: 0.00235 sec, ips: 44.85005 instance/sec.
[03/04 12:05:09] epoch:[ 28/30 ] train step:300  loss: 0.79980 lr: 0.000100 batch_cost: 0.35754 sec, reader_cost: 0.00225 sec, ips: 44.75001 instance/sec.
[03/04 12:05:13] epoch:[ 28/30 ] train step:310  loss: 0.78076 lr: 0.000100 batch_cost: 0.35629 sec, reader_cost: 0.00223 sec, ips: 44.90714 instance/sec.
[03/04 12:05:17] epoch:[ 28/30 ] train step:320  loss: 0.78693 lr: 0.000100 batch_cost: 0.35661 sec, reader_cost: 0.00247 sec, ips: 44.86672 instance/sec.
[03/04 12:05:20] epoch:[ 28/30 ] train step:330  loss: 0.78637 lr: 0.000100 batch_cost: 0.36022 sec, reader_cost: 0.00250 sec, ips: 44.41678 instance/sec.
[03/04 12:05:24] epoch:[ 28/30 ] train step:340  loss: 0.90191 lr: 0.000100 batch_cost: 0.35662 sec, reader_cost: 0.00016 sec, ips: 44.86528 instance/sec.
[03/04 12:05:27] epoch:[ 28/30 ] train step:350  loss: 0.78699 lr: 0.000100 batch_cost: 0.35696 sec, reader_cost: 0.00217 sec, ips: 44.82354 instance/sec.
[03/04 12:05:31] epoch:[ 28/30 ] train step:360  loss: 0.83283 lr: 0.000100 batch_cost: 0.35766 sec, reader_cost: 0.00230 sec, ips: 44.73537 instance/sec.
[03/04 12:05:34] epoch:[ 28/30 ] train step:370  loss: 0.78676 lr: 0.000100 batch_cost: 0.35841 sec, reader_cost: 0.00225 sec, ips: 44.64207 instance/sec.
[03/04 12:05:38] epoch:[ 28/30 ] train step:380  loss: 0.70380 lr: 0.000100 batch_cost: 0.35913 sec, reader_cost: 0.00230 sec, ips: 44.55165 instance/sec.
[03/04 12:05:42] epoch:[ 28/30 ] train step:390  loss: 0.73774 lr: 0.000100 batch_cost: 0.35641 sec, reader_cost: 0.00015 sec, ips: 44.89151 instance/sec.
[03/04 12:05:45] epoch:[ 28/30 ] train step:400  loss: 0.75090 lr: 0.000100 batch_cost: 0.35820 sec, reader_cost: 0.00016 sec, ips: 44.66807 instance/sec.
[03/04 12:05:49] epoch:[ 28/30 ] train step:410  loss: 0.86469 lr: 0.000100 batch_cost: 0.35643 sec, reader_cost: 0.00220 sec, ips: 44.88902 instance/sec.
[03/04 12:05:52] epoch:[ 28/30 ] train step:420  loss: 0.67872 lr: 0.000100 batch_cost: 0.35713 sec, reader_cost: 0.00016 sec, ips: 44.80220 instance/sec.
[03/04 12:05:56] epoch:[ 28/30 ] train step:430  loss: 0.71427 lr: 0.000100 batch_cost: 0.35617 sec, reader_cost: 0.00018 sec, ips: 44.92196 instance/sec.
[03/04 12:05:59] epoch:[ 28/30 ] train step:440  loss: 0.68612 lr: 0.000100 batch_cost: 0.35644 sec, reader_cost: 0.00245 sec, ips: 44.88791 instance/sec.
[03/04 12:06:03] epoch:[ 28/30 ] train step:450  loss: 0.73017 lr: 0.000100 batch_cost: 0.35689 sec, reader_cost: 0.00015 sec, ips: 44.83207 instance/sec.
[03/04 12:06:07] epoch:[ 28/30 ] train step:460  loss: 0.78335 lr: 0.000100 batch_cost: 0.35583 sec, reader_cost: 0.00016 sec, ips: 44.96584 instance/sec.
[03/04 12:06:10] epoch:[ 28/30 ] train step:470  loss: 0.69167 lr: 0.000100 batch_cost: 0.35588 sec, reader_cost: 0.00017 sec, ips: 44.95936 instance/sec.
[03/04 12:06:14] epoch:[ 28/30 ] train step:480  loss: 0.65390 lr: 0.000100 batch_cost: 0.35828 sec, reader_cost: 0.00016 sec, ips: 44.65767 instance/sec.
[03/04 12:06:17] epoch:[ 28/30 ] train step:490  loss: 0.82478 lr: 0.000100 batch_cost: 0.35625 sec, reader_cost: 0.00231 sec, ips: 44.91212 instance/sec.
[03/04 12:06:21] epoch:[ 28/30 ] train step:500  loss: 0.74248 lr: 0.000100 batch_cost: 0.35832 sec, reader_cost: 0.00236 sec, ips: 44.65268 instance/sec.
[03/04 12:06:24] epoch:[ 28/30 ] train step:510  loss: 0.95794 lr: 0.000100 batch_cost: 0.35530 sec, reader_cost: 0.00017 sec, ips: 45.03255 instance/sec.
[03/04 12:06:28] epoch:[ 28/30 ] train step:520  loss: 0.66654 lr: 0.000100 batch_cost: 0.35921 sec, reader_cost: 0.00262 sec, ips: 44.54207 instance/sec.
[03/04 12:06:32] epoch:[ 28/30 ] train step:530  loss: 1.14037 lr: 0.000100 batch_cost: 0.35836 sec, reader_cost: 0.00286 sec, ips: 44.64774 instance/sec.
[03/04 12:06:35] epoch:[ 28/30 ] train step:540  loss: 1.07987 lr: 0.000100 batch_cost: 0.35604 sec, reader_cost: 0.00252 sec, ips: 44.93907 instance/sec.
[03/04 12:06:39] epoch:[ 28/30 ] train step:550  loss: 0.73072 lr: 0.000100 batch_cost: 0.35930 sec, reader_cost: 0.00326 sec, ips: 44.53060 instance/sec.
[03/04 12:06:42] epoch:[ 28/30 ] train step:560  loss: 0.66924 lr: 0.000100 batch_cost: 0.36878 sec, reader_cost: 0.00290 sec, ips: 43.38643 instance/sec.
[03/04 12:06:46] epoch:[ 28/30 ] train step:570  loss: 0.75562 lr: 0.000100 batch_cost: 0.35333 sec, reader_cost: 0.00022 sec, ips: 45.28401 instance/sec.
[03/04 12:06:50] epoch:[ 28/30 ] train step:580  loss: 0.60809 lr: 0.000100 batch_cost: 0.36287 sec, reader_cost: 0.00038 sec, ips: 44.09345 instance/sec.
[03/04 12:06:53] epoch:[ 28/30 ] train step:590  loss: 0.66454 lr: 0.000100 batch_cost: 0.35554 sec, reader_cost: 0.00244 sec, ips: 45.00251 instance/sec.
[03/04 12:06:57] epoch:[ 28/30 ] train step:600  loss: 0.69977 lr: 0.000100 batch_cost: 0.35598 sec, reader_cost: 0.00244 sec, ips: 44.94620 instance/sec.
[03/04 12:07:00] epoch:[ 28/30 ] train step:610  loss: 0.77609 lr: 0.000100 batch_cost: 0.36781 sec, reader_cost: 0.00241 sec, ips: 43.50120 instance/sec.
[03/04 12:07:04] epoch:[ 28/30 ] train step:620  loss: 0.96938 lr: 0.000100 batch_cost: 0.35742 sec, reader_cost: 0.00266 sec, ips: 44.76518 instance/sec.
[03/04 12:07:07] epoch:[ 28/30 ] train step:630  loss: 0.74554 lr: 0.000100 batch_cost: 0.35640 sec, reader_cost: 0.00016 sec, ips: 44.89383 instance/sec.
[03/04 12:07:11] epoch:[ 28/30 ] train step:640  loss: 0.81779 lr: 0.000100 batch_cost: 0.35749 sec, reader_cost: 0.00248 sec, ips: 44.75679 instance/sec.
[03/04 12:07:15] epoch:[ 28/30 ] train step:650  loss: 0.79304 lr: 0.000100 batch_cost: 0.35605 sec, reader_cost: 0.00232 sec, ips: 44.93799 instance/sec.
[03/04 12:07:18] epoch:[ 28/30 ] train step:660  loss: 0.67372 lr: 0.000100 batch_cost: 0.35717 sec, reader_cost: 0.00246 sec, ips: 44.79598 instance/sec.
[03/04 12:07:22] epoch:[ 28/30 ] train step:670  loss: 0.71715 lr: 0.000100 batch_cost: 0.35907 sec, reader_cost: 0.00246 sec, ips: 44.55916 instance/sec.
[03/04 12:07:25] epoch:[ 28/30 ] train step:680  loss: 0.94936 lr: 0.000100 batch_cost: 0.35643 sec, reader_cost: 0.00263 sec, ips: 44.88989 instance/sec.
[03/04 12:07:29] epoch:[ 28/30 ] train step:690  loss: 0.89686 lr: 0.000100 batch_cost: 0.35872 sec, reader_cost: 0.00222 sec, ips: 44.60249 instance/sec.
[03/04 12:07:33] epoch:[ 28/30 ] train step:700  loss: 0.78762 lr: 0.000100 batch_cost: 0.35873 sec, reader_cost: 0.00236 sec, ips: 44.60119 instance/sec.
[03/04 12:07:36] epoch:[ 28/30 ] train step:710  loss: 0.72251 lr: 0.000100 batch_cost: 0.35529 sec, reader_cost: 0.00023 sec, ips: 45.03343 instance/sec.
[03/04 12:07:40] epoch:[ 28/30 ] train step:720  loss: 0.54284 lr: 0.000100 batch_cost: 0.35731 sec, reader_cost: 0.00249 sec, ips: 44.77925 instance/sec.
[03/04 12:07:43] epoch:[ 28/30 ] train step:730  loss: 0.77831 lr: 0.000100 batch_cost: 0.35586 sec, reader_cost: 0.00265 sec, ips: 44.96108 instance/sec.
[03/04 12:07:47] epoch:[ 28/30 ] train step:740  loss: 0.82365 lr: 0.000100 batch_cost: 0.36175 sec, reader_cost: 0.00253 sec, ips: 44.22937 instance/sec.
[03/04 12:07:50] epoch:[ 28/30 ] train step:750  loss: 0.65048 lr: 0.000100 batch_cost: 0.35716 sec, reader_cost: 0.00243 sec, ips: 44.79751 instance/sec.
[03/04 12:07:54] epoch:[ 28/30 ] train step:760  loss: 0.61196 lr: 0.000100 batch_cost: 0.35625 sec, reader_cost: 0.00246 sec, ips: 44.91179 instance/sec.
[03/04 12:07:58] epoch:[ 28/30 ] train step:770  loss: 0.73389 lr: 0.000100 batch_cost: 0.35773 sec, reader_cost: 0.00014 sec, ips: 44.72705 instance/sec.
[03/04 12:08:01] epoch:[ 28/30 ] train step:780  loss: 0.71767 lr: 0.000100 batch_cost: 0.35531 sec, reader_cost: 0.00007 sec, ips: 45.03147 instance/sec.
[03/04 12:08:03] END epoch:28  train loss_avg: 0.76307  avg_batch_cost: 0.35786 sec, avg_reader_cost: 0.00013 sec, batch_cost_sum: 282.34456 sec, avg_ips: 44.59799 instance/sec.
[03/04 12:08:05] epoch:[ 29/30 ] train step:0    loss: 0.67688 lr: 0.000100 batch_cost: 1.27409 sec, reader_cost: 0.89918 sec, ips: 12.55794 instance/sec.
[03/04 12:08:08] epoch:[ 29/30 ] train step:10   loss: 0.79629 lr: 0.000100 batch_cost: 0.36088 sec, reader_cost: 0.00230 sec, ips: 44.33643 instance/sec.
[03/04 12:08:12] epoch:[ 29/30 ] train step:20   loss: 0.78614 lr: 0.000100 batch_cost: 0.35563 sec, reader_cost: 0.00238 sec, ips: 44.99110 instance/sec.
[03/04 12:08:16] epoch:[ 29/30 ] train step:30   loss: 0.59095 lr: 0.000100 batch_cost: 0.35437 sec, reader_cost: 0.00009 sec, ips: 45.15014 instance/sec.
[03/04 12:08:19] epoch:[ 29/30 ] train step:40   loss: 0.71451 lr: 0.000100 batch_cost: 0.35659 sec, reader_cost: 0.00012 sec, ips: 44.86915 instance/sec.
[03/04 12:08:23] epoch:[ 29/30 ] train step:50   loss: 0.69799 lr: 0.000100 batch_cost: 0.35745 sec, reader_cost: 0.00217 sec, ips: 44.76115 instance/sec.
[03/04 12:08:26] epoch:[ 29/30 ] train step:60   loss: 0.68175 lr: 0.000100 batch_cost: 0.35662 sec, reader_cost: 0.00022 sec, ips: 44.86570 instance/sec.
[03/04 12:08:30] epoch:[ 29/30 ] train step:70   loss: 0.80899 lr: 0.000100 batch_cost: 0.35442 sec, reader_cost: 0.00015 sec, ips: 45.14431 instance/sec.
[03/04 12:08:33] epoch:[ 29/30 ] train step:80   loss: 0.78979 lr: 0.000100 batch_cost: 0.35363 sec, reader_cost: 0.00010 sec, ips: 45.24520 instance/sec.
[03/04 12:08:37] epoch:[ 29/30 ] train step:90   loss: 0.81085 lr: 0.000100 batch_cost: 0.35822 sec, reader_cost: 0.00229 sec, ips: 44.66492 instance/sec.
[03/04 12:08:41] epoch:[ 29/30 ] train step:100  loss: 0.72468 lr: 0.000100 batch_cost: 0.35802 sec, reader_cost: 0.00238 sec, ips: 44.69041 instance/sec.
[03/04 12:08:44] epoch:[ 29/30 ] train step:110  loss: 0.68642 lr: 0.000100 batch_cost: 0.36039 sec, reader_cost: 0.00233 sec, ips: 44.39635 instance/sec.
[03/04 12:08:48] epoch:[ 29/30 ] train step:120  loss: 0.95402 lr: 0.000100 batch_cost: 0.35545 sec, reader_cost: 0.00013 sec, ips: 45.01277 instance/sec.
[03/04 12:08:51] epoch:[ 29/30 ] train step:130  loss: 0.73100 lr: 0.000100 batch_cost: 0.35948 sec, reader_cost: 0.00224 sec, ips: 44.50901 instance/sec.
[03/04 12:08:55] epoch:[ 29/30 ] train step:140  loss: 0.80270 lr: 0.000100 batch_cost: 0.35735 sec, reader_cost: 0.00237 sec, ips: 44.77441 instance/sec.
[03/04 12:08:58] epoch:[ 29/30 ] train step:150  loss: 0.76434 lr: 0.000100 batch_cost: 0.35514 sec, reader_cost: 0.00012 sec, ips: 45.05314 instance/sec.
[03/04 12:09:02] epoch:[ 29/30 ] train step:160  loss: 0.71759 lr: 0.000100 batch_cost: 0.35757 sec, reader_cost: 0.00239 sec, ips: 44.74646 instance/sec.
[03/04 12:09:06] epoch:[ 29/30 ] train step:170  loss: 0.67341 lr: 0.000100 batch_cost: 0.35582 sec, reader_cost: 0.00231 sec, ips: 44.96650 instance/sec.
[03/04 12:09:09] epoch:[ 29/30 ] train step:180  loss: 0.74412 lr: 0.000100 batch_cost: 0.36004 sec, reader_cost: 0.00262 sec, ips: 44.43919 instance/sec.
[03/04 12:09:13] epoch:[ 29/30 ] train step:190  loss: 0.83773 lr: 0.000100 batch_cost: 0.35680 sec, reader_cost: 0.00012 sec, ips: 44.84304 instance/sec.
[03/04 12:09:16] epoch:[ 29/30 ] train step:200  loss: 0.99073 lr: 0.000100 batch_cost: 0.35665 sec, reader_cost: 0.00238 sec, ips: 44.86211 instance/sec.
[03/04 12:09:20] epoch:[ 29/30 ] train step:210  loss: 0.75079 lr: 0.000100 batch_cost: 0.35859 sec, reader_cost: 0.00245 sec, ips: 44.61972 instance/sec.
[03/04 12:09:23] epoch:[ 29/30 ] train step:220  loss: 0.74957 lr: 0.000100 batch_cost: 0.35736 sec, reader_cost: 0.00256 sec, ips: 44.77333 instance/sec.
[03/04 12:09:27] epoch:[ 29/30 ] train step:230  loss: 0.69470 lr: 0.000100 batch_cost: 0.36051 sec, reader_cost: 0.00012 sec, ips: 44.38150 instance/sec.
[03/04 12:09:31] epoch:[ 29/30 ] train step:240  loss: 0.67272 lr: 0.000100 batch_cost: 0.35823 sec, reader_cost: 0.00234 sec, ips: 44.66400 instance/sec.
[03/04 12:09:34] epoch:[ 29/30 ] train step:250  loss: 0.93856 lr: 0.000100 batch_cost: 0.35997 sec, reader_cost: 0.00234 sec, ips: 44.44802 instance/sec.
[03/04 12:09:38] epoch:[ 29/30 ] train step:260  loss: 0.68446 lr: 0.000100 batch_cost: 0.35862 sec, reader_cost: 0.00017 sec, ips: 44.61515 instance/sec.
[03/04 12:09:41] epoch:[ 29/30 ] train step:270  loss: 0.81072 lr: 0.000100 batch_cost: 0.35935 sec, reader_cost: 0.00231 sec, ips: 44.52496 instance/sec.
[03/04 12:09:45] epoch:[ 29/30 ] train step:280  loss: 0.82152 lr: 0.000100 batch_cost: 0.36168 sec, reader_cost: 0.00264 sec, ips: 44.23840 instance/sec.
[03/04 12:09:48] epoch:[ 29/30 ] train step:290  loss: 0.79390 lr: 0.000100 batch_cost: 0.36124 sec, reader_cost: 0.00251 sec, ips: 44.29172 instance/sec.
[03/04 12:09:52] epoch:[ 29/30 ] train step:300  loss: 0.65170 lr: 0.000100 batch_cost: 0.36065 sec, reader_cost: 0.00030 sec, ips: 44.36463 instance/sec.
[03/04 12:09:56] epoch:[ 29/30 ] train step:310  loss: 0.70671 lr: 0.000100 batch_cost: 0.35802 sec, reader_cost: 0.00015 sec, ips: 44.69017 instance/sec.
[03/04 12:09:59] epoch:[ 29/30 ] train step:320  loss: 0.68417 lr: 0.000100 batch_cost: 0.35422 sec, reader_cost: 0.00010 sec, ips: 45.16977 instance/sec.
[03/04 12:10:03] epoch:[ 29/30 ] train step:330  loss: 0.70645 lr: 0.000100 batch_cost: 0.36039 sec, reader_cost: 0.00231 sec, ips: 44.39600 instance/sec.
[03/04 12:10:06] epoch:[ 29/30 ] train step:340  loss: 0.86059 lr: 0.000100 batch_cost: 0.35616 sec, reader_cost: 0.00019 sec, ips: 44.92376 instance/sec.
[03/04 12:10:10] epoch:[ 29/30 ] train step:350  loss: 0.75808 lr: 0.000100 batch_cost: 0.35657 sec, reader_cost: 0.00015 sec, ips: 44.87233 instance/sec.
[03/04 12:10:14] epoch:[ 29/30 ] train step:360  loss: 0.71099 lr: 0.000100 batch_cost: 0.36025 sec, reader_cost: 0.00252 sec, ips: 44.41334 instance/sec.
[03/04 12:10:17] epoch:[ 29/30 ] train step:370  loss: 0.79567 lr: 0.000100 batch_cost: 0.35748 sec, reader_cost: 0.00232 sec, ips: 44.75744 instance/sec.
[03/04 12:10:21] epoch:[ 29/30 ] train step:380  loss: 0.77005 lr: 0.000100 batch_cost: 0.35509 sec, reader_cost: 0.00011 sec, ips: 45.05847 instance/sec.
[03/04 12:10:24] epoch:[ 29/30 ] train step:390  loss: 0.70486 lr: 0.000100 batch_cost: 0.35720 sec, reader_cost: 0.00246 sec, ips: 44.79302 instance/sec.
[03/04 12:10:28] epoch:[ 29/30 ] train step:400  loss: 0.67078 lr: 0.000100 batch_cost: 0.35799 sec, reader_cost: 0.00265 sec, ips: 44.69377 instance/sec.
[03/04 12:10:31] epoch:[ 29/30 ] train step:410  loss: 0.83944 lr: 0.000100 batch_cost: 0.35925 sec, reader_cost: 0.00038 sec, ips: 44.53737 instance/sec.
[03/04 12:10:35] epoch:[ 29/30 ] train step:420  loss: 0.78266 lr: 0.000100 batch_cost: 0.35591 sec, reader_cost: 0.00019 sec, ips: 44.95461 instance/sec.
[03/04 12:10:39] epoch:[ 29/30 ] train step:430  loss: 0.83343 lr: 0.000100 batch_cost: 0.35737 sec, reader_cost: 0.00021 sec, ips: 44.77199 instance/sec.
[03/04 12:10:42] epoch:[ 29/30 ] train step:440  loss: 0.71277 lr: 0.000100 batch_cost: 0.35817 sec, reader_cost: 0.00265 sec, ips: 44.67110 instance/sec.
[03/04 12:10:46] epoch:[ 29/30 ] train step:450  loss: 0.91458 lr: 0.000100 batch_cost: 0.35911 sec, reader_cost: 0.00260 sec, ips: 44.55514 instance/sec.
[03/04 12:10:49] epoch:[ 29/30 ] train step:460  loss: 0.83351 lr: 0.000100 batch_cost: 0.35845 sec, reader_cost: 0.00010 sec, ips: 44.63649 instance/sec.
[03/04 12:10:53] epoch:[ 29/30 ] train step:470  loss: 0.68120 lr: 0.000100 batch_cost: 0.35668 sec, reader_cost: 0.00222 sec, ips: 44.85824 instance/sec.
[03/04 12:10:57] epoch:[ 29/30 ] train step:480  loss: 0.74352 lr: 0.000100 batch_cost: 0.35858 sec, reader_cost: 0.00252 sec, ips: 44.62079 instance/sec.
[03/04 12:11:00] epoch:[ 29/30 ] train step:490  loss: 1.00527 lr: 0.000100 batch_cost: 0.36044 sec, reader_cost: 0.00238 sec, ips: 44.39060 instance/sec.
[03/04 12:11:04] epoch:[ 29/30 ] train step:500  loss: 0.80312 lr: 0.000100 batch_cost: 0.35515 sec, reader_cost: 0.00256 sec, ips: 45.05175 instance/sec.
[03/04 12:11:07] epoch:[ 29/30 ] train step:510  loss: 0.70753 lr: 0.000100 batch_cost: 0.35453 sec, reader_cost: 0.00026 sec, ips: 45.13019 instance/sec.
[03/04 12:11:11] epoch:[ 29/30 ] train step:520  loss: 0.68759 lr: 0.000100 batch_cost: 0.35731 sec, reader_cost: 0.00013 sec, ips: 44.77853 instance/sec.
[03/04 12:11:14] epoch:[ 29/30 ] train step:530  loss: 0.66161 lr: 0.000100 batch_cost: 0.35974 sec, reader_cost: 0.00242 sec, ips: 44.47692 instance/sec.
[03/04 12:11:18] epoch:[ 29/30 ] train step:540  loss: 0.64212 lr: 0.000100 batch_cost: 0.35763 sec, reader_cost: 0.00014 sec, ips: 44.73877 instance/sec.
[03/04 12:11:22] epoch:[ 29/30 ] train step:550  loss: 0.71146 lr: 0.000100 batch_cost: 0.35581 sec, reader_cost: 0.00233 sec, ips: 44.96741 instance/sec.
[03/04 12:11:25] epoch:[ 29/30 ] train step:560  loss: 0.64879 lr: 0.000100 batch_cost: 0.35755 sec, reader_cost: 0.00262 sec, ips: 44.74879 instance/sec.
[03/04 12:11:29] epoch:[ 29/30 ] train step:570  loss: 0.67119 lr: 0.000100 batch_cost: 0.35652 sec, reader_cost: 0.00245 sec, ips: 44.87804 instance/sec.
[03/04 12:11:32] epoch:[ 29/30 ] train step:580  loss: 0.65769 lr: 0.000100 batch_cost: 0.35817 sec, reader_cost: 0.00171 sec, ips: 44.67191 instance/sec.
[03/04 12:11:36] epoch:[ 29/30 ] train step:590  loss: 0.59408 lr: 0.000100 batch_cost: 0.35874 sec, reader_cost: 0.00243 sec, ips: 44.60086 instance/sec.
[03/04 12:11:39] epoch:[ 29/30 ] train step:600  loss: 0.71537 lr: 0.000100 batch_cost: 0.35529 sec, reader_cost: 0.00024 sec, ips: 45.03425 instance/sec.
[03/04 12:11:43] epoch:[ 29/30 ] train step:610  loss: 0.58379 lr: 0.000100 batch_cost: 0.35963 sec, reader_cost: 0.00250 sec, ips: 44.49045 instance/sec.
[03/04 12:11:47] epoch:[ 29/30 ] train step:620  loss: 0.74553 lr: 0.000100 batch_cost: 0.35455 sec, reader_cost: 0.00025 sec, ips: 45.12785 instance/sec.
[03/04 12:11:50] epoch:[ 29/30 ] train step:630  loss: 0.75741 lr: 0.000100 batch_cost: 0.35801 sec, reader_cost: 0.00248 sec, ips: 44.69157 instance/sec.
[03/04 12:11:54] epoch:[ 29/30 ] train step:640  loss: 0.79629 lr: 0.000100 batch_cost: 0.35972 sec, reader_cost: 0.00272 sec, ips: 44.47886 instance/sec.
[03/04 12:11:57] epoch:[ 29/30 ] train step:650  loss: 0.79060 lr: 0.000100 batch_cost: 0.35942 sec, reader_cost: 0.00248 sec, ips: 44.51580 instance/sec.
[03/04 12:12:01] epoch:[ 29/30 ] train step:660  loss: 0.77860 lr: 0.000100 batch_cost: 0.35730 sec, reader_cost: 0.00255 sec, ips: 44.78074 instance/sec.
[03/04 12:12:04] epoch:[ 29/30 ] train step:670  loss: 0.66647 lr: 0.000100 batch_cost: 0.35620 sec, reader_cost: 0.00243 sec, ips: 44.91823 instance/sec.
[03/04 12:12:08] epoch:[ 29/30 ] train step:680  loss: 0.75622 lr: 0.000100 batch_cost: 0.35865 sec, reader_cost: 0.00255 sec, ips: 44.61130 instance/sec.
[03/04 12:12:12] epoch:[ 29/30 ] train step:690  loss: 0.78351 lr: 0.000100 batch_cost: 0.35917 sec, reader_cost: 0.00249 sec, ips: 44.54668 instance/sec.
[03/04 12:12:15] epoch:[ 29/30 ] train step:700  loss: 0.69831 lr: 0.000100 batch_cost: 0.35839 sec, reader_cost: 0.00283 sec, ips: 44.64454 instance/sec.
[03/04 12:12:19] epoch:[ 29/30 ] train step:710  loss: 0.73881 lr: 0.000100 batch_cost: 0.35563 sec, reader_cost: 0.00015 sec, ips: 44.99068 instance/sec.
[03/04 12:12:22] epoch:[ 29/30 ] train step:720  loss: 1.10140 lr: 0.000100 batch_cost: 0.35841 sec, reader_cost: 0.00273 sec, ips: 44.64106 instance/sec.
[03/04 12:12:26] epoch:[ 29/30 ] train step:730  loss: 0.84364 lr: 0.000100 batch_cost: 0.36073 sec, reader_cost: 0.00266 sec, ips: 44.35413 instance/sec.
[03/04 12:12:30] epoch:[ 29/30 ] train step:740  loss: 0.78464 lr: 0.000100 batch_cost: 0.35969 sec, reader_cost: 0.00254 sec, ips: 44.48334 instance/sec.
[03/04 12:12:33] epoch:[ 29/30 ] train step:750  loss: 0.87510 lr: 0.000100 batch_cost: 0.35870 sec, reader_cost: 0.00243 sec, ips: 44.60596 instance/sec.
[03/04 12:12:37] epoch:[ 29/30 ] train step:760  loss: 0.79054 lr: 0.000100 batch_cost: 0.35771 sec, reader_cost: 0.00269 sec, ips: 44.72884 instance/sec.
[03/04 12:12:40] epoch:[ 29/30 ] train step:770  loss: 0.65422 lr: 0.000100 batch_cost: 0.35970 sec, reader_cost: 0.00246 sec, ips: 44.48119 instance/sec.
[03/04 12:12:44] epoch:[ 29/30 ] train step:780  loss: 0.80170 lr: 0.000100 batch_cost: 0.35525 sec, reader_cost: 0.00010 sec, ips: 45.03932 instance/sec.
[03/04 12:12:46] END epoch:29  train loss_avg: 0.76065  avg_batch_cost: 0.35395 sec, avg_reader_cost: 0.00008 sec, batch_cost_sum: 282.30917 sec, avg_ips: 44.60358 instance/sec.
[03/04 12:12:47] epoch:[ 30/30 ] train step:0    loss: 0.64760 lr: 0.000100 batch_cost: 1.14338 sec, reader_cost: 0.77522 sec, ips: 13.99356 instance/sec.
[03/04 12:12:51] epoch:[ 30/30 ] train step:10   loss: 0.69734 lr: 0.000100 batch_cost: 0.35510 sec, reader_cost: 0.00214 sec, ips: 45.05768 instance/sec.
[03/04 12:12:54] epoch:[ 30/30 ] train step:20   loss: 0.81729 lr: 0.000100 batch_cost: 0.35538 sec, reader_cost: 0.00209 sec, ips: 45.02228 instance/sec.
[03/04 12:12:58] epoch:[ 30/30 ] train step:30   loss: 0.76381 lr: 0.000100 batch_cost: 0.35560 sec, reader_cost: 0.00013 sec, ips: 44.99463 instance/sec.
[03/04 12:13:02] epoch:[ 30/30 ] train step:40   loss: 0.72202 lr: 0.000100 batch_cost: 0.35623 sec, reader_cost: 0.00251 sec, ips: 44.91507 instance/sec.
[03/04 12:13:05] epoch:[ 30/30 ] train step:50   loss: 0.82940 lr: 0.000100 batch_cost: 0.35711 sec, reader_cost: 0.00234 sec, ips: 44.80394 instance/sec.
[03/04 12:13:09] epoch:[ 30/30 ] train step:60   loss: 0.64954 lr: 0.000100 batch_cost: 0.35547 sec, reader_cost: 0.00017 sec, ips: 45.01026 instance/sec.
[03/04 12:13:12] epoch:[ 30/30 ] train step:70   loss: 0.86260 lr: 0.000100 batch_cost: 0.35601 sec, reader_cost: 0.00011 sec, ips: 44.94268 instance/sec.
[03/04 12:13:16] epoch:[ 30/30 ] train step:80   loss: 0.70770 lr: 0.000100 batch_cost: 0.35784 sec, reader_cost: 0.00254 sec, ips: 44.71307 instance/sec.
[03/04 12:13:19] epoch:[ 30/30 ] train step:90   loss: 0.74979 lr: 0.000100 batch_cost: 0.36131 sec, reader_cost: 0.00231 sec, ips: 44.28374 instance/sec.
[03/04 12:13:23] epoch:[ 30/30 ] train step:100  loss: 0.85437 lr: 0.000100 batch_cost: 0.35967 sec, reader_cost: 0.00242 sec, ips: 44.48497 instance/sec.
[03/04 12:13:27] epoch:[ 30/30 ] train step:110  loss: 0.70022 lr: 0.000100 batch_cost: 0.35636 sec, reader_cost: 0.00013 sec, ips: 44.89818 instance/sec.
[03/04 12:13:30] epoch:[ 30/30 ] train step:120  loss: 0.80290 lr: 0.000100 batch_cost: 0.36108 sec, reader_cost: 0.00268 sec, ips: 44.31178 instance/sec.
[03/04 12:13:34] epoch:[ 30/30 ] train step:130  loss: 0.70400 lr: 0.000100 batch_cost: 0.35994 sec, reader_cost: 0.00231 sec, ips: 44.45164 instance/sec.
[03/04 12:13:37] epoch:[ 30/30 ] train step:140  loss: 0.67053 lr: 0.000100 batch_cost: 0.36077 sec, reader_cost: 0.00234 sec, ips: 44.34932 instance/sec.
[03/04 12:13:41] epoch:[ 30/30 ] train step:150  loss: 0.67572 lr: 0.000100 batch_cost: 0.35897 sec, reader_cost: 0.00245 sec, ips: 44.57207 instance/sec.
[03/04 12:13:45] epoch:[ 30/30 ] train step:160  loss: 0.60355 lr: 0.000100 batch_cost: 0.35741 sec, reader_cost: 0.00260 sec, ips: 44.76709 instance/sec.
[03/04 12:13:48] epoch:[ 30/30 ] train step:170  loss: 0.74017 lr: 0.000100 batch_cost: 0.35907 sec, reader_cost: 0.00230 sec, ips: 44.55919 instance/sec.
[03/04 12:13:52] epoch:[ 30/30 ] train step:180  loss: 0.63253 lr: 0.000100 batch_cost: 0.35795 sec, reader_cost: 0.00255 sec, ips: 44.69866 instance/sec.
[03/04 12:13:55] epoch:[ 30/30 ] train step:190  loss: 0.64215 lr: 0.000100 batch_cost: 0.35968 sec, reader_cost: 0.00236 sec, ips: 44.48444 instance/sec.
[03/04 12:13:59] epoch:[ 30/30 ] train step:200  loss: 0.92614 lr: 0.000100 batch_cost: 0.35987 sec, reader_cost: 0.00268 sec, ips: 44.46068 instance/sec.
[03/04 12:14:02] epoch:[ 30/30 ] train step:210  loss: 0.66276 lr: 0.000100 batch_cost: 0.35900 sec, reader_cost: 0.00234 sec, ips: 44.56798 instance/sec.
[03/04 12:14:06] epoch:[ 30/30 ] train step:220  loss: 0.80071 lr: 0.000100 batch_cost: 0.35911 sec, reader_cost: 0.00246 sec, ips: 44.55496 instance/sec.
[03/04 12:14:10] epoch:[ 30/30 ] train step:230  loss: 0.87135 lr: 0.000100 batch_cost: 0.35909 sec, reader_cost: 0.00232 sec, ips: 44.55692 instance/sec.
[03/04 12:14:13] epoch:[ 30/30 ] train step:240  loss: 0.90619 lr: 0.000100 batch_cost: 0.35846 sec, reader_cost: 0.00271 sec, ips: 44.63572 instance/sec.
[03/04 12:14:17] epoch:[ 30/30 ] train step:250  loss: 0.70939 lr: 0.000100 batch_cost: 0.35882 sec, reader_cost: 0.00245 sec, ips: 44.59019 instance/sec.
[03/04 12:14:20] epoch:[ 30/30 ] train step:260  loss: 0.64666 lr: 0.000100 batch_cost: 0.35656 sec, reader_cost: 0.00240 sec, ips: 44.87356 instance/sec.
[03/04 12:14:24] epoch:[ 30/30 ] train step:270  loss: 0.86034 lr: 0.000100 batch_cost: 0.35723 sec, reader_cost: 0.00217 sec, ips: 44.78929 instance/sec.
[03/04 12:14:28] epoch:[ 30/30 ] train step:280  loss: 0.81247 lr: 0.000100 batch_cost: 0.35870 sec, reader_cost: 0.00272 sec, ips: 44.60522 instance/sec.
[03/04 12:14:31] epoch:[ 30/30 ] train step:290  loss: 1.02420 lr: 0.000100 batch_cost: 0.36016 sec, reader_cost: 0.00241 sec, ips: 44.42519 instance/sec.
[03/04 12:14:35] epoch:[ 30/30 ] train step:300  loss: 0.84243 lr: 0.000100 batch_cost: 0.35496 sec, reader_cost: 0.00250 sec, ips: 45.07575 instance/sec.
[03/04 12:14:38] epoch:[ 30/30 ] train step:310  loss: 0.76739 lr: 0.000100 batch_cost: 0.35514 sec, reader_cost: 0.00220 sec, ips: 45.05293 instance/sec.
[03/04 12:14:42] epoch:[ 30/30 ] train step:320  loss: 0.90073 lr: 0.000100 batch_cost: 0.35830 sec, reader_cost: 0.00256 sec, ips: 44.65586 instance/sec.
[03/04 12:14:45] epoch:[ 30/30 ] train step:330  loss: 0.66597 lr: 0.000100 batch_cost: 0.35693 sec, reader_cost: 0.00247 sec, ips: 44.82695 instance/sec.
[03/04 12:14:49] epoch:[ 30/30 ] train step:340  loss: 0.75215 lr: 0.000100 batch_cost: 0.35398 sec, reader_cost: 0.00018 sec, ips: 45.19998 instance/sec.
[03/04 12:14:53] epoch:[ 30/30 ] train step:350  loss: 0.73130 lr: 0.000100 batch_cost: 0.35681 sec, reader_cost: 0.00221 sec, ips: 44.84196 instance/sec.
[03/04 12:14:56] epoch:[ 30/30 ] train step:360  loss: 0.70385 lr: 0.000100 batch_cost: 0.35379 sec, reader_cost: 0.00016 sec, ips: 45.22468 instance/sec.
[03/04 12:15:00] epoch:[ 30/30 ] train step:370  loss: 0.72937 lr: 0.000100 batch_cost: 0.35592 sec, reader_cost: 0.00237 sec, ips: 44.95454 instance/sec.
[03/04 12:15:03] epoch:[ 30/30 ] train step:380  loss: 0.69317 lr: 0.000100 batch_cost: 0.35759 sec, reader_cost: 0.00223 sec, ips: 44.74408 instance/sec.
[03/04 12:15:07] epoch:[ 30/30 ] train step:390  loss: 0.70516 lr: 0.000100 batch_cost: 0.35831 sec, reader_cost: 0.00233 sec, ips: 44.65467 instance/sec.
[03/04 12:15:10] epoch:[ 30/30 ] train step:400  loss: 0.76647 lr: 0.000100 batch_cost: 0.35761 sec, reader_cost: 0.00228 sec, ips: 44.74175 instance/sec.
[03/04 12:15:14] epoch:[ 30/30 ] train step:410  loss: 0.82536 lr: 0.000100 batch_cost: 0.35676 sec, reader_cost: 0.00017 sec, ips: 44.84780 instance/sec.
[03/04 12:15:17] epoch:[ 30/30 ] train step:420  loss: 0.75648 lr: 0.000100 batch_cost: 0.35931 sec, reader_cost: 0.00240 sec, ips: 44.52998 instance/sec.
[03/04 12:15:21] epoch:[ 30/30 ] train step:430  loss: 0.64999 lr: 0.000100 batch_cost: 0.35297 sec, reader_cost: 0.00024 sec, ips: 45.32971 instance/sec.
[03/04 12:15:25] epoch:[ 30/30 ] train step:440  loss: 0.84971 lr: 0.000100 batch_cost: 0.35580 sec, reader_cost: 0.00019 sec, ips: 44.96864 instance/sec.
[03/04 12:15:28] epoch:[ 30/30 ] train step:450  loss: 0.72219 lr: 0.000100 batch_cost: 0.35742 sec, reader_cost: 0.00231 sec, ips: 44.76533 instance/sec.
[03/04 12:15:32] epoch:[ 30/30 ] train step:460  loss: 0.87021 lr: 0.000100 batch_cost: 0.35588 sec, reader_cost: 0.00243 sec, ips: 44.95909 instance/sec.
[03/04 12:15:35] epoch:[ 30/30 ] train step:470  loss: 0.77548 lr: 0.000100 batch_cost: 0.35640 sec, reader_cost: 0.00027 sec, ips: 44.89314 instance/sec.
[03/04 12:15:39] epoch:[ 30/30 ] train step:480  loss: 0.63018 lr: 0.000100 batch_cost: 0.35577 sec, reader_cost: 0.00016 sec, ips: 44.97328 instance/sec.
[03/04 12:15:42] epoch:[ 30/30 ] train step:490  loss: 0.72734 lr: 0.000100 batch_cost: 0.35939 sec, reader_cost: 0.00247 sec, ips: 44.51967 instance/sec.
[03/04 12:15:46] epoch:[ 30/30 ] train step:500  loss: 0.77063 lr: 0.000100 batch_cost: 0.35565 sec, reader_cost: 0.00224 sec, ips: 44.98809 instance/sec.
[03/04 12:15:50] epoch:[ 30/30 ] train step:510  loss: 0.85932 lr: 0.000100 batch_cost: 0.35758 sec, reader_cost: 0.00010 sec, ips: 44.74512 instance/sec.
[03/04 12:15:53] epoch:[ 30/30 ] train step:520  loss: 0.89303 lr: 0.000100 batch_cost: 0.35414 sec, reader_cost: 0.00013 sec, ips: 45.17975 instance/sec.
[03/04 12:15:57] epoch:[ 30/30 ] train step:530  loss: 0.74670 lr: 0.000100 batch_cost: 0.35652 sec, reader_cost: 0.00014 sec, ips: 44.87852 instance/sec.
[03/04 12:16:00] epoch:[ 30/30 ] train step:540  loss: 0.59741 lr: 0.000100 batch_cost: 0.35646 sec, reader_cost: 0.00246 sec, ips: 44.88617 instance/sec.
[03/04 12:16:04] epoch:[ 30/30 ] train step:550  loss: 0.60003 lr: 0.000100 batch_cost: 0.35550 sec, reader_cost: 0.00220 sec, ips: 45.00755 instance/sec.
[03/04 12:16:07] epoch:[ 30/30 ] train step:560  loss: 0.82061 lr: 0.000100 batch_cost: 0.35841 sec, reader_cost: 0.00265 sec, ips: 44.64189 instance/sec.
[03/04 12:16:11] epoch:[ 30/30 ] train step:570  loss: 0.71779 lr: 0.000100 batch_cost: 0.35516 sec, reader_cost: 0.00242 sec, ips: 45.05045 instance/sec.
[03/04 12:16:15] epoch:[ 30/30 ] train step:580  loss: 0.72167 lr: 0.000100 batch_cost: 0.35505 sec, reader_cost: 0.00018 sec, ips: 45.06419 instance/sec.
[03/04 12:16:18] epoch:[ 30/30 ] train step:590  loss: 0.86632 lr: 0.000100 batch_cost: 0.36101 sec, reader_cost: 0.00230 sec, ips: 44.31989 instance/sec.
[03/04 12:16:22] epoch:[ 30/30 ] train step:600  loss: 0.79111 lr: 0.000100 batch_cost: 0.35733 sec, reader_cost: 0.00015 sec, ips: 44.77632 instance/sec.
[03/04 12:16:25] epoch:[ 30/30 ] train step:610  loss: 1.10101 lr: 0.000100 batch_cost: 0.36123 sec, reader_cost: 0.00249 sec, ips: 44.29315 instance/sec.
[03/04 12:16:29] epoch:[ 30/30 ] train step:620  loss: 0.69214 lr: 0.000100 batch_cost: 0.35810 sec, reader_cost: 0.00238 sec, ips: 44.68059 instance/sec.
[03/04 12:16:32] epoch:[ 30/30 ] train step:630  loss: 1.08404 lr: 0.000100 batch_cost: 0.35675 sec, reader_cost: 0.00224 sec, ips: 44.84891 instance/sec.
[03/04 12:16:36] epoch:[ 30/30 ] train step:640  loss: 0.87496 lr: 0.000100 batch_cost: 0.35946 sec, reader_cost: 0.00266 sec, ips: 44.51072 instance/sec.
[03/04 12:16:40] epoch:[ 30/30 ] train step:650  loss: 0.82737 lr: 0.000100 batch_cost: 0.35847 sec, reader_cost: 0.00032 sec, ips: 44.63456 instance/sec.
[03/04 12:16:43] epoch:[ 30/30 ] train step:660  loss: 0.81014 lr: 0.000100 batch_cost: 0.35802 sec, reader_cost: 0.00224 sec, ips: 44.69062 instance/sec.
[03/04 12:16:47] epoch:[ 30/30 ] train step:670  loss: 0.73007 lr: 0.000100 batch_cost: 0.35987 sec, reader_cost: 0.00230 sec, ips: 44.45997 instance/sec.
[03/04 12:16:50] epoch:[ 30/30 ] train step:680  loss: 0.63362 lr: 0.000100 batch_cost: 0.35712 sec, reader_cost: 0.00264 sec, ips: 44.80331 instance/sec.
[03/04 12:16:54] epoch:[ 30/30 ] train step:690  loss: 0.78238 lr: 0.000100 batch_cost: 0.35923 sec, reader_cost: 0.00228 sec, ips: 44.53917 instance/sec.
[03/04 12:16:58] epoch:[ 30/30 ] train step:700  loss: 0.74877 lr: 0.000100 batch_cost: 0.35935 sec, reader_cost: 0.00245 sec, ips: 44.52487 instance/sec.
[03/04 12:17:01] epoch:[ 30/30 ] train step:710  loss: 0.65804 lr: 0.000100 batch_cost: 0.35859 sec, reader_cost: 0.00013 sec, ips: 44.61966 instance/sec.
[03/04 12:17:05] epoch:[ 30/30 ] train step:720  loss: 0.77751 lr: 0.000100 batch_cost: 0.35668 sec, reader_cost: 0.00274 sec, ips: 44.85764 instance/sec.
[03/04 12:17:08] epoch:[ 30/30 ] train step:730  loss: 0.83500 lr: 0.000100 batch_cost: 0.35762 sec, reader_cost: 0.00220 sec, ips: 44.74029 instance/sec.
[03/04 12:17:12] epoch:[ 30/30 ] train step:740  loss: 0.79201 lr: 0.000100 batch_cost: 0.35980 sec, reader_cost: 0.00234 sec, ips: 44.46908 instance/sec.
[03/04 12:17:16] epoch:[ 30/30 ] train step:750  loss: 1.00914 lr: 0.000100 batch_cost: 0.35949 sec, reader_cost: 0.00233 sec, ips: 44.50727 instance/sec.
[03/04 12:17:19] epoch:[ 30/30 ] train step:760  loss: 0.75711 lr: 0.000100 batch_cost: 0.35762 sec, reader_cost: 0.00253 sec, ips: 44.74064 instance/sec.
[03/04 12:17:23] epoch:[ 30/30 ] train step:770  loss: 0.65036 lr: 0.000100 batch_cost: 0.35854 sec, reader_cost: 0.00231 sec, ips: 44.62503 instance/sec.
[03/04 12:17:26] epoch:[ 30/30 ] train step:780  loss: 0.72065 lr: 0.000100 batch_cost: 0.35573 sec, reader_cost: 0.00006 sec, ips: 44.97738 instance/sec.
[03/04 12:17:29] END epoch:30  train loss_avg: 0.75608  avg_batch_cost: 0.35249 sec, avg_reader_cost: 0.00005 sec, batch_cost_sum: 282.12803 sec, avg_ips: 44.63222 instance/sec.
[03/04 12:17:29] training BMN finished
